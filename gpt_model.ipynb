{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT Model for Disaster Tweet Classification\n",
    "\n",
    "In this Notebook, we will train a GPT-2 model to classify tweets as disaster-related or not. \n",
    "\n",
    "We will first use the original raw `text` feature from train.csv, without any preprocessing of data, to train the GPT-2 model because we want to evaluate if it is worth our time training this model at all. If it does not achieve significantly better results, we will likely not continue fine-tuning the GPT-2 model and stick to our initial classification models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import GPT2Tokenizer, GPT2Config, GPT2ForSequenceClassification, TrainingArguments, Trainer, TextClassificationPipeline\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train_data = train.copy()\n",
    "test_data = test.copy()\n",
    "\n",
    "# Split the training data into train set and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data[\"text\"], train_data[\"target\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GPT-2 tokenizer, model, and configuration\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "config = GPT2Config.from_pretrained(\"gpt2\", num_labels=2)\n",
    "config.pad_token_id = tokenizer.eos_token_id\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", config=config)\n",
    "\n",
    "# Set a padding token for the GPT-2 tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize the training and validation data\n",
    "train_encodings = tokenizer(X_train.to_list(), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(X_val.to_list(), truncation=True, padding=True)\n",
    "\n",
    "# Create a dataset object for the trainer\n",
    "class DisasterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = DisasterDataset(train_encodings, y_train.to_list())\n",
    "val_dataset = DisasterDataset(val_encodings, y_val.to_list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the training arguments and trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"no\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "test_pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "predictions = test_pipeline(test_data[\"text\"].to_list())\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "test_data[\"target\"] = [prediction[\"label\"].split(\"_\")[-1] for prediction in predictions]\n",
    "test_data[[\"id\", \"target\"]].to_csv(\"predictions/gpt2_predictions.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprising Results\n",
    "\n",
    "It achieved an accuracy score of 0.81918 which is significantly higher than the scores achieved by any other models we have trained, and this is before any preprocessing of the dataset. Since it achieved much better results than the previous models we have trained, we decided to continue fine-tuning it.\n",
    "\n",
    "We decided to use the `text`, `keyword`, `tweet_count` and `punctuation_count` features to train the GPT-2 model. These features have been proven to display strong relationship with `target` in data_preprocessing.ipynb. \n",
    "\n",
    "Since the GPT-2 model only takes in a single text input, our plan is to concatenate all of the features into one `combined_text` feature and pass it to GPT-2 model as a text input to train it.\n",
    "\n",
    "Examples of how `combined_text` will look like:\n",
    "1. \"Courageous and honest analysis of need to use Atomic Bomb in 1945. #Hiroshima70 Japanese military refused surrender. https://t.co/VhmtyTptGR (Keyword: military , Tweet Length: 140, Punctuation Count: 8)\"\n",
    "2. \"Typhoon Soudelor kills 28 in China and Taiwan (Keyword: , Tweet length: 45, Punctuation Count: 0)\"\n",
    "\n",
    "By concatenating the `keyword`, `tweet_length` and `punctuation_length` at the end of `text` explicitly in parentheses, it can help the GPT-2 model better understand the data with more context, and potentially perform better at predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(data, text):\n",
    "    data[text] = data['text'] + ' (Keyword: ' + data['keyword'].fillna('') + ',' + ' Tweet length: ' + data['tweet_length'].astype(str) + ',' + ' Punctuation Count: ' + data['punctuation_count'].astype(str) +')'\n",
    "    return data\n",
    "\n",
    "# Load train dataset\n",
    "train_text_keyword_data = pd.read_csv('train.csv')\n",
    "train_meta_data = pd.read_csv('train_data_mod.csv')\n",
    "train_meta_data = train_meta_data.drop(['target', 'text', 'keyword'], axis=1)\n",
    "\n",
    "# Load test dataset\n",
    "test_text_keyword_data = pd.read_csv('test.csv')\n",
    "test_meta_data = pd.read_csv('test_data_mod.csv')\n",
    "test_meta_data = test_meta_data.drop(['text', 'keyword'], axis=1)\n",
    "\n",
    "# Merge the data\n",
    "train = train_text_keyword_data.merge(train_meta_data, on='id')\n",
    "test = test_text_keyword_data.merge(test_meta_data, on='id')\n",
    "\n",
    "# Concatenate the features\n",
    "train = combine_text(train, 'combined_text')\n",
    "test = combine_text(test, 'combined_text')\n",
    "\n",
    "train_data = train.copy()\n",
    "test_data = test.copy()\n",
    "\n",
    "# Split the training data into train set and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data[\"combined_text\"], train_data[\"target\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the concatenated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "print(\"X_train:\")\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"\\nX_val:\")\n",
    "print(X_val.head())\n",
    "\n",
    "print(\"\\ntest_data:\")\n",
    "print(test_data[\"combined_text\"].head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", config=config)\n",
    "\n",
    "train_encodings = tokenizer(X_train.to_list(), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(X_val.to_list(), truncation=True, padding=True)\n",
    "\n",
    "train_dataset = DisasterDataset(train_encodings, y_train.to_list())\n",
    "val_dataset = DisasterDataset(val_encodings, y_val.to_list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the training arguments and trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"no\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "test_pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "predictions = test_pipeline(test_data[\"combined_text\"].to_list())\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "test_data[\"target\"] = [prediction[\"label\"].split(\"_\")[-1] for prediction in predictions]\n",
    "test_data[[\"id\", \"target\"]].to_csv(\"predictions/gpt2_predictions2.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slightly Better Results\n",
    "\n",
    "It achieved an accuracy score of 0.82715 which is slightly higher than the scores achieved by using a non-preprocessed data(0.81918). The increase is lesser than we have expected because we thought that incorporating additional features would have a more significant impact on the model's performance. However, it is still an improvement, and we can consider further refining the model.\n",
    "\n",
    "Here, we decided to clean up the data by removing any URL and special characters, and train the GPT-2 model with the cleaned data. This reduces noise in the dataset and keeps the data more consistent. We have also decided to not convert characters to lowercase, eliminate stop words, and avoid lemmatization, because the GPT-2 model has the ability to process these words with context, ultimately producing predictions that are more meaningful.\n",
    "\n",
    "Our prediction is that the model will perform slightly better than the first."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#','', text)\n",
    "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Clean the text column in train and test dataset\n",
    "train_data['text'] = train['text'].apply(lambda x: clean_text(x))\n",
    "test_data[\"text\"] = test_data[\"text\"].apply(lambda x: clean_text(x))\n",
    "\n",
    "# Concatenate the cleaned text with other features\n",
    "train_data = combine_text(train_data, 'cleaned_combined_text')\n",
    "test_data = combine_text(test_data, 'cleaned_combined_text')\n",
    "\n",
    "# Split the training data into train set and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data[\"cleaned_combined_text\"], train_data[\"target\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cleaned X_train:\")\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"\\nCleaned X_val:\")\n",
    "print(X_val.head())\n",
    "\n",
    "print(\"\\nCleaned test_data:\")\n",
    "print(test_data[\"cleaned_combined_text\"].head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare GPT-2 Model with the cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", config=config)\n",
    "\n",
    "train_encodings = tokenizer(X_train.to_list(), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(X_val.to_list(), truncation=True, padding=True)\n",
    "\n",
    "train_dataset = DisasterDataset(train_encodings, y_train.to_list())\n",
    "val_dataset = DisasterDataset(val_encodings, y_val.to_list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the GPT-2 Model with the cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the training arguments and trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"no\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "predictions = test_pipeline(test_data[\"cleaned_combined_text\"].to_list())\n",
    "\n",
    "test_data[\"target\"] = [prediction[\"label\"].split(\"_\")[-1] for prediction in predictions]\n",
    "test_data[[\"id\", \"target\"]].to_csv(\"predictions/gpt2_predictions3.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Result\n",
    "\n",
    "Indeed, the accuracy score is very slightly better at 0.8296 (vs 0.82715) with the cleaned data. \n",
    "\n",
    "We will further fine-tune the GPT-2 model by optimizing `Learning Rate` and `Number of Epochs`. We decided to perform a Grid Search to find the best combination of learning rate and number of epochs.\n",
    "\n",
    "This involves training and evaluating the model with different combinations of learning rates and the number of epochs, and the best model with the highest validation accuracy will be used as the final model for predictions. This approach can help in finding the optimal hyperparameters for the model, leading to improved performance and potentially better prediction results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for Learning Rate and Number of Epochs\n",
    "\n",
    "`learning_rates = [1e-5, 5e-5, 1e-4]`: These learning rates are chosen because they are within the typical range used in practice for fine-tuning pre-trained models like GPT-2. A smaller learning rate, like 1e-5, might lead to slower convergence but can be more stable, while a larger learning rate, like 1e-4, can speed up the training process but may cause overshooting and instability in training. The value 5e-5 is chosen as a middle ground between these two extremes.\n",
    "\n",
    "`num_epochs = [3, 5, 7]`: These values for the number of epochs are chosen based on the assumption that the pre-trained GPT-2 model has already learned useful text representations, and a smaller number of epochs might be sufficient for fine-tuning. Using a smaller number of epochs can help prevent overfitting and reduce training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_val_accuracy(model, val_dataset):\n",
    "    val_pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "    # Convert tokenized inputs back to original text\n",
    "    val_texts = [tokenizer.decode(x[\"input_ids\"], skip_special_tokens=True) for x in val_dataset]\n",
    "    val_predictions = val_pipeline(val_texts)\n",
    "    val_labels = [x[\"labels\"].tolist() for x in val_dataset]\n",
    "    val_accuracy = accuracy_score(val_labels, [int(prediction[\"label\"].split(\"_\")[-1]) for prediction in val_predictions])\n",
    "    return val_accuracy\n",
    "\n",
    "learning_rates = [1e-5, 5e-5, 1e-4]\n",
    "num_epochs = [3, 5, 7]\n",
    "\n",
    "best_model = None\n",
    "best_val_accuracy = 0\n",
    "best_lr = None\n",
    "best_epoch = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for epoch in num_epochs:\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f\"./gpt2_results_lr{lr}_epoch{epoch}\",\n",
    "            num_train_epochs=epoch,\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            logging_dir=\"./logs\",\n",
    "            logging_steps=100,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            save_strategy=\"no\",\n",
    "            seed=42,\n",
    "            learning_rate=lr,\n",
    "        )\n",
    "        \n",
    "        model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", config=config)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        val_accuracy = compute_val_accuracy(model, val_dataset)\n",
    "        print(f\"Learning rate: {lr}, Num Epochs: {epoch}, Validation accuracy: {val_accuracy}\")\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model = model\n",
    "            best_lr = lr\n",
    "            best_epoch = epoch\n",
    "\n",
    "print(f\"Best validation accuracy: {best_val_accuracy}, Best learning rate: {best_lr}, Best number of epochs: {best_epoch}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = TextClassificationPipeline(model=best_model, tokenizer=tokenizer)\n",
    "predictions = test_pipeline(test_data[\"keyword_text\"].to_list())\n",
    "\n",
    "test_data[\"target\"] = [prediction[\"label\"].split(\"_\")[-1] for prediction in predictions]\n",
    "test_data[[\"id\", \"target\"]].to_csv(\"predictions/gpt2_best_predictions.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unexpected Result\n",
    "\n",
    "It is unexpected that the best model with the optimal combination of learning rate and number of epochs **performed the worst**, with an accuracy score of 0.81366. Here are some possible reasons we can think of for this:\n",
    "\n",
    "1. **Overfitting**: The model might have overfit the training data due to the chosen combination of learning rate and number of epochs. This can happen when the model becomes too specialized in learning the patterns in the training data, and as a result, performs poorly on new, unseen data.\n",
    "\n",
    "2. **Local minima**: It is possible that the model got stuck in a local minimum during the training process, which may have resulted in suboptimal performance. The chosen learning rate and number of epochs might not have been suitable to escape the local minimum and reach a better solution.\n",
    "\n",
    "3. **Randomness**: The training process involves a certain amount of randomness, which can lead to different results with different runs, even with the same hyperparameters. The worse performance might be attributed to the inherent randomness in the training process, and perhaps with additional runs, the performance might improve."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, while the GPT-2 model initially showed promising results, the fine-tuning attempts with various preprocessing techniques and hyperparameter combinations did not yield the expected improvements. This result shocked us as we initially believed that preprocessing the data and fine-tuning the hyperparameters would lead to significant improvements in the model's performance. \n",
    "\n",
    "Nevertheless, the GPT-2 model still performed the best out of all the other models we have trained. It was an unexpected outcome but an eye-opening experience that has allowed us to draw several valuable insights:\n",
    "\n",
    "1. **Importance of raw data**: The fact that the GPT-2 model performed really well on raw data suggests that the context and structure of the original data might be more important than initially thought. This highlights the importance of carefully considering the impact of preprocessing on the model's performance.\n",
    "\n",
    "2. **Complexity of fine-tuning**: Fine-tuning a pre-trained model like GPT-2 can be a complex process, and finding the optimal combination of hyperparameters might not always lead to the best results. This underlines the importance of exploring different strategies and being open to experimentation during the fine-tuning process.\n",
    "\n",
    "3. **Model robustness**: The GPT-2 model's ability to perform well on raw data, without any preprocessing or cleaning, showcases the robustness of this model. It demonstrates that it can effectively handle noisy and unstructured data, making it a strong contender for natural language processing tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
