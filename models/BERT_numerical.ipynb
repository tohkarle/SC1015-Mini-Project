{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup, DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "train = pd.read_csv('../train_data_mod.csv')\n",
    "test = pd.read_csv('../test_data_mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mod = train.copy()\n",
    "test_mod = test.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  instead of using the preprocessed text, we will use the original text applied.\n",
    "- This is because BERT can learn context and relationships between words (including mispelled words), which makes it different from standard preprocessing techniques. \n",
    "- It also has it's own special tokenizer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing the Text Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_distil = BertTokenizer.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'keyword', 'location', 'text', 'target', 'preprocess_text',\n",
       "       'bigram', 'trigram', 'pos', 'keyword_encoded', 'tweet_length',\n",
       "       'punctuation_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "drop_cols = ['keyword', 'location', 'preprocess_text','bigram','trigram', 'pos']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mod.drop(drop_cols, axis=1, inplace=True)\n",
    "test_mod.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'text', 'target', 'keyword_encoded', 'tweet_length',\n",
       "       'punctuation_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'text', 'keyword_encoded', 'tweet_length', 'punctuation_count'], dtype='object')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features_columns = ['keyword_encoded', 'tweet_length', 'punctuation_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(text_column, tokenizer):\n",
    "    max_len = 0\n",
    "    for text in text_column:\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        # print(tokens)\n",
    "        max_len = max(max_len, len(tokens))\n",
    "    print(\"Max length: \", max_len, \" tokens\")\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  104  tokens\n",
      "Max length:  99  tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length(train_mod['text'], tokenizer)\n",
    "max_length(test_mod['text'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs =  tokenizer_distil(train_mod['text'].tolist(), padding=True, truncation=True, max_length=128, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs_test = tokenizer_distil(test_mod['text'].tolist(), padding=True, truncation=True, max_length=128, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_inputs_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encoded_inputs['input_ids']\n",
    "attention_mask = encoded_inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test = encoded_inputs_test['input_ids']\n",
    "attention_mask_test = encoded_inputs_test['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  3458,  9115,  ...,     0,     0,     0],\n",
      "        [  101,  4089,  1783,  ...,     0,     0,     0],\n",
      "        [  101,  1398,  3159,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 26528,   119,  ...,     0,     0,     0],\n",
      "        [  101,  3284, 11950,  ...,     0,     0,     0],\n",
      "        [  101,  1109,  6372,  ...,     0,     0,     0]])\n",
      "torch.Size([7613, 106])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "torch.Size([7613, 106])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)\n",
    "print(input_ids.shape)\n",
    "print(attention_mask)\n",
    "print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2066,  2171,  ...,     0,     0,     0],\n",
      "        [  101, 23599,  1164,  ...,     0,     0,     0],\n",
      "        [  101,  1175,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2565,  2800,  ...,     0,     0,     0],\n",
      "        [  101, 22157,  2349,  ...,     0,     0,     0],\n",
      "        [  101,   108,  1392,  ...,     0,     0,     0]])\n",
      "torch.Size([3263, 101])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "torch.Size([3263, 101])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids_test)\n",
    "print(input_ids_test.shape)\n",
    "print(attention_mask_test)\n",
    "print(attention_mask_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing the numerical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have a dataset df that contains both numerical and non-numerical features\n",
    "\n",
    "# Separate the numerical and non-numerical features\n",
    "numerical_features = train_mod[numerical_features_columns]\n",
    "non_numerical_features = train_mod[['text','target']]\n",
    "\n",
    "# Create an instance of the StandardScaler class\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the numerical features\n",
    "scaler.fit(numerical_features)\n",
    "\n",
    "# Transform the numerical features using the fitted scaler\n",
    "numerical_features_scaled = scaler.transform(numerical_features)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features_scaled_test = scaler.transform(test_mod[numerical_features_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scaled_numerical_features to a tensor\n",
    "numerical_tensor = torch.tensor(numerical_features_scaled, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_tensor_test = torch.tensor(numerical_features_scaled_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1453, -0.9501, -1.2671],\n",
       "        [ 1.1453, -1.8658, -1.2671],\n",
       "        [ 1.1453,  0.9405, -0.8331],\n",
       "        ...,\n",
       "        [ 1.1453, -1.0682,  0.9028],\n",
       "        [ 1.1453,  1.0587, -0.3992],\n",
       "        [ 1.1453, -0.2116,  0.0348]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1453, -1.9840, -1.4841],\n",
       "        [ 1.1453, -1.0978, -0.8331],\n",
       "        [ 1.1453, -0.1525, -1.0501],\n",
       "        ...,\n",
       "        [ 1.1453, -1.3636, -0.3992],\n",
       "        [ 1.1453, -1.0682,  0.0348],\n",
       "        [ 1.1453, -0.9796, -0.8331]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_tensor_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the hidden states from BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 2\n",
    "dataset = TensorDataset(input_ids, attention_mask)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = TensorDataset(input_ids_test, attention_mask_test)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[187], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m      9\u001b[0m     \u001b[39mfor\u001b[39;00m batch_input_ids, batch_attention_masks \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m---> 10\u001b[0m         outputs \u001b[39m=\u001b[39m bert_model(input_ids\u001b[39m=\u001b[39;49mbatch_input_ids, attention_mask\u001b[39m=\u001b[39;49mbatch_attention_masks)\n\u001b[0;32m     11\u001b[0m         batch_embeddings \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlast_hidden_state[:, \u001b[39m0\u001b[39m, :]\n\u001b[0;32m     12\u001b[0m         text_embeddings\u001b[39m.\u001b[39mappend(batch_embeddings)\n",
      "File \u001b[1;32mc:\\Users\\yuhao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\yuhao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[1;32m-> 1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1021\u001b[0m     embedding_output,\n\u001b[0;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1023\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1024\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1025\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1026\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1027\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1028\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1029\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1031\u001b[0m )\n\u001b[0;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1033\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yuhao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\yuhao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    601\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    603\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    608\u001b[0m     )\n\u001b[0;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 610\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    611\u001b[0m         hidden_states,\n\u001b[0;32m    612\u001b[0m         attention_mask,\n\u001b[0;32m    613\u001b[0m         layer_head_mask,\n\u001b[0;32m    614\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    615\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    616\u001b[0m         past_key_value,\n\u001b[0;32m    617\u001b[0m         output_attentions,\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    620\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    621\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\yuhao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\yuhao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:537\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    534\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    535\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 537\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    538\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[0;32m    539\u001b[0m )\n\u001b[0;32m    540\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[0;32m    542\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yuhao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pytorch_utils.py:236\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    234\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 236\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[1;32mc:\\Users\\yuhao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:550\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m    549\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 550\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[0;32m    551\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\yuhao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\yuhao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:462\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 462\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[0;32m    463\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    464\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32mc:\\Users\\yuhao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\yuhao\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "bert_model = BertModel.from_pretrained('bert-base-cased')\n",
    "bert_model.eval()\n",
    "\n",
    "text_embeddings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_input_ids, batch_attention_masks in dataloader:\n",
    "        outputs = bert_model(input_ids=batch_input_ids, attention_mask=batch_attention_masks)\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        text_embeddings.append(batch_embeddings)\n",
    "\n",
    "# Concatenate all batch embeddings into a single tensor\n",
    "text_embeddings = torch.cat(text_embeddings, dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cat() received an invalid combination of arguments - got (Tensor, dim=int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[152], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m         text_embeddings_test\u001b[39m.\u001b[39mappend(batch_embeddings)\n\u001b[0;32m     11\u001b[0m \u001b[39m# Concatenate all batch embeddings into a single tensor\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m text_embeddings_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(text_embeddings, dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (Tensor, dim=int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-cased')\n",
    "bert_model.eval()\n",
    "text_embeddings_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_input_ids, batch_attention_masks in dataloader_test:\n",
    "        outputs = bert_model(input_ids=batch_input_ids, attention_mask=batch_attention_masks)\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        text_embeddings_test.append(batch_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all batch embeddings into a single tensor\n",
    "text_embeddings_test = torch.cat(text_embeddings_test, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features_test = torch.cat([text_embeddings_test, numerical_tensor_test], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m combined_features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([text_embeddings, numerical_tensor], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "combined_features = torch.cat([text_embeddings, numerical_tensor], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 771)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined Neural Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "# Create a simple feed-forward neural network\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, bert_output_size, num_numerical_features, num_classes):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.layer = nn.Linear(bert_output_size + num_numerical_features, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModelMoreHLs(nn.Module):\n",
    "    def __init__(self, bert_output_size, num_numerical_features, num_classes, hidden_size=128, dropout_rate=0.5):\n",
    "        super(CombinedModelMoreHLs, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(bert_output_size + num_numerical_features, hidden_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.activation1 = nn.ReLU()\n",
    "\n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.activation2 = nn.ReLU()\n",
    "\n",
    "        # self.layer3 = nn.Linear(hidden_size, hidden_size)\n",
    "        # self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        # self.activation3 = nn.ReLU()\n",
    "\n",
    "        # self.layer4 = nn.Linear(hidden_size, hidden_size)\n",
    "        # self.dropout4 = nn.Dropout(dropout_rate)\n",
    "        # self.activation4 = nn.ReLU()\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.activation1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.activation2(x)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to numpy for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = combined_features.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2935, -0.0725, -0.1569,  ...,  1.1453, -0.9501, -1.2671],\n",
       "        [ 0.2558,  0.1809, -0.1708,  ...,  1.1453, -1.8658, -1.2671],\n",
       "        [ 0.0527,  0.0251,  0.1077,  ...,  1.1453,  0.9405, -0.8331],\n",
       "        ...,\n",
       "        [ 0.4800,  0.0919,  0.0373,  ...,  1.1453, -1.0682,  0.9028],\n",
       "        [ 0.3759,  0.0696, -0.2249,  ...,  1.1453,  1.0587, -0.3992],\n",
       "        [ 0.2824,  0.1017, -0.2784,  ...,  1.1453, -0.2116,  0.0348]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features_test = combined_features_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_mod['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_numpy = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_and_validate(train_dataloader, val_dataloader, len_val_dataset, num_epochs=10, device='cuda' if torch.cuda.is_available() else 'cpu', lr=1e-3):\n",
    "    # Replace with your custom model\n",
    "    model = CombinedModel(bert_output_size=768, num_numerical_features=len(numerical_features_columns), num_classes=1)\n",
    "    #model = CombinedModelMoreHLs(bert_output_size=768, num_numerical_features=len(numerical_features_columns), num_classes=1)\n",
    "    model.to(device)\n",
    "\n",
    "    print(\"Loaded Model to device\")\n",
    "    # Define the loss function and optimizer\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    print(\"Initialized Loss and Optimizer\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch_features, batch_labels in train_dataloader:\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(batch_features)\n",
    "            loss = loss_fn(logits, batch_labels)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Print the average training loss for the epoch\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {total_loss / len(train_dataloader)}')\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_labels in val_dataloader:\n",
    "                batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                logits = model(batch_features)\n",
    "                loss = loss_fn(logits, batch_labels)\n",
    "\n",
    "                # Calculate the number of correct predictions\n",
    "                predictions = (logits > 0).float()\n",
    "                correct_predictions += (predictions == batch_labels).sum().item()\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        # Print the average validation loss and accuracy for the epoch\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {total_val_loss / len(val_dataloader)}, Validation Accuracy: {correct_predictions / len_val_dataset}')\n",
    "    return correct_predictions / len_val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.5584e-01,  1.8094e-01, -1.7079e-01, -2.6513e-01, -4.3705e-01,\n",
       "         5.8956e-02,  3.7884e-01,  1.1668e-01,  1.8814e-01, -1.3791e+00,\n",
       "        -1.6295e-01,  3.5897e-01, -1.2012e-01, -1.8769e-01, -3.4638e-01,\n",
       "         1.7986e-01,  6.7315e-02,  2.1108e-01,  2.7141e-01,  3.2946e-02,\n",
       "        -4.3810e-02, -1.5269e-01,  5.6467e-01, -2.1989e-01,  3.0091e-01,\n",
       "        -1.2909e-01,  1.6395e-01,  1.9878e-01, -1.8192e-01,  1.0246e-01,\n",
       "         3.5770e-02,  2.9780e-02, -1.6495e-01,  2.9364e-01, -8.6084e-02,\n",
       "         2.2865e-01, -1.2303e-01, -3.8921e-01,  3.9487e-02, -3.6750e-01,\n",
       "        -3.9128e-01,  6.3324e-03,  3.2161e-01, -4.2472e-01,  3.1954e-03,\n",
       "        -8.1638e-01,  4.3500e-02, -7.2592e-03, -2.6870e-01, -1.9641e-02,\n",
       "        -7.7145e-02,  3.9884e-01,  5.6206e-01,  8.7265e-02,  3.3191e-01,\n",
       "        -1.6589e-02,  1.7489e-02,  4.9950e-02, -4.0167e-01,  1.2930e-01,\n",
       "         5.5091e-01,  6.6280e-03,  3.0802e-01, -9.7849e-02,  1.4942e-01,\n",
       "        -1.5388e-02, -1.5098e-01,  4.6848e-01, -4.9491e-01, -5.6170e-01,\n",
       "        -1.3467e-01,  1.6382e-01,  3.4321e-01,  9.1607e-01,  4.1354e-01,\n",
       "        -8.1195e-02,  4.5796e-01,  1.0327e-01, -9.0666e-02,  3.9845e-01,\n",
       "        -1.7436e-01,  4.2916e-02, -1.7960e-01, -5.1299e-02, -2.1247e-01,\n",
       "        -1.7351e-01,  7.8205e-02, -2.9716e-01, -1.6322e-01, -1.8872e-01,\n",
       "         1.1559e-01,  1.3945e-01, -2.8096e-01,  6.0584e-02,  6.6691e-02,\n",
       "         2.1263e-01,  2.0839e-01,  2.1947e-01,  5.9583e+00, -9.7344e-02,\n",
       "        -1.1845e-02, -3.2400e-02,  2.9534e-01, -4.4499e-01,  3.7119e-02,\n",
       "         5.9394e-02, -1.4633e-01, -4.5080e-01,  3.1574e-01,  2.6790e-01,\n",
       "         2.3094e-01, -7.9702e-02,  2.5965e-01, -3.6542e-02, -1.3294e-01,\n",
       "        -1.9662e-01, -8.1305e-02,  1.7207e-01,  8.0910e-03, -1.1548e-01,\n",
       "         1.5894e-01, -1.4847e-01,  1.0886e+00, -4.9367e-03, -1.9686e-01,\n",
       "        -6.3750e-02, -2.0864e-01, -3.3620e-02,  2.8638e-01, -2.9131e-01,\n",
       "        -4.9625e-01,  6.2192e-02, -6.0122e-02, -2.0028e-01,  2.9399e-01,\n",
       "         5.6190e-02,  2.9477e-02, -5.3384e-02, -4.5164e-01,  1.9808e-01,\n",
       "         3.2728e-01, -2.1080e-01,  1.5812e-01, -2.3991e-01, -4.8727e-01,\n",
       "         2.5331e+00, -3.2778e-01,  3.3084e-01,  8.7465e-02, -7.9441e-02,\n",
       "        -8.0000e-02, -1.3111e-01, -4.0113e-02,  1.1533e-01, -1.6333e-01,\n",
       "        -1.6302e-01,  1.2326e-01, -5.9064e-02,  6.9571e-02,  8.8359e-02,\n",
       "        -6.1890e-01, -1.7820e-02, -4.5770e-01,  2.7920e-01, -4.2677e-05,\n",
       "        -1.5460e-01,  1.6484e-01, -8.3067e-01,  3.4208e-01,  2.4214e-01,\n",
       "        -3.8160e-01,  7.4445e-02, -1.9473e+00,  4.0085e-01,  2.6107e-03,\n",
       "         2.4313e-01,  2.6311e-02,  1.7031e-01, -3.8638e-02, -3.3818e-01,\n",
       "        -1.2920e-01, -7.1459e-02,  5.1937e-01,  1.0502e-01, -1.8757e-01,\n",
       "         2.0447e-01,  3.2159e-01, -2.7495e-01,  2.8664e-01, -2.2670e-01,\n",
       "        -1.5075e-01, -1.5392e-02, -2.6003e-01, -6.7366e-02,  1.7465e-01,\n",
       "        -4.1054e-02, -1.9121e-01, -2.3577e-01,  4.1764e-01,  2.7649e-01,\n",
       "        -6.5901e-02, -1.7798e-01,  2.1882e-02,  4.7199e-01,  7.4936e-01,\n",
       "        -7.9934e-02,  2.5213e-01,  9.4877e-02, -9.6222e-02,  4.3018e-02,\n",
       "        -3.5052e-01, -2.0538e-01, -4.1237e-02,  2.2269e-01,  2.7501e-01,\n",
       "        -4.5480e-01, -8.8959e-02,  1.3101e-01,  1.1854e-01, -1.2701e-01,\n",
       "        -3.8450e-01,  1.4339e-02, -4.3462e-01, -4.0530e-01, -9.8764e-02,\n",
       "        -4.1048e-01, -1.0629e-01, -1.2877e-01, -1.6393e-01, -3.3398e-01,\n",
       "         3.7360e-01, -4.4224e-02, -1.8027e-01, -1.7306e-01,  2.6395e-01,\n",
       "        -1.3614e-01,  2.2732e-03, -8.6429e-03, -2.2215e-01,  2.9193e-01,\n",
       "         7.1176e-02, -2.9324e-02,  9.5116e-02, -2.3337e-01, -4.6791e-01,\n",
       "         2.9552e-01,  7.6263e-01,  1.2574e-01,  2.8395e-02,  3.6719e-01,\n",
       "         8.6094e-01,  1.6650e-01, -1.0006e-01, -4.2537e-01, -1.3057e-01,\n",
       "         1.5550e-02, -2.3669e-01, -1.2460e+00, -1.9309e-01, -1.4790e-01,\n",
       "         2.5760e-01, -3.1509e+00,  3.9029e-01,  1.6648e-01, -1.5511e-01,\n",
       "        -9.2267e-02,  1.8439e-01,  3.6567e-02, -7.7467e-02,  3.6813e-01,\n",
       "        -4.7977e-01, -4.7494e-02, -4.7527e-01, -4.8864e-02, -4.8356e-02,\n",
       "         2.5507e-01, -4.4813e-01,  2.3564e-01, -1.2059e-01, -2.0477e-01,\n",
       "        -1.2504e-02,  1.2588e-01, -1.5025e-01,  6.4780e-02, -1.0362e-01,\n",
       "         2.9969e-01,  6.5917e-01,  3.9747e-01, -1.2095e-01,  3.9952e+00,\n",
       "         2.0772e-01,  3.4756e-01,  3.6382e-01, -1.6808e-01, -3.0417e-01,\n",
       "         3.3594e-01, -8.1430e-01,  8.6207e-03,  1.7435e-01, -2.3136e-01,\n",
       "         3.8029e-02, -1.5382e-01, -4.3187e-01, -3.6664e-01, -2.8631e-01,\n",
       "        -1.7748e-02, -2.7889e-02,  9.0470e-02, -6.8909e-01,  1.1357e-01,\n",
       "         4.6275e-01,  4.3546e-02, -3.6439e-02,  2.9943e-02, -2.1631e-01,\n",
       "        -7.0298e-01, -4.4306e-01,  5.7771e-01, -4.6023e-02, -9.8678e-01,\n",
       "        -1.0090e-01,  2.8863e-01, -5.9122e-01,  1.7593e-01,  1.0409e-01,\n",
       "        -1.1267e-01,  1.0616e-01, -1.6009e-01,  5.2297e-02,  2.3301e-01,\n",
       "        -2.2751e-01,  2.0611e-02, -4.1883e-01, -3.5442e-01, -1.7016e-02,\n",
       "        -1.5741e-01, -4.2651e-01, -1.6736e-01, -3.8105e-01,  3.2924e-01,\n",
       "        -3.1063e-01,  1.7592e-01, -1.4280e-02, -6.6245e-02,  3.3747e-01,\n",
       "         1.2442e-01, -1.9632e-01, -2.5617e-01, -1.4798e-02,  7.0891e-01,\n",
       "        -1.3693e-01,  3.1428e-02,  1.6213e-01,  4.4093e-01, -3.9656e-01,\n",
       "        -9.4637e-02, -1.7004e-01, -9.7996e-02,  1.3358e-01, -2.1960e-01,\n",
       "        -3.9655e-01, -1.8899e+00,  4.6482e-01,  3.8109e-02, -1.4127e-01,\n",
       "        -1.1725e-01, -1.3309e-01,  1.0321e-01, -1.8469e-01,  2.8603e-01,\n",
       "         1.8268e-01,  2.5977e-01,  3.1583e-01,  1.4014e-01, -4.4890e-01,\n",
       "         2.5068e-01, -1.6856e-02,  1.1018e+00, -9.9824e-03, -3.9765e-01,\n",
       "        -5.0902e-01, -1.0307e-01,  2.8159e-01,  1.1057e-01, -3.7504e-01,\n",
       "         4.3605e-01,  1.3974e-01, -2.1019e-01,  1.8067e-01,  9.8000e-03,\n",
       "         5.5085e-01, -1.5598e-01, -1.9031e-01, -2.6892e-01, -3.6769e-01,\n",
       "        -5.1667e-02, -3.3363e-02,  1.1299e-02,  5.8907e-01,  1.8741e-01,\n",
       "        -3.1693e-01,  2.9613e-01,  1.4450e-01, -4.0647e-02,  4.2288e-02,\n",
       "         3.6653e-01,  1.2616e-01, -3.2860e-01, -1.0519e+00,  4.2975e-02,\n",
       "        -3.1935e-01, -1.4577e-01, -5.3905e-01,  1.5981e-01,  2.4747e-01,\n",
       "         2.3883e-01,  4.0672e-01, -1.5679e-01,  3.0330e-01,  1.6096e-02,\n",
       "         2.1308e-01,  7.6938e-02, -1.9118e-01,  6.4088e-02, -5.3771e-01,\n",
       "         2.9274e-01, -2.3624e-02, -4.6418e-01,  1.2255e-01,  4.2044e-02,\n",
       "        -4.9718e-01, -2.2280e-01,  2.3505e-01, -1.5908e-01, -4.0784e-01,\n",
       "        -3.6357e-01,  5.7035e-02, -1.7855e-01, -3.0057e-01,  4.8147e+00,\n",
       "        -4.8671e-01,  4.9361e-01,  1.9862e-01, -1.2134e-01, -1.4010e-01,\n",
       "         7.4349e-02, -1.2104e-01,  9.1511e-01, -2.1573e-01, -6.3340e-02,\n",
       "        -6.5185e-01,  2.1448e-01,  1.2659e-01, -3.4797e-01,  4.2923e-01,\n",
       "         8.0223e-02, -6.0715e-02, -3.0275e-02, -6.5153e-01, -4.9681e-02,\n",
       "        -3.3713e-01,  1.3827e-01, -1.4791e-01,  5.0011e-01,  3.1670e-01,\n",
       "        -1.7194e-01, -1.8313e-01, -2.7986e-01, -2.9287e-02, -5.8853e-01,\n",
       "         4.7260e-01,  3.0847e-01,  1.3734e-01, -7.0342e-02, -2.4027e-01,\n",
       "         1.6711e-01,  1.3177e-01,  2.3567e-01, -7.4628e-03,  7.7966e-02,\n",
       "        -1.6594e-02,  7.1786e-01,  6.1311e-02,  3.5798e-01,  4.1912e-01,\n",
       "         1.1117e-01,  1.9578e-02,  1.9777e-01,  4.9200e-01, -1.6749e-01,\n",
       "         6.4143e-02,  4.2801e-02, -3.9856e-01,  8.5342e-02,  2.3863e-01,\n",
       "        -7.7880e-02, -4.2924e-01,  2.9176e-01,  2.0381e-01, -6.1984e-02,\n",
       "        -9.2818e-02, -3.7880e-01,  2.3460e-02, -1.2960e-01, -3.9881e-01,\n",
       "         4.7126e-01, -2.1201e-01,  2.5346e-01, -3.1382e-01, -1.1686e-01,\n",
       "        -1.2509e-01, -6.7483e-01,  9.1491e-02,  1.9159e-01, -3.5051e-03,\n",
       "        -6.0814e-01,  9.2888e-03, -1.6188e-01, -6.6355e-02, -1.9919e-01,\n",
       "         1.9347e-01, -2.0049e-01, -3.5767e-01,  2.9907e-01, -2.2985e-01,\n",
       "        -9.6713e-01, -5.8820e-02,  2.2892e-02,  4.2655e-01,  1.4552e-01,\n",
       "        -4.5358e-02,  7.4401e-02, -1.5398e-01, -2.1143e-02, -1.3642e-01,\n",
       "        -4.4854e-01,  2.1592e-01, -1.9863e-01, -8.0210e-02,  4.1195e-01,\n",
       "         2.5769e-01,  3.9754e-01,  2.4976e-01,  2.7691e-01, -2.1657e-01,\n",
       "         7.1023e-02, -8.3307e-02, -9.0690e-02, -3.4582e-02,  4.9591e-01,\n",
       "         8.9904e-02,  3.9867e-03, -1.0844e-01, -2.0857e-01,  1.1273e-01,\n",
       "         1.1706e-01, -2.4674e-01, -7.3247e+00,  2.9290e-01, -6.3859e-02,\n",
       "         1.9705e-01, -2.9634e-01, -2.6639e-01,  4.2589e-01,  4.2104e-01,\n",
       "         3.5663e-02,  3.9136e-01, -2.0552e-01,  1.1738e-01, -1.9566e+00,\n",
       "         5.1983e-01, -1.0835e-01,  1.2019e-01, -7.3637e-02, -9.1325e-01,\n",
       "         5.1875e-02,  7.8767e-01, -1.1261e-01,  9.2622e-03,  1.8451e-01,\n",
       "        -2.1675e-02,  3.3171e-01, -7.8744e-02,  1.8096e-01,  6.4527e-02,\n",
       "         1.1947e-02, -1.5983e-01,  2.1775e-01, -1.4584e-02,  6.5998e-01,\n",
       "         2.3685e-02, -1.7734e-02, -6.7572e-02,  1.9491e-01,  2.9907e-01,\n",
       "         1.7701e-01,  2.1838e-02, -2.2836e-01,  1.7327e-01, -2.6770e-02,\n",
       "         5.2035e-03, -5.7000e-01, -1.3761e-01, -6.0303e-01, -2.2700e+00,\n",
       "         2.4201e-01, -1.6674e-01,  2.3427e-01, -6.4820e-02, -4.2545e-02,\n",
       "        -3.8779e-02, -6.5785e-01,  2.2516e-02, -2.3920e-01, -9.8150e-02,\n",
       "         3.8246e-01, -1.4513e-01, -2.3187e-01, -8.2546e-02,  3.9002e-01,\n",
       "         9.5561e-02, -2.3471e-02,  2.4149e-01, -4.2771e-01, -8.5547e-02,\n",
       "        -4.6934e-02, -5.8198e-02, -2.4009e-01,  2.1110e-02,  1.1704e-01,\n",
       "         1.3025e-01,  8.4316e-02,  1.2769e-01, -1.3716e-01,  4.5981e-02,\n",
       "        -2.6071e-01,  2.5933e-02, -3.9133e-01,  6.4549e-02,  1.8609e-01,\n",
       "         2.3116e-01,  1.3018e-01,  7.1499e-03,  1.3623e-01,  3.2371e-01,\n",
       "        -1.5884e-01, -9.9184e-02,  2.9454e-01,  3.1491e-02,  1.9647e-01,\n",
       "        -2.4653e-04, -2.4623e-01,  2.4469e-01, -2.6285e-01,  1.6534e-01,\n",
       "        -3.9740e-01, -4.6658e-01,  1.4874e-01,  1.5557e-01, -1.4532e-01,\n",
       "        -2.0556e-01, -1.4725e-01, -1.9443e-01,  2.4823e+00,  1.9104e-02,\n",
       "        -1.5080e-01,  3.8613e-02,  8.6687e-02,  2.9021e-01, -2.3004e-01,\n",
       "         1.8321e-02,  1.7618e+00,  1.0067e-01, -2.2675e-01,  7.5831e-03,\n",
       "         3.8657e-02, -5.0813e-02, -3.7062e-01,  5.2478e-01,  9.7300e-02,\n",
       "         2.5556e-01, -2.8044e-01, -9.3699e-03,  3.2395e-01, -3.9104e-01,\n",
       "         4.6522e-01, -5.5576e-02, -1.0181e-01, -2.0128e-01, -1.1570e-01,\n",
       "        -5.4399e-01,  7.8746e-02, -6.4373e-01,  3.7418e-01,  7.8972e-02,\n",
       "        -5.7750e-02,  1.0094e+00, -9.5065e-02,  1.7111e-01,  2.6285e-01,\n",
       "         5.6512e-02,  8.9754e-03, -3.5620e-01, -1.2590e-01, -7.0137e-02,\n",
       "        -7.1432e-01,  4.4468e-01, -2.3739e-01, -1.0051e-01, -1.7916e-01,\n",
       "        -6.0959e-01,  1.3074e-01,  6.9473e-02, -4.5596e-02, -6.3148e-01,\n",
       "         1.0044e-01,  3.9238e-01, -3.8896e-03, -2.8757e-01, -2.1926e-01,\n",
       "         1.8451e-01,  1.6005e-01,  1.0354e-01,  4.5509e-02, -4.7587e-03,\n",
       "         4.4632e-03, -7.5936e-02,  4.1854e-01, -5.5067e-01,  7.4686e-02,\n",
       "         2.8148e-02, -1.1504e-01, -6.4155e-01,  1.3935e-01,  1.6597e-01,\n",
       "        -2.1323e+00, -3.5825e-01,  1.4119e-01, -8.9194e-02, -5.2051e-02,\n",
       "        -3.1872e-01,  4.0992e-01,  1.2950e-01,  4.1786e-01,  2.0556e-01,\n",
       "         1.4412e-01,  1.3656e+00, -7.8694e-02, -2.1906e-01,  1.9554e-03,\n",
       "         3.1055e-02,  3.6197e-01, -1.4234e-01, -2.8314e-01, -8.1316e-01,\n",
       "        -1.8910e-01,  1.2677e+00, -6.6939e-02,  2.7426e-01,  6.2093e-01,\n",
       "         7.2051e-02,  1.0820e-02,  1.7770e-01,  2.8536e-01,  3.1812e-02,\n",
       "        -1.3905e-01,  1.7801e-01, -2.4975e-02,  1.1453e+00, -1.8658e+00,\n",
       "        -1.2671e+00])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(combined_features[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = torch.tensor(labels_numpy).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7613, 1])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.type()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performed with CombinedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.51180837538064\n",
      "Epoch 1/10, Validation Loss: 0.45885537131762627, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 2/10, Training Loss: 0.4391647931237233\n",
      "Epoch 2/10, Validation Loss: 0.43369067538315087, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 3/10, Training Loss: 0.42095061489368674\n",
      "Epoch 3/10, Validation Loss: 0.4212238465421175, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 4/10, Training Loss: 0.4164696148061377\n",
      "Epoch 4/10, Validation Loss: 0.4188422065091695, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 5/10, Training Loss: 0.410205944512147\n",
      "Epoch 5/10, Validation Loss: 0.4260024076122888, Validation Accuracy: 0.799080761654629\n",
      "Epoch 6/10, Training Loss: 0.4071837898118915\n",
      "Epoch 6/10, Validation Loss: 0.4176338863856505, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 7/10, Training Loss: 0.4051137128527083\n",
      "Epoch 7/10, Validation Loss: 0.41878228931058764, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 8/10, Training Loss: 0.40326748947732716\n",
      "Epoch 8/10, Validation Loss: 0.41380079509934203, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 9/10, Training Loss: 0.4021063603636787\n",
      "Epoch 9/10, Validation Loss: 0.42540195800793107, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 10/10, Training Loss: 0.3994318921451415\n",
      "Epoch 10/10, Validation Loss: 0.4150819907754816, Validation Accuracy: 0.8174655285620486\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5047903122316821\n",
      "Epoch 1/10, Validation Loss: 0.47919455385176923, Validation Accuracy: 0.7688772160210111\n",
      "Epoch 2/10, Training Loss: 0.4383465031509011\n",
      "Epoch 2/10, Validation Loss: 0.42211223112819085, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 3/10, Training Loss: 0.42177107497032856\n",
      "Epoch 3/10, Validation Loss: 0.42163641336349605, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 4/10, Training Loss: 0.4177063845019797\n",
      "Epoch 4/10, Validation Loss: 0.4131171401024489, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 5/10, Training Loss: 0.41054035769164404\n",
      "Epoch 5/10, Validation Loss: 0.41057987045984307, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 6/10, Training Loss: 0.40910144625940503\n",
      "Epoch 6/10, Validation Loss: 0.4243191407886163, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 7/10, Training Loss: 0.4050151707892969\n",
      "Epoch 7/10, Validation Loss: 0.40910919457283945, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 8/10, Training Loss: 0.4027728895972094\n",
      "Epoch 8/10, Validation Loss: 0.413549408989505, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 9/10, Training Loss: 0.4007995464396602\n",
      "Epoch 9/10, Validation Loss: 0.41757128588094605, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 10/10, Training Loss: 0.4006431807820096\n",
      "Epoch 10/10, Validation Loss: 0.40900577336588767, Validation Accuracy: 0.8115561391989494\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5062166573064221\n",
      "Epoch 1/10, Validation Loss: 0.4593508302073204, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 2/10, Training Loss: 0.4355525316528761\n",
      "Epoch 2/10, Validation Loss: 0.4389219722315591, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 3/10, Training Loss: 0.4164405436379703\n",
      "Epoch 3/10, Validation Loss: 0.500009304990124, Validation Accuracy: 0.7524622455679579\n",
      "Epoch 4/10, Training Loss: 0.4086509052898705\n",
      "Epoch 4/10, Validation Loss: 0.43440940787927956, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 5/10, Training Loss: 0.40686645430666724\n",
      "Epoch 5/10, Validation Loss: 0.4466883604712199, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 6/10, Training Loss: 0.4034660851138001\n",
      "Epoch 6/10, Validation Loss: 0.43168537129516377, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 7/10, Training Loss: 0.3998991831467338\n",
      "Epoch 7/10, Validation Loss: 0.43331447580136867, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 8/10, Training Loss: 0.39707774570177545\n",
      "Epoch 8/10, Validation Loss: 0.43322044988382236, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 9/10, Training Loss: 0.3956903960321128\n",
      "Epoch 9/10, Validation Loss: 0.4366135279506601, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 10/10, Training Loss: 0.39217929954682124\n",
      "Epoch 10/10, Validation Loss: 0.4382012141770951, Validation Accuracy: 0.8030203545633617\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5102963585826982\n",
      "Epoch 1/10, Validation Loss: 0.4508914202841789, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 2/10, Training Loss: 0.43896338323087203\n",
      "Epoch 2/10, Validation Loss: 0.41759171894707603, Validation Accuracy: 0.8206307490144547\n",
      "Epoch 3/10, Training Loss: 0.4265817469597019\n",
      "Epoch 3/10, Validation Loss: 0.4060112517034508, Validation Accuracy: 0.823915900131406\n",
      "Epoch 4/10, Training Loss: 0.41836781884858926\n",
      "Epoch 4/10, Validation Loss: 0.4022370340078289, Validation Accuracy: 0.8245729303547963\n",
      "Epoch 5/10, Training Loss: 0.41601536781808207\n",
      "Epoch 5/10, Validation Loss: 0.40361742646048204, Validation Accuracy: 0.8193166885676741\n",
      "Epoch 6/10, Training Loss: 0.41287341685550105\n",
      "Epoch 6/10, Validation Loss: 0.40205454209049024, Validation Accuracy: 0.8199737187910644\n",
      "Epoch 7/10, Training Loss: 0.41012266202978886\n",
      "Epoch 7/10, Validation Loss: 0.39895544999830074, Validation Accuracy: 0.8258869908015769\n",
      "Epoch 8/10, Training Loss: 0.4059746410805253\n",
      "Epoch 8/10, Validation Loss: 0.39927472702729766, Validation Accuracy: 0.828515111695138\n",
      "Epoch 9/10, Training Loss: 0.4045377704718216\n",
      "Epoch 9/10, Validation Loss: 0.40143228121374913, Validation Accuracy: 0.828515111695138\n",
      "Epoch 10/10, Training Loss: 0.4024135282463602\n",
      "Epoch 10/10, Validation Loss: 0.3984434281656255, Validation Accuracy: 0.823915900131406\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5133590045094177\n",
      "Epoch 1/10, Validation Loss: 0.46067621176623547, Validation Accuracy: 0.7871222076215506\n",
      "Epoch 2/10, Training Loss: 0.4370931208211919\n",
      "Epoch 2/10, Validation Loss: 0.4291150161499128, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 3/10, Training Loss: 0.4215766136140961\n",
      "Epoch 3/10, Validation Loss: 0.42616409357851714, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 4/10, Training Loss: 0.4155878633690944\n",
      "Epoch 4/10, Validation Loss: 0.42298448319834564, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 5/10, Training Loss: 0.4092602307940014\n",
      "Epoch 5/10, Validation Loss: 0.4216313041278517, Validation Accuracy: 0.7956636005256241\n",
      "Epoch 6/10, Training Loss: 0.4047099902316576\n",
      "Epoch 6/10, Validation Loss: 0.4255737408176455, Validation Accuracy: 0.80946123521682\n",
      "Epoch 7/10, Training Loss: 0.40292430914488675\n",
      "Epoch 7/10, Validation Loss: 0.4283083234742986, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 8/10, Training Loss: 0.3997477861732401\n",
      "Epoch 8/10, Validation Loss: 0.41847424848853604, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 9/10, Training Loss: 0.39844780749692693\n",
      "Epoch 9/10, Validation Loss: 0.4200606202287356, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 10/10, Training Loss: 0.3961394033162534\n",
      "Epoch 10/10, Validation Loss: 0.4233711904880264, Validation Accuracy: 0.8101182654402103\n",
      "Average Validation Accuracy: 0.8132152375791952\n"
     ]
    }
   ],
   "source": [
    "val_accuracies = []\n",
    "for train_idx, val_idx in skf.split(combined_features, labels):\n",
    "    # Create TensorDatasets for the current fold\n",
    "    train_dataset = TensorDataset(torch.tensor(combined_features[train_idx]), torch.tensor(labels_numpy[train_idx].reshape(-1,1), dtype=torch.float32))\n",
    "    val_dataset = TensorDataset(torch.tensor(combined_features[val_idx]), torch.tensor(labels_numpy[val_idx].reshape(-1,1), dtype=torch.float32))\n",
    "\n",
    "    # Create DataLoaders for the current fold\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    # Train and validate your model for the current fold\n",
    "    # Train and validate your model for the current fold and store the validation accuracy\n",
    "    val_accuracy = train_and_validate(train_dataloader, val_dataloader, len(val_dataset))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Calculate the average validation accuracy across all folds\n",
    "average_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "print(f'Average Validation Accuracy: {average_val_accuracy}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performed on CombinedModel but with different epoch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5061437223214177\n",
      "Epoch 1/10, Validation Loss: 0.45030209285582545, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 2/10, Training Loss: 0.4370809833462939\n",
      "Epoch 2/10, Validation Loss: 0.42884213364249124, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 3/10, Training Loss: 0.4221029051547758\n",
      "Epoch 3/10, Validation Loss: 0.42262336943318085, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 4/10, Training Loss: 0.413288775567464\n",
      "Epoch 4/10, Validation Loss: 0.4160624578673178, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 5/10, Training Loss: 0.41199049615640965\n",
      "Epoch 5/10, Validation Loss: 0.4517123924851105, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 6/10, Training Loss: 0.4082318685381744\n",
      "Epoch 6/10, Validation Loss: 0.42018501035362016, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 7/10, Training Loss: 0.4052742184518673\n",
      "Epoch 7/10, Validation Loss: 0.42138958884237326, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 8/10, Training Loss: 0.40371980222817166\n",
      "Epoch 8/10, Validation Loss: 0.4311162475984134, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 9/10, Training Loss: 0.3988658282612487\n",
      "Epoch 9/10, Validation Loss: 0.4145197567788406, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 10/10, Training Loss: 0.39819935993768096\n",
      "Epoch 10/10, Validation Loss: 0.4185918809465713, Validation Accuracy: 0.8089297439264609\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5098644300141516\n",
      "Epoch 1/10, Validation Loss: 0.45013916855239117, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 2/10, Training Loss: 0.43999563688485643\n",
      "Epoch 2/10, Validation Loss: 0.4388618120309258, Validation Accuracy: 0.793827971109652\n",
      "Epoch 3/10, Training Loss: 0.42244985929428747\n",
      "Epoch 3/10, Validation Loss: 0.42783013413323784, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 4/10, Training Loss: 0.41551838830856513\n",
      "Epoch 4/10, Validation Loss: 0.41276764483508016, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 5/10, Training Loss: 0.41316915172447993\n",
      "Epoch 5/10, Validation Loss: 0.40950981719682666, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 6/10, Training Loss: 0.4069222015355594\n",
      "Epoch 6/10, Validation Loss: 0.41087268341664246, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 7/10, Training Loss: 0.4053422162245734\n",
      "Epoch 7/10, Validation Loss: 0.4077332375073776, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 8/10, Training Loss: 0.401175980395063\n",
      "Epoch 8/10, Validation Loss: 0.4103384382281628, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 9/10, Training Loss: 0.402777679978315\n",
      "Epoch 9/10, Validation Loss: 0.4089173639475987, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 10/10, Training Loss: 0.3989961038140722\n",
      "Epoch 10/10, Validation Loss: 0.4124347795074055, Validation Accuracy: 0.8102429415627052\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5091063160243936\n",
      "Epoch 1/10, Validation Loss: 0.4684775933545297, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 2/10, Training Loss: 0.43419691081356815\n",
      "Epoch 2/10, Validation Loss: 0.4438549969052769, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 3/10, Training Loss: 0.4183735863312962\n",
      "Epoch 3/10, Validation Loss: 0.4363560974695452, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 4/10, Training Loss: 0.41016506071244013\n",
      "Epoch 4/10, Validation Loss: 0.4349389362651172, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 5/10, Training Loss: 0.40609771634630487\n",
      "Epoch 5/10, Validation Loss: 0.43351772018947216, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 6/10, Training Loss: 0.4027895687729746\n",
      "Epoch 6/10, Validation Loss: 0.43669989269168275, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 7/10, Training Loss: 0.40175903174938177\n",
      "Epoch 7/10, Validation Loss: 0.43553471366304375, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 8/10, Training Loss: 0.40054690229689355\n",
      "Epoch 8/10, Validation Loss: 0.4336942120976941, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 9/10, Training Loss: 0.3940306129569574\n",
      "Epoch 9/10, Validation Loss: 0.4334005960287692, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 10/10, Training Loss: 0.3955664233331449\n",
      "Epoch 10/10, Validation Loss: 0.4307940567975269, Validation Accuracy: 0.8128693368351937\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5127406066914243\n",
      "Epoch 1/10, Validation Loss: 0.4440327528571583, Validation Accuracy: 0.7917214191852825\n",
      "Epoch 2/10, Training Loss: 0.44047593349820674\n",
      "Epoch 2/10, Validation Loss: 0.42494155965862473, Validation Accuracy: 0.816688567674113\n",
      "Epoch 3/10, Training Loss: 0.426729629456684\n",
      "Epoch 3/10, Validation Loss: 0.40730221056579297, Validation Accuracy: 0.8186596583442839\n",
      "Epoch 4/10, Training Loss: 0.4171575518359193\n",
      "Epoch 4/10, Validation Loss: 0.40265989666365826, Validation Accuracy: 0.8363994743758213\n",
      "Epoch 5/10, Training Loss: 0.4137912251426792\n",
      "Epoch 5/10, Validation Loss: 0.4172936458803752, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 6/10, Training Loss: 0.41153409836564475\n",
      "Epoch 6/10, Validation Loss: 0.40981533893271893, Validation Accuracy: 0.8272010512483574\n",
      "Epoch 7/10, Training Loss: 0.4088235540691949\n",
      "Epoch 7/10, Validation Loss: 0.4134354232981099, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 8/10, Training Loss: 0.4055409875265726\n",
      "Epoch 8/10, Validation Loss: 0.39994502500557777, Validation Accuracy: 0.8265440210249672\n",
      "Epoch 9/10, Training Loss: 0.4046266782060852\n",
      "Epoch 9/10, Validation Loss: 0.3978060394993627, Validation Accuracy: 0.8291721419185283\n",
      "Epoch 10/10, Training Loss: 0.4013333054078533\n",
      "Epoch 10/10, Validation Loss: 0.4333546110063167, Validation Accuracy: 0.80946123521682\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5089702314631207\n",
      "Epoch 1/10, Validation Loss: 0.45955854287634346, Validation Accuracy: 0.7864651773981604\n",
      "Epoch 2/10, Training Loss: 0.4377760331579081\n",
      "Epoch 2/10, Validation Loss: 0.4293559036212754, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 3/10, Training Loss: 0.4199296820058128\n",
      "Epoch 3/10, Validation Loss: 0.42318916905924914, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 4/10, Training Loss: 0.41527796311797743\n",
      "Epoch 4/10, Validation Loss: 0.421414595750692, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 5/10, Training Loss: 0.40970648151487504\n",
      "Epoch 5/10, Validation Loss: 0.4240135230338542, Validation Accuracy: 0.7923784494086727\n",
      "Epoch 6/10, Training Loss: 0.40508377938739115\n",
      "Epoch 6/10, Validation Loss: 0.42363983661872556, Validation Accuracy: 0.7923784494086727\n",
      "Epoch 7/10, Training Loss: 0.4025309871187986\n",
      "Epoch 7/10, Validation Loss: 0.4202793197150474, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 8/10, Training Loss: 0.40079236124444195\n",
      "Epoch 8/10, Validation Loss: 0.4236594310020589, Validation Accuracy: 0.7956636005256241\n",
      "Epoch 9/10, Training Loss: 0.39808321362385757\n",
      "Epoch 9/10, Validation Loss: 0.4259466781276059, Validation Accuracy: 0.7956636005256241\n",
      "Epoch 10/10, Training Loss: 0.3973764266202769\n",
      "Epoch 10/10, Validation Loss: 0.4227499337233018, Validation Accuracy: 0.812089356110381\n",
      "Average Validation Accuracy: 0.8107185227303122\n",
      "Number of Epochs: 10\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/20, Training Loss: 0.5098886874130392\n",
      "Epoch 1/20, Validation Loss: 0.45218163135788203, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 2/20, Training Loss: 0.43682641054936283\n",
      "Epoch 2/20, Validation Loss: 0.4351331986955011, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 3/20, Training Loss: 0.42476428987512127\n",
      "Epoch 3/20, Validation Loss: 0.42360133995638466, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 4/20, Training Loss: 0.4167187486010117\n",
      "Epoch 4/20, Validation Loss: 0.42288189207774185, Validation Accuracy: 0.8069599474720945\n",
      "Epoch 5/20, Training Loss: 0.4110323650825994\n",
      "Epoch 5/20, Validation Loss: 0.4210672357865653, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 6/20, Training Loss: 0.4095418768839573\n",
      "Epoch 6/20, Validation Loss: 0.41706583785449025, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 7/20, Training Loss: 0.4046233558826872\n",
      "Epoch 7/20, Validation Loss: 0.4210591931188606, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 8/20, Training Loss: 0.40289741313559174\n",
      "Epoch 8/20, Validation Loss: 0.4160719601466706, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 9/20, Training Loss: 0.3997094047175148\n",
      "Epoch 9/20, Validation Loss: 0.4202904013907098, Validation Accuracy: 0.8069599474720945\n",
      "Epoch 10/20, Training Loss: 0.3985221290916908\n",
      "Epoch 10/20, Validation Loss: 0.41301443784726855, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 11/20, Training Loss: 0.3965230617926424\n",
      "Epoch 11/20, Validation Loss: 0.41325778598014595, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 12/20, Training Loss: 0.3963992832780979\n",
      "Epoch 12/20, Validation Loss: 0.41577975299813985, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 13/20, Training Loss: 0.39393271688675\n",
      "Epoch 13/20, Validation Loss: 0.43281118320154893, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 14/20, Training Loss: 0.39243863347497354\n",
      "Epoch 14/20, Validation Loss: 0.42231042090198756, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 15/20, Training Loss: 0.39035754641053555\n",
      "Epoch 15/20, Validation Loss: 0.4213150435015169, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 16/20, Training Loss: 0.3891565386900126\n",
      "Epoch 16/20, Validation Loss: 0.4178453499929131, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 17/20, Training Loss: 0.3884300379537222\n",
      "Epoch 17/20, Validation Loss: 0.41400017125132194, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 18/20, Training Loss: 0.38660476310789743\n",
      "Epoch 18/20, Validation Loss: 0.4211671232436028, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 19/20, Training Loss: 0.38637795810174597\n",
      "Epoch 19/20, Validation Loss: 0.41516489763768555, Validation Accuracy: 0.814182534471438\n",
      "Epoch 20/20, Training Loss: 0.3870337591249877\n",
      "Epoch 20/20, Validation Loss: 0.41418992109713754, Validation Accuracy: 0.8154957321076822\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/20, Training Loss: 0.5140005138719802\n",
      "Epoch 1/20, Validation Loss: 0.44570181409569937, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 2/20, Training Loss: 0.4397098060276878\n",
      "Epoch 2/20, Validation Loss: 0.42720407567411195, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 3/20, Training Loss: 0.4248075045527905\n",
      "Epoch 3/20, Validation Loss: 0.41392218924239665, Validation Accuracy: 0.81483913328956\n",
      "Epoch 4/20, Training Loss: 0.41609777644120177\n",
      "Epoch 4/20, Validation Loss: 0.41190563648432027, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 5/20, Training Loss: 0.4114561545762803\n",
      "Epoch 5/20, Validation Loss: 0.4126846070903602, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 6/20, Training Loss: 0.40666290980780845\n",
      "Epoch 6/20, Validation Loss: 0.4260802325982776, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 7/20, Training Loss: 0.40531958495890064\n",
      "Epoch 7/20, Validation Loss: 0.4105444590302662, Validation Accuracy: 0.81483913328956\n",
      "Epoch 8/20, Training Loss: 0.40355941740272866\n",
      "Epoch 8/20, Validation Loss: 0.40829162278178477, Validation Accuracy: 0.814182534471438\n",
      "Epoch 9/20, Training Loss: 0.4012081130038644\n",
      "Epoch 9/20, Validation Loss: 0.43386973455762834, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 10/20, Training Loss: 0.4009987381421362\n",
      "Epoch 10/20, Validation Loss: 0.4084092349652689, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 11/20, Training Loss: 0.39849192745924933\n",
      "Epoch 11/20, Validation Loss: 0.40833717556328986, Validation Accuracy: 0.814182534471438\n",
      "Epoch 12/20, Training Loss: 0.3960115863621391\n",
      "Epoch 12/20, Validation Loss: 0.41689520332162605, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 13/20, Training Loss: 0.39315003398170306\n",
      "Epoch 13/20, Validation Loss: 0.40883261808901245, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 14/20, Training Loss: 0.3928830246453288\n",
      "Epoch 14/20, Validation Loss: 0.4135416771592426, Validation Accuracy: 0.8069599474720945\n",
      "Epoch 15/20, Training Loss: 0.3930636928942338\n",
      "Epoch 15/20, Validation Loss: 0.41637019306928386, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 16/20, Training Loss: 0.38962365550983924\n",
      "Epoch 16/20, Validation Loss: 0.4187114167646432, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 17/20, Training Loss: 0.38868159104598166\n",
      "Epoch 17/20, Validation Loss: 0.40934822578665786, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 18/20, Training Loss: 0.3874478568066293\n",
      "Epoch 18/20, Validation Loss: 0.4120653487293352, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 19/20, Training Loss: 0.3883404487504421\n",
      "Epoch 19/20, Validation Loss: 0.40859974259559395, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 20/20, Training Loss: 0.3846855486383823\n",
      "Epoch 20/20, Validation Loss: 0.4087249620120329, Validation Accuracy: 0.8168089297439265\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/20, Training Loss: 0.5097740265367225\n",
      "Epoch 1/20, Validation Loss: 0.4648945793041384, Validation Accuracy: 0.7846355876559422\n",
      "Epoch 2/20, Training Loss: 0.4360675260893942\n",
      "Epoch 2/20, Validation Loss: 0.4445604750623254, Validation Accuracy: 0.804333552199606\n",
      "Epoch 3/20, Training Loss: 0.41785141309415263\n",
      "Epoch 3/20, Validation Loss: 0.4514597209258229, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 4/20, Training Loss: 0.4142470654207734\n",
      "Epoch 4/20, Validation Loss: 0.4342804110526102, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 5/20, Training Loss: 0.40774280330523105\n",
      "Epoch 5/20, Validation Loss: 0.439917545570597, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 6/20, Training Loss: 0.4035253482931868\n",
      "Epoch 6/20, Validation Loss: 0.4401394187701934, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 7/20, Training Loss: 0.40121510208357036\n",
      "Epoch 7/20, Validation Loss: 0.43428110504883743, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 8/20, Training Loss: 0.39729458862167644\n",
      "Epoch 8/20, Validation Loss: 0.44386015665663786, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 9/20, Training Loss: 0.39444037009607463\n",
      "Epoch 9/20, Validation Loss: 0.4353306513933065, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 10/20, Training Loss: 0.39518141497679427\n",
      "Epoch 10/20, Validation Loss: 0.4315561100216436, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 11/20, Training Loss: 0.3916354094414417\n",
      "Epoch 11/20, Validation Loss: 0.4409386553357877, Validation Accuracy: 0.81483913328956\n",
      "Epoch 12/20, Training Loss: 0.39008871578364546\n",
      "Epoch 12/20, Validation Loss: 0.44376946710225645, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 13/20, Training Loss: 0.38892316465263604\n",
      "Epoch 13/20, Validation Loss: 0.43149503585711824, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 14/20, Training Loss: 0.3863280120787267\n",
      "Epoch 14/20, Validation Loss: 0.4419110866302517, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 15/20, Training Loss: 0.38668771569673316\n",
      "Epoch 15/20, Validation Loss: 0.4489834150738273, Validation Accuracy: 0.788575180564675\n",
      "Epoch 16/20, Training Loss: 0.3864155536776609\n",
      "Epoch 16/20, Validation Loss: 0.4475794579024324, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 17/20, Training Loss: 0.3827178574550965\n",
      "Epoch 17/20, Validation Loss: 0.4399591473111619, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 18/20, Training Loss: 0.38341470572637915\n",
      "Epoch 18/20, Validation Loss: 0.46823659989280697, Validation Accuracy: 0.7728168089297439\n",
      "Epoch 19/20, Training Loss: 0.38041693365734236\n",
      "Epoch 19/20, Validation Loss: 0.43439296572054714, Validation Accuracy: 0.814182534471438\n",
      "Epoch 20/20, Training Loss: 0.3798266772493681\n",
      "Epoch 20/20, Validation Loss: 0.43335886707734217, Validation Accuracy: 0.8168089297439265\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/20, Training Loss: 0.5115267883722238\n",
      "Epoch 1/20, Validation Loss: 0.44964951514729656, Validation Accuracy: 0.790407358738502\n",
      "Epoch 2/20, Training Loss: 0.44048398316610515\n",
      "Epoch 2/20, Validation Loss: 0.4284219962413086, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 3/20, Training Loss: 0.4268551300966677\n",
      "Epoch 3/20, Validation Loss: 0.4113219170904284, Validation Accuracy: 0.8219448094612353\n",
      "Epoch 4/20, Training Loss: 0.42048540700647463\n",
      "Epoch 4/20, Validation Loss: 0.418159979059122, Validation Accuracy: 0.8199737187910644\n",
      "Epoch 5/20, Training Loss: 0.4173002250130799\n",
      "Epoch 5/20, Validation Loss: 0.4014328353165488, Validation Accuracy: 0.8265440210249672\n",
      "Epoch 6/20, Training Loss: 0.4111538042663902\n",
      "Epoch 6/20, Validation Loss: 0.3998800742961661, Validation Accuracy: 0.8298291721419185\n",
      "Epoch 7/20, Training Loss: 0.4086226990539336\n",
      "Epoch 7/20, Validation Loss: 0.4112754118926238, Validation Accuracy: 0.8232588699080158\n",
      "Epoch 8/20, Training Loss: 0.40638517800552326\n",
      "Epoch 8/20, Validation Loss: 0.398610305782232, Validation Accuracy: 0.8219448094612353\n",
      "Epoch 9/20, Training Loss: 0.40335976510379573\n",
      "Epoch 9/20, Validation Loss: 0.3999139614383744, Validation Accuracy: 0.8219448094612353\n",
      "Epoch 10/20, Training Loss: 0.40453158751169216\n",
      "Epoch 10/20, Validation Loss: 0.4136200801064675, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 11/20, Training Loss: 0.40001642115394587\n",
      "Epoch 11/20, Validation Loss: 0.4020113641132859, Validation Accuracy: 0.8193166885676741\n",
      "Epoch 12/20, Training Loss: 0.39972346522442\n",
      "Epoch 12/20, Validation Loss: 0.40453517212683615, Validation Accuracy: 0.8252299605781866\n",
      "Epoch 13/20, Training Loss: 0.396449296141234\n",
      "Epoch 13/20, Validation Loss: 0.40022319389497424, Validation Accuracy: 0.831143232588699\n",
      "Epoch 14/20, Training Loss: 0.3966815198803433\n",
      "Epoch 14/20, Validation Loss: 0.4000088354640918, Validation Accuracy: 0.828515111695138\n",
      "Epoch 15/20, Training Loss: 0.39379067795248485\n",
      "Epoch 15/20, Validation Loss: 0.4032629783026367, Validation Accuracy: 0.8304862023653088\n",
      "Epoch 16/20, Training Loss: 0.39502013168661926\n",
      "Epoch 16/20, Validation Loss: 0.3963166341692677, Validation Accuracy: 0.8212877792378449\n",
      "Epoch 17/20, Training Loss: 0.39146759309207046\n",
      "Epoch 17/20, Validation Loss: 0.3962899005791436, Validation Accuracy: 0.8232588699080158\n",
      "Epoch 18/20, Training Loss: 0.3927996536213269\n",
      "Epoch 18/20, Validation Loss: 0.41380642262818923, Validation Accuracy: 0.8186596583442839\n",
      "Epoch 19/20, Training Loss: 0.3888450737729708\n",
      "Epoch 19/20, Validation Loss: 0.3966672351944665, Validation Accuracy: 0.8278580814717477\n",
      "Epoch 20/20, Training Loss: 0.3896551882833477\n",
      "Epoch 20/20, Validation Loss: 0.39651452001008686, Validation Accuracy: 0.831143232588699\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/20, Training Loss: 0.5122218308212563\n",
      "Epoch 1/20, Validation Loss: 0.45665620411721825, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 2/20, Training Loss: 0.4369664826183494\n",
      "Epoch 2/20, Validation Loss: 0.4285254679152167, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 3/20, Training Loss: 0.4201838364849097\n",
      "Epoch 3/20, Validation Loss: 0.4403513874761097, Validation Accuracy: 0.7890932982917214\n",
      "Epoch 4/20, Training Loss: 0.4135945289740412\n",
      "Epoch 4/20, Validation Loss: 0.42626411208385573, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 5/20, Training Loss: 0.40834633348964333\n",
      "Epoch 5/20, Validation Loss: 0.42469966486681504, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 6/20, Training Loss: 0.40581658187266095\n",
      "Epoch 6/20, Validation Loss: 0.4258727119621182, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 7/20, Training Loss: 0.404097807102316\n",
      "Epoch 7/20, Validation Loss: 0.4295934944350214, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 8/20, Training Loss: 0.4007999979526665\n",
      "Epoch 8/20, Validation Loss: 0.4261901255755524, Validation Accuracy: 0.8147174770039421\n",
      "Epoch 9/20, Training Loss: 0.398472822415508\n",
      "Epoch 9/20, Validation Loss: 0.41929806070646064, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 10/20, Training Loss: 0.39819087180995877\n",
      "Epoch 10/20, Validation Loss: 0.42200672118412574, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 11/20, Training Loss: 0.3953661074143226\n",
      "Epoch 11/20, Validation Loss: 0.41893222051336193, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 12/20, Training Loss: 0.39126926396051886\n",
      "Epoch 12/20, Validation Loss: 0.4223653018981686, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 13/20, Training Loss: 0.3911647469861301\n",
      "Epoch 13/20, Validation Loss: 0.4404968150272107, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 14/20, Training Loss: 0.3922591518874713\n",
      "Epoch 14/20, Validation Loss: 0.4234304881474267, Validation Accuracy: 0.80946123521682\n",
      "Epoch 15/20, Training Loss: 0.38851891659454413\n",
      "Epoch 15/20, Validation Loss: 0.4193770115834256, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 16/20, Training Loss: 0.3883580081800385\n",
      "Epoch 16/20, Validation Loss: 0.4206197816117896, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 17/20, Training Loss: 0.3861742780893415\n",
      "Epoch 17/20, Validation Loss: 0.42430712259252656, Validation Accuracy: 0.80946123521682\n",
      "Epoch 18/20, Training Loss: 0.38586555655038574\n",
      "Epoch 18/20, Validation Loss: 0.4199307022996598, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 19/20, Training Loss: 0.3843038277187216\n",
      "Epoch 19/20, Validation Loss: 0.42985387984175644, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 20/20, Training Loss: 0.38225863276054384\n",
      "Epoch 20/20, Validation Loss: 0.4255119532990362, Validation Accuracy: 0.8061760840998686\n",
      "Average Validation Accuracy: 0.8172865816568204\n",
      "Number of Epochs: 20\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/30, Training Loss: 0.5076653273517066\n",
      "Epoch 1/30, Validation Loss: 0.46213665425153305, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 2/30, Training Loss: 0.43688381153337286\n",
      "Epoch 2/30, Validation Loss: 0.4344797021665498, Validation Accuracy: 0.81483913328956\n",
      "Epoch 3/30, Training Loss: 0.4217339819126085\n",
      "Epoch 3/30, Validation Loss: 0.4213303136809958, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 4/30, Training Loss: 0.4138850897667915\n",
      "Epoch 4/30, Validation Loss: 0.4178169002434658, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 5/30, Training Loss: 0.41325183019159345\n",
      "Epoch 5/30, Validation Loss: 0.4170464354698883, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 6/30, Training Loss: 0.40554080929929814\n",
      "Epoch 6/30, Validation Loss: 0.4144047992937852, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 7/30, Training Loss: 0.4033152087007373\n",
      "Epoch 7/30, Validation Loss: 0.42605360685140675, Validation Accuracy: 0.8220617202889035\n",
      "Epoch 8/30, Training Loss: 0.4016832627424496\n",
      "Epoch 8/30, Validation Loss: 0.43105809548528407, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 9/30, Training Loss: 0.39955140300231967\n",
      "Epoch 9/30, Validation Loss: 0.4314546324897811, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 10/30, Training Loss: 0.3969246398931335\n",
      "Epoch 10/30, Validation Loss: 0.42748365061679433, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 11/30, Training Loss: 0.3982467169523865\n",
      "Epoch 11/30, Validation Loss: 0.42022431253684756, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 12/30, Training Loss: 0.3952798642012782\n",
      "Epoch 12/30, Validation Loss: 0.41718482074001073, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 13/30, Training Loss: 0.3935925342103471\n",
      "Epoch 13/30, Validation Loss: 0.41435955655980483, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 14/30, Training Loss: 0.39280089197724355\n",
      "Epoch 14/30, Validation Loss: 0.4125900560141546, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 15/30, Training Loss: 0.39040708897288234\n",
      "Epoch 15/30, Validation Loss: 0.4129031693358072, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 16/30, Training Loss: 0.39002141273846935\n",
      "Epoch 16/30, Validation Loss: 0.4133879424740819, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 17/30, Training Loss: 0.38765306463782867\n",
      "Epoch 17/30, Validation Loss: 0.47372929257443125, Validation Accuracy: 0.7734734077478661\n",
      "Epoch 18/30, Training Loss: 0.3869937700940555\n",
      "Epoch 18/30, Validation Loss: 0.41361096745152126, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 19/30, Training Loss: 0.3856639158753116\n",
      "Epoch 19/30, Validation Loss: 0.4198241589971238, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 20/30, Training Loss: 0.3831197815773681\n",
      "Epoch 20/30, Validation Loss: 0.41927855532050756, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 21/30, Training Loss: 0.3828953088913846\n",
      "Epoch 21/30, Validation Loss: 0.4166473795840253, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 22/30, Training Loss: 0.38256363522779596\n",
      "Epoch 22/30, Validation Loss: 0.4138009166686323, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 23/30, Training Loss: 0.37984697126692984\n",
      "Epoch 23/30, Validation Loss: 0.41616762911227984, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 24/30, Training Loss: 0.38190378912595\n",
      "Epoch 24/30, Validation Loss: 0.41317676519731267, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 25/30, Training Loss: 0.38038163726997815\n",
      "Epoch 25/30, Validation Loss: 0.4175362322694032, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 26/30, Training Loss: 0.378124443271498\n",
      "Epoch 26/30, Validation Loss: 0.4161280258339269, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 27/30, Training Loss: 0.37788959305606334\n",
      "Epoch 27/30, Validation Loss: 0.416897255888316, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 28/30, Training Loss: 0.37821570656743886\n",
      "Epoch 28/30, Validation Loss: 0.413753868417122, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 29/30, Training Loss: 0.3781953517132466\n",
      "Epoch 29/30, Validation Loss: 0.4158252112430896, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 30/30, Training Loss: 0.3775318111647458\n",
      "Epoch 30/30, Validation Loss: 0.4146443798221375, Validation Accuracy: 0.8200919238345371\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/30, Training Loss: 0.5143905000228268\n",
      "Epoch 1/30, Validation Loss: 0.45435434451121937, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 2/30, Training Loss: 0.440004650474064\n",
      "Epoch 2/30, Validation Loss: 0.42495234197502985, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 3/30, Training Loss: 0.4246516477052621\n",
      "Epoch 3/30, Validation Loss: 0.41728841646998655, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 4/30, Training Loss: 0.4168246694671826\n",
      "Epoch 4/30, Validation Loss: 0.41118909069458853, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 5/30, Training Loss: 0.41274285212824036\n",
      "Epoch 5/30, Validation Loss: 0.41777729537552566, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 6/30, Training Loss: 0.4071843321642929\n",
      "Epoch 6/30, Validation Loss: 0.41000077695980747, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 7/30, Training Loss: 0.40569065835845125\n",
      "Epoch 7/30, Validation Loss: 0.4088865952829572, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 8/30, Training Loss: 0.40299729158089853\n",
      "Epoch 8/30, Validation Loss: 0.41082759722287115, Validation Accuracy: 0.814182534471438\n",
      "Epoch 9/30, Training Loss: 0.39864918401860816\n",
      "Epoch 9/30, Validation Loss: 0.4099864626976208, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 10/30, Training Loss: 0.3990173121166276\n",
      "Epoch 10/30, Validation Loss: 0.4089542862944578, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 11/30, Training Loss: 0.3995425641644267\n",
      "Epoch 11/30, Validation Loss: 0.40967252404862986, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 12/30, Training Loss: 0.394839424327055\n",
      "Epoch 12/30, Validation Loss: 0.41610488030786447, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 13/30, Training Loss: 0.3918111012891678\n",
      "Epoch 13/30, Validation Loss: 0.4135826656994707, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 14/30, Training Loss: 0.39144567763946186\n",
      "Epoch 14/30, Validation Loss: 0.41750631444838815, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 15/30, Training Loss: 0.39170268655136187\n",
      "Epoch 15/30, Validation Loss: 0.41022831955388267, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 16/30, Training Loss: 0.3894657951552333\n",
      "Epoch 16/30, Validation Loss: 0.41345171409498177, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 17/30, Training Loss: 0.3888766973027642\n",
      "Epoch 17/30, Validation Loss: 0.40917932288965003, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 18/30, Training Loss: 0.38870164660585366\n",
      "Epoch 18/30, Validation Loss: 0.41140571619866717, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 19/30, Training Loss: 0.3848151097519035\n",
      "Epoch 19/30, Validation Loss: 0.4212509389206065, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 20/30, Training Loss: 0.3858596626962498\n",
      "Epoch 20/30, Validation Loss: 0.4083738441028052, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 21/30, Training Loss: 0.38709466087966765\n",
      "Epoch 21/30, Validation Loss: 0.43832285924575715, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 22/30, Training Loss: 0.38288589865164807\n",
      "Epoch 22/30, Validation Loss: 0.4115634158117141, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 23/30, Training Loss: 0.38233111998227637\n",
      "Epoch 23/30, Validation Loss: 0.4127929762239856, Validation Accuracy: 0.8069599474720945\n",
      "Epoch 24/30, Training Loss: 0.3836071955631646\n",
      "Epoch 24/30, Validation Loss: 0.4091769457204726, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 25/30, Training Loss: 0.3820650452684386\n",
      "Epoch 25/30, Validation Loss: 0.411604733806084, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 26/30, Training Loss: 0.38138093162337783\n",
      "Epoch 26/30, Validation Loss: 0.4099383013449726, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 27/30, Training Loss: 0.37974969749864473\n",
      "Epoch 27/30, Validation Loss: 0.4112309490023327, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 28/30, Training Loss: 0.38064832200743554\n",
      "Epoch 28/30, Validation Loss: 0.41659952241303255, Validation Accuracy: 0.799080761654629\n",
      "Epoch 29/30, Training Loss: 0.3781344198873584\n",
      "Epoch 29/30, Validation Loss: 0.41081930331261685, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 30/30, Training Loss: 0.3787130171877975\n",
      "Epoch 30/30, Validation Loss: 0.41235434295151246, Validation Accuracy: 0.8102429415627052\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/30, Training Loss: 0.5043056749413646\n",
      "Epoch 1/30, Validation Loss: 0.4644974848518821, Validation Accuracy: 0.7806959947472094\n",
      "Epoch 2/30, Training Loss: 0.4346051074056018\n",
      "Epoch 2/30, Validation Loss: 0.44144739046770864, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 3/30, Training Loss: 0.41718321510656614\n",
      "Epoch 3/30, Validation Loss: 0.44398039424333585, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 4/30, Training Loss: 0.41024220994920557\n",
      "Epoch 4/30, Validation Loss: 0.46793114019470067, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 5/30, Training Loss: 0.4071963688950213\n",
      "Epoch 5/30, Validation Loss: 0.44777409447581357, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 6/30, Training Loss: 0.40310927337705305\n",
      "Epoch 6/30, Validation Loss: 0.4332506821944295, Validation Accuracy: 0.81483913328956\n",
      "Epoch 7/30, Training Loss: 0.3987303121294093\n",
      "Epoch 7/30, Validation Loss: 0.4406431702048523, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 8/30, Training Loss: 0.3977032018986743\n",
      "Epoch 8/30, Validation Loss: 0.4322838258115253, Validation Accuracy: 0.8069599474720945\n",
      "Epoch 9/30, Training Loss: 0.3953776331398431\n",
      "Epoch 9/30, Validation Loss: 0.43216807404971874, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 10/30, Training Loss: 0.39154026555166316\n",
      "Epoch 10/30, Validation Loss: 0.44338659157108573, Validation Accuracy: 0.799080761654629\n",
      "Epoch 11/30, Training Loss: 0.39264419948647966\n",
      "Epoch 11/30, Validation Loss: 0.44646989355224587, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 12/30, Training Loss: 0.39125163674237223\n",
      "Epoch 12/30, Validation Loss: 0.4315373249429995, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 13/30, Training Loss: 0.3874789407559893\n",
      "Epoch 13/30, Validation Loss: 0.43296087356723106, Validation Accuracy: 0.81483913328956\n",
      "Epoch 14/30, Training Loss: 0.3873127260370048\n",
      "Epoch 14/30, Validation Loss: 0.4324335713544129, Validation Accuracy: 0.81483913328956\n",
      "Epoch 15/30, Training Loss: 0.3860932778410633\n",
      "Epoch 15/30, Validation Loss: 0.4341969634967013, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 16/30, Training Loss: 0.38497169096306394\n",
      "Epoch 16/30, Validation Loss: 0.4557266947642671, Validation Accuracy: 0.814182534471438\n",
      "Epoch 17/30, Training Loss: 0.38491048029284153\n",
      "Epoch 17/30, Validation Loss: 0.44032828196278573, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 18/30, Training Loss: 0.3827653496997954\n",
      "Epoch 18/30, Validation Loss: 0.431505167642267, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 19/30, Training Loss: 0.3818660501605804\n",
      "Epoch 19/30, Validation Loss: 0.4484466757157242, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 20/30, Training Loss: 0.3798481419125176\n",
      "Epoch 20/30, Validation Loss: 0.43105857896360117, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 21/30, Training Loss: 0.379539121910343\n",
      "Epoch 21/30, Validation Loss: 0.43083486783059793, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 22/30, Training Loss: 0.37791017472763544\n",
      "Epoch 22/30, Validation Loss: 0.4329723929449994, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 23/30, Training Loss: 0.37597222094304295\n",
      "Epoch 23/30, Validation Loss: 0.4319528057508132, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 24/30, Training Loss: 0.377316677390434\n",
      "Epoch 24/30, Validation Loss: 0.4469386146974345, Validation Accuracy: 0.8220617202889035\n",
      "Epoch 25/30, Training Loss: 0.3766984115220274\n",
      "Epoch 25/30, Validation Loss: 0.4425362806611192, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 26/30, Training Loss: 0.37423203753556794\n",
      "Epoch 26/30, Validation Loss: 0.43796032963135323, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 27/30, Training Loss: 0.37329319841045094\n",
      "Epoch 27/30, Validation Loss: 0.44503619798815064, Validation Accuracy: 0.793827971109652\n",
      "Epoch 28/30, Training Loss: 0.3744260191995641\n",
      "Epoch 28/30, Validation Loss: 0.4464529115141062, Validation Accuracy: 0.8069599474720945\n",
      "Epoch 29/30, Training Loss: 0.3734772038056938\n",
      "Epoch 29/30, Validation Loss: 0.43810653058490207, Validation Accuracy: 0.8069599474720945\n",
      "Epoch 30/30, Training Loss: 0.37311330803833764\n",
      "Epoch 30/30, Validation Loss: 0.4860912576678614, Validation Accuracy: 0.7649376231122784\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/30, Training Loss: 0.5054973669721698\n",
      "Epoch 1/30, Validation Loss: 0.4389764403251453, Validation Accuracy: 0.797634691195795\n",
      "Epoch 2/30, Training Loss: 0.44021676334105136\n",
      "Epoch 2/30, Validation Loss: 0.41772187647473125, Validation Accuracy: 0.80946123521682\n",
      "Epoch 3/30, Training Loss: 0.42701296997195465\n",
      "Epoch 3/30, Validation Loss: 0.43802065351558606, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 4/30, Training Loss: 0.4180382244640917\n",
      "Epoch 4/30, Validation Loss: 0.4091214459408952, Validation Accuracy: 0.8232588699080158\n",
      "Epoch 5/30, Training Loss: 0.41370935531777975\n",
      "Epoch 5/30, Validation Loss: 0.40240659617394675, Validation Accuracy: 0.8318002628120894\n",
      "Epoch 6/30, Training Loss: 0.4110938064617122\n",
      "Epoch 6/30, Validation Loss: 0.4036026625011448, Validation Accuracy: 0.8265440210249672\n",
      "Epoch 7/30, Training Loss: 0.40879638236886245\n",
      "Epoch 7/30, Validation Loss: 0.39988736802448777, Validation Accuracy: 0.8304862023653088\n",
      "Epoch 8/30, Training Loss: 0.4057262241742586\n",
      "Epoch 8/30, Validation Loss: 0.3993684964751854, Validation Accuracy: 0.8331143232588699\n",
      "Epoch 9/30, Training Loss: 0.4058351037715833\n",
      "Epoch 9/30, Validation Loss: 0.3993908440430907, Validation Accuracy: 0.8304862023653088\n",
      "Epoch 10/30, Training Loss: 0.4019597280193658\n",
      "Epoch 10/30, Validation Loss: 0.3982427105483116, Validation Accuracy: 0.823915900131406\n",
      "Epoch 11/30, Training Loss: 0.40187958318965017\n",
      "Epoch 11/30, Validation Loss: 0.4026692264581694, Validation Accuracy: 0.8278580814717477\n",
      "Epoch 12/30, Training Loss: 0.39741695738761756\n",
      "Epoch 12/30, Validation Loss: 0.4080212761877173, Validation Accuracy: 0.8147174770039421\n",
      "Epoch 13/30, Training Loss: 0.39686181471533977\n",
      "Epoch 13/30, Validation Loss: 0.4002640320485487, Validation Accuracy: 0.8304862023653088\n",
      "Epoch 14/30, Training Loss: 0.3961595728592532\n",
      "Epoch 14/30, Validation Loss: 0.40992208673613856, Validation Accuracy: 0.8232588699080158\n",
      "Epoch 15/30, Training Loss: 0.39401575027331903\n",
      "Epoch 15/30, Validation Loss: 0.4144479869157856, Validation Accuracy: 0.8193166885676741\n",
      "Epoch 16/30, Training Loss: 0.3935009880807847\n",
      "Epoch 16/30, Validation Loss: 0.39689571855111894, Validation Accuracy: 0.8226018396846255\n",
      "Epoch 17/30, Training Loss: 0.3903681066209876\n",
      "Epoch 17/30, Validation Loss: 0.3994905870914927, Validation Accuracy: 0.8298291721419185\n",
      "Epoch 18/30, Training Loss: 0.3921148690915718\n",
      "Epoch 18/30, Validation Loss: 0.3979693565576176, Validation Accuracy: 0.8298291721419185\n",
      "Epoch 19/30, Training Loss: 0.3907029527603719\n",
      "Epoch 19/30, Validation Loss: 0.3959077964707507, Validation Accuracy: 0.8258869908015769\n",
      "Epoch 20/30, Training Loss: 0.39035023344568226\n",
      "Epoch 20/30, Validation Loss: 0.3993979863120311, Validation Accuracy: 0.8291721419185283\n",
      "Epoch 21/30, Training Loss: 0.3882643200574428\n",
      "Epoch 21/30, Validation Loss: 0.39748337754677415, Validation Accuracy: 0.831143232588699\n",
      "Epoch 22/30, Training Loss: 0.3882803518100204\n",
      "Epoch 22/30, Validation Loss: 0.4030447627529892, Validation Accuracy: 0.831143232588699\n",
      "Epoch 23/30, Training Loss: 0.38527803433927027\n",
      "Epoch 23/30, Validation Loss: 0.406122565240214, Validation Accuracy: 0.8226018396846255\n",
      "Epoch 24/30, Training Loss: 0.384046085824178\n",
      "Epoch 24/30, Validation Loss: 0.436942203175179, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 25/30, Training Loss: 0.3870516922227119\n",
      "Epoch 25/30, Validation Loss: 0.4028315118743175, Validation Accuracy: 0.8291721419185283\n",
      "Epoch 26/30, Training Loss: 0.3835218142170527\n",
      "Epoch 26/30, Validation Loss: 0.39756036145095736, Validation Accuracy: 0.8272010512483574\n",
      "Epoch 27/30, Training Loss: 0.3861522495922611\n",
      "Epoch 27/30, Validation Loss: 0.3979917458936338, Validation Accuracy: 0.8245729303547963\n",
      "Epoch 28/30, Training Loss: 0.38180111655647675\n",
      "Epoch 28/30, Validation Loss: 0.40421334520489444, Validation Accuracy: 0.8245729303547963\n",
      "Epoch 29/30, Training Loss: 0.3818761219424526\n",
      "Epoch 29/30, Validation Loss: 0.3968232914620123, Validation Accuracy: 0.8219448094612353\n",
      "Epoch 30/30, Training Loss: 0.38120231353078926\n",
      "Epoch 30/30, Validation Loss: 0.4003446717156556, Validation Accuracy: 0.823915900131406\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/30, Training Loss: 0.5074394686132904\n",
      "Epoch 1/30, Validation Loss: 0.4764628096322739, Validation Accuracy: 0.778580814717477\n",
      "Epoch 2/30, Training Loss: 0.434888367186694\n",
      "Epoch 2/30, Validation Loss: 0.43582553730507173, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 3/30, Training Loss: 0.4210550762282738\n",
      "Epoch 3/30, Validation Loss: 0.4225036009404984, Validation Accuracy: 0.7950065703022339\n",
      "Epoch 4/30, Training Loss: 0.4158011080447848\n",
      "Epoch 4/30, Validation Loss: 0.4296689015954577, Validation Accuracy: 0.80946123521682\n",
      "Epoch 5/30, Training Loss: 0.4103063130873473\n",
      "Epoch 5/30, Validation Loss: 0.42566916855607984, Validation Accuracy: 0.80946123521682\n",
      "Epoch 6/30, Training Loss: 0.40650489800695205\n",
      "Epoch 6/30, Validation Loss: 0.4282133984745173, Validation Accuracy: 0.7923784494086727\n",
      "Epoch 7/30, Training Loss: 0.4031765454123652\n",
      "Epoch 7/30, Validation Loss: 0.4233262435733024, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 8/30, Training Loss: 0.39957169095284045\n",
      "Epoch 8/30, Validation Loss: 0.4344195702371641, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 9/30, Training Loss: 0.398655263144826\n",
      "Epoch 9/30, Validation Loss: 0.419733211729695, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 10/30, Training Loss: 0.3962596454058732\n",
      "Epoch 10/30, Validation Loss: 0.44377607127154217, Validation Accuracy: 0.7884362680683311\n",
      "Epoch 11/30, Training Loss: 0.39541260444918486\n",
      "Epoch 11/30, Validation Loss: 0.4183256203084404, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 12/30, Training Loss: 0.39339643563302795\n",
      "Epoch 12/30, Validation Loss: 0.42157867064221677, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 13/30, Training Loss: 0.3909601413613073\n",
      "Epoch 13/30, Validation Loss: 0.4191486119092759, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 14/30, Training Loss: 0.3888052838984046\n",
      "Epoch 14/30, Validation Loss: 0.4182999817488705, Validation Accuracy: 0.812089356110381\n",
      "Epoch 15/30, Training Loss: 0.38799148210351236\n",
      "Epoch 15/30, Validation Loss: 0.41976649799818144, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 16/30, Training Loss: 0.3884425073558968\n",
      "Epoch 16/30, Validation Loss: 0.4300067052342661, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 17/30, Training Loss: 0.38546167584405017\n",
      "Epoch 17/30, Validation Loss: 0.4217730145072516, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 18/30, Training Loss: 0.3861481652172219\n",
      "Epoch 18/30, Validation Loss: 0.4187634101586114, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 19/30, Training Loss: 0.3856713326496324\n",
      "Epoch 19/30, Validation Loss: 0.4208196730435831, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 20/30, Training Loss: 0.38453750418904886\n",
      "Epoch 20/30, Validation Loss: 0.4204445389045783, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 21/30, Training Loss: 0.38273282594529034\n",
      "Epoch 21/30, Validation Loss: 0.4357753118782923, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 22/30, Training Loss: 0.38194879503270457\n",
      "Epoch 22/30, Validation Loss: 0.43039280247352824, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 23/30, Training Loss: 0.37971624437220924\n",
      "Epoch 23/30, Validation Loss: 0.42400514083812063, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 24/30, Training Loss: 0.37966039630625975\n",
      "Epoch 24/30, Validation Loss: 0.42615039595427157, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 25/30, Training Loss: 0.38115683449261145\n",
      "Epoch 25/30, Validation Loss: 0.41986472518500234, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 26/30, Training Loss: 0.37909216900158116\n",
      "Epoch 26/30, Validation Loss: 0.425219822996808, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 27/30, Training Loss: 0.37733323413516906\n",
      "Epoch 27/30, Validation Loss: 0.4195992649869301, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 28/30, Training Loss: 0.3763225707579942\n",
      "Epoch 28/30, Validation Loss: 0.43067046368972484, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 29/30, Training Loss: 0.3762528680343171\n",
      "Epoch 29/30, Validation Loss: 0.43204133005822515, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 30/30, Training Loss: 0.37549080652749445\n",
      "Epoch 30/30, Validation Loss: 0.4191008541362448, Validation Accuracy: 0.8114323258869908\n",
      "Average Validation Accuracy: 0.8061241429055835\n",
      "Number of Epochs: 30\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.5035082609282704\n",
      "Epoch 1/40, Validation Loss: 0.45123721319811505, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 2/40, Training Loss: 0.4348141924133451\n",
      "Epoch 2/40, Validation Loss: 0.42612028749981473, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 3/40, Training Loss: 0.42128661446019106\n",
      "Epoch 3/40, Validation Loss: 0.42003739986042077, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 4/40, Training Loss: 0.41576231433337757\n",
      "Epoch 4/40, Validation Loss: 0.4191095993039808, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 5/40, Training Loss: 0.41121774595084154\n",
      "Epoch 5/40, Validation Loss: 0.4232690877510303, Validation Accuracy: 0.81483913328956\n",
      "Epoch 6/40, Training Loss: 0.40717283534643844\n",
      "Epoch 6/40, Validation Loss: 0.41679189252759774, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 7/40, Training Loss: 0.40472034640668886\n",
      "Epoch 7/40, Validation Loss: 0.4143465102811134, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 8/40, Training Loss: 0.40158695472389694\n",
      "Epoch 8/40, Validation Loss: 0.41809815254198945, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 9/40, Training Loss: 0.39767143458831966\n",
      "Epoch 9/40, Validation Loss: 0.4230251367842652, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 10/40, Training Loss: 0.39789236885473483\n",
      "Epoch 10/40, Validation Loss: 0.4169115567511601, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 11/40, Training Loss: 0.39615113282786424\n",
      "Epoch 11/40, Validation Loss: 0.4133439308802807, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 12/40, Training Loss: 0.394578026245859\n",
      "Epoch 12/40, Validation Loss: 0.41932817960050717, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 13/40, Training Loss: 0.39580850764678843\n",
      "Epoch 13/40, Validation Loss: 0.414024856078063, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 14/40, Training Loss: 0.390754894844777\n",
      "Epoch 14/40, Validation Loss: 0.41400979685533734, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 15/40, Training Loss: 0.3897272267151536\n",
      "Epoch 15/40, Validation Loss: 0.4177958842620488, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 16/40, Training Loss: 0.39020646542428045\n",
      "Epoch 16/40, Validation Loss: 0.41302509904297857, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 17/40, Training Loss: 0.38789325357559\n",
      "Epoch 17/40, Validation Loss: 0.4172428436187237, Validation Accuracy: 0.81483913328956\n",
      "Epoch 18/40, Training Loss: 0.38652796167244746\n",
      "Epoch 18/40, Validation Loss: 0.4129031816624222, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 19/40, Training Loss: 0.38563881950389367\n",
      "Epoch 19/40, Validation Loss: 0.4197052781182434, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 20/40, Training Loss: 0.3831781249718247\n",
      "Epoch 20/40, Validation Loss: 0.4186054361077191, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 21/40, Training Loss: 0.3827795217503009\n",
      "Epoch 21/40, Validation Loss: 0.4415808909753074, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 22/40, Training Loss: 0.3844488433945992\n",
      "Epoch 22/40, Validation Loss: 0.4147215250742997, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 23/40, Training Loss: 0.3808606229869165\n",
      "Epoch 23/40, Validation Loss: 0.4139416602035468, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 24/40, Training Loss: 0.3794999347897027\n",
      "Epoch 24/40, Validation Loss: 0.4160536218103002, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 25/40, Training Loss: 0.38298682866525147\n",
      "Epoch 25/40, Validation Loss: 0.4294979633149052, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 26/40, Training Loss: 0.3805472838186373\n",
      "Epoch 26/40, Validation Loss: 0.4164011795853913, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 27/40, Training Loss: 0.3787929582509782\n",
      "Epoch 27/40, Validation Loss: 0.4235941372538736, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 28/40, Training Loss: 0.37766585984509293\n",
      "Epoch 28/40, Validation Loss: 0.4161427824304522, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 29/40, Training Loss: 0.3754829398950371\n",
      "Epoch 29/40, Validation Loss: 0.4185435463191639, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 30/40, Training Loss: 0.37597455176722816\n",
      "Epoch 30/40, Validation Loss: 0.4146039745824031, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 31/40, Training Loss: 0.37626065798543806\n",
      "Epoch 31/40, Validation Loss: 0.41450114731545223, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 32/40, Training Loss: 0.3747833606657472\n",
      "Epoch 32/40, Validation Loss: 0.4218334953900407, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 33/40, Training Loss: 0.37477716742440315\n",
      "Epoch 33/40, Validation Loss: 0.4217274264866457, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 34/40, Training Loss: 0.37327570587963727\n",
      "Epoch 34/40, Validation Loss: 0.41505205349421315, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 35/40, Training Loss: 0.3747203122345325\n",
      "Epoch 35/40, Validation Loss: 0.4161935329573785, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 36/40, Training Loss: 0.37356329665291965\n",
      "Epoch 36/40, Validation Loss: 0.42461285694302375, Validation Accuracy: 0.8220617202889035\n",
      "Epoch 37/40, Training Loss: 0.37270912985143856\n",
      "Epoch 37/40, Validation Loss: 0.42332654838396616, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 38/40, Training Loss: 0.3720541109924945\n",
      "Epoch 38/40, Validation Loss: 0.418701159265575, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 39/40, Training Loss: 0.37274499264425964\n",
      "Epoch 39/40, Validation Loss: 0.4229031557909637, Validation Accuracy: 0.8227183191070256\n",
      "Epoch 40/40, Training Loss: 0.37008469777665737\n",
      "Epoch 40/40, Validation Loss: 0.4232963206665834, Validation Accuracy: 0.8069599474720945\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.5105427477577227\n",
      "Epoch 1/40, Validation Loss: 0.45598781319500886, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 2/40, Training Loss: 0.44078249361102034\n",
      "Epoch 2/40, Validation Loss: 0.4207915272856258, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 3/40, Training Loss: 0.42205437262031664\n",
      "Epoch 3/40, Validation Loss: 0.4138205443455287, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 4/40, Training Loss: 0.4171147240702249\n",
      "Epoch 4/40, Validation Loss: 0.41131948773305455, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 5/40, Training Loss: 0.41058143247847795\n",
      "Epoch 5/40, Validation Loss: 0.4116081417055498, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 6/40, Training Loss: 0.40818054525284314\n",
      "Epoch 6/40, Validation Loss: 0.42230732644376645, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 7/40, Training Loss: 0.40661656215122055\n",
      "Epoch 7/40, Validation Loss: 0.4111118527197557, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 8/40, Training Loss: 0.40337016230101974\n",
      "Epoch 8/40, Validation Loss: 0.41123449331373757, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 9/40, Training Loss: 0.4014992725074761\n",
      "Epoch 9/40, Validation Loss: 0.416253451097035, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 10/40, Training Loss: 0.3995936196248519\n",
      "Epoch 10/40, Validation Loss: 0.41049494882996795, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 11/40, Training Loss: 0.3967624290496737\n",
      "Epoch 11/40, Validation Loss: 0.4095845814618765, Validation Accuracy: 0.81483913328956\n",
      "Epoch 12/40, Training Loss: 0.39569592352203653\n",
      "Epoch 12/40, Validation Loss: 0.40819309169124246, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 13/40, Training Loss: 0.3921426882444248\n",
      "Epoch 13/40, Validation Loss: 0.40818458053415047, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 14/40, Training Loss: 0.39059705858722604\n",
      "Epoch 14/40, Validation Loss: 0.4429556531148977, Validation Accuracy: 0.7806959947472094\n",
      "Epoch 15/40, Training Loss: 0.39077040699269044\n",
      "Epoch 15/40, Validation Loss: 0.4122369050082424, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 16/40, Training Loss: 0.38851217135513233\n",
      "Epoch 16/40, Validation Loss: 0.4121261137093939, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 17/40, Training Loss: 0.388253611094487\n",
      "Epoch 17/40, Validation Loss: 0.41089202788370754, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 18/40, Training Loss: 0.3891182144434042\n",
      "Epoch 18/40, Validation Loss: 0.4093748324926143, Validation Accuracy: 0.814182534471438\n",
      "Epoch 19/40, Training Loss: 0.3847686206809492\n",
      "Epoch 19/40, Validation Loss: 0.41318872981553617, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 20/40, Training Loss: 0.3852548515301912\n",
      "Epoch 20/40, Validation Loss: 0.4094099929429474, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 21/40, Training Loss: 0.3839870310703835\n",
      "Epoch 21/40, Validation Loss: 0.40818801175081293, Validation Accuracy: 0.81483913328956\n",
      "Epoch 22/40, Training Loss: 0.38266519509901215\n",
      "Epoch 22/40, Validation Loss: 0.4113839636142341, Validation Accuracy: 0.8220617202889035\n",
      "Epoch 23/40, Training Loss: 0.38223658781743114\n",
      "Epoch 23/40, Validation Loss: 0.40874740604252713, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 24/40, Training Loss: 0.3806700310046513\n",
      "Epoch 24/40, Validation Loss: 0.4130014370912345, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 25/40, Training Loss: 0.38180945436726876\n",
      "Epoch 25/40, Validation Loss: 0.45659362936772757, Validation Accuracy: 0.7806959947472094\n",
      "Epoch 26/40, Training Loss: 0.38137702978267446\n",
      "Epoch 26/40, Validation Loss: 0.4083259417846097, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 27/40, Training Loss: 0.38014155913760345\n",
      "Epoch 27/40, Validation Loss: 0.40915395188296494, Validation Accuracy: 0.814182534471438\n",
      "Epoch 28/40, Training Loss: 0.3786675103419409\n",
      "Epoch 28/40, Validation Loss: 0.410107203188757, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 29/40, Training Loss: 0.37784536943582725\n",
      "Epoch 29/40, Validation Loss: 0.4095063925433065, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 30/40, Training Loss: 0.3759848089678472\n",
      "Epoch 30/40, Validation Loss: 0.41476802117830014, Validation Accuracy: 0.804333552199606\n",
      "Epoch 31/40, Training Loss: 0.37551332440158824\n",
      "Epoch 31/40, Validation Loss: 0.4185175466063525, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 32/40, Training Loss: 0.37802069670865385\n",
      "Epoch 32/40, Validation Loss: 0.40931794039066394, Validation Accuracy: 0.814182534471438\n",
      "Epoch 33/40, Training Loss: 0.3770323750071638\n",
      "Epoch 33/40, Validation Loss: 0.420106935153925, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 34/40, Training Loss: 0.37393489843258865\n",
      "Epoch 34/40, Validation Loss: 0.42280677973209874, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 35/40, Training Loss: 0.37481187628655455\n",
      "Epoch 35/40, Validation Loss: 0.41250586842250136, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 36/40, Training Loss: 0.3730957146558001\n",
      "Epoch 36/40, Validation Loss: 0.4118608549598078, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 37/40, Training Loss: 0.37261709516618663\n",
      "Epoch 37/40, Validation Loss: 0.4123376168271634, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 38/40, Training Loss: 0.37354061579981973\n",
      "Epoch 38/40, Validation Loss: 0.41828325453228976, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 39/40, Training Loss: 0.37392963361963044\n",
      "Epoch 39/40, Validation Loss: 0.4124085332622937, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 40/40, Training Loss: 0.3702460006172732\n",
      "Epoch 40/40, Validation Loss: 0.41086414658235315, Validation Accuracy: 0.8108995403808273\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.5036669788671917\n",
      "Epoch 1/40, Validation Loss: 0.46494136426929406, Validation Accuracy: 0.7820091923834537\n",
      "Epoch 2/40, Training Loss: 0.43132935441893544\n",
      "Epoch 2/40, Validation Loss: 0.44461784648333547, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 3/40, Training Loss: 0.41784466235969325\n",
      "Epoch 3/40, Validation Loss: 0.4345020342871781, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 4/40, Training Loss: 0.4105519527261417\n",
      "Epoch 4/40, Validation Loss: 0.43450253475359907, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 5/40, Training Loss: 0.40578965923878463\n",
      "Epoch 5/40, Validation Loss: 0.4521165485079376, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 6/40, Training Loss: 0.4009420219368822\n",
      "Epoch 6/40, Validation Loss: 0.4412097448278316, Validation Accuracy: 0.799080761654629\n",
      "Epoch 7/40, Training Loss: 0.3989870820947363\n",
      "Epoch 7/40, Validation Loss: 0.43191706220477977, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 8/40, Training Loss: 0.39701808797405774\n",
      "Epoch 8/40, Validation Loss: 0.4353763438439416, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 9/40, Training Loss: 0.3959266874508986\n",
      "Epoch 9/40, Validation Loss: 0.43090287750070005, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 10/40, Training Loss: 0.3928332409951005\n",
      "Epoch 10/40, Validation Loss: 0.4569631769902107, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 11/40, Training Loss: 0.3906992447423184\n",
      "Epoch 11/40, Validation Loss: 0.43406803779187003, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 12/40, Training Loss: 0.3911351699606953\n",
      "Epoch 12/40, Validation Loss: 0.434702545092368, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 13/40, Training Loss: 0.38722061834192967\n",
      "Epoch 13/40, Validation Loss: 0.43911227554628984, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 14/40, Training Loss: 0.3876741049601024\n",
      "Epoch 14/40, Validation Loss: 0.4366915126365283, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 15/40, Training Loss: 0.3853590615910143\n",
      "Epoch 15/40, Validation Loss: 0.43624384904095015, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 16/40, Training Loss: 0.384359049642571\n",
      "Epoch 16/40, Validation Loss: 0.44455735001186425, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 17/40, Training Loss: 0.3824210200077436\n",
      "Epoch 17/40, Validation Loss: 0.4330479063200935, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 18/40, Training Loss: 0.3819803647951191\n",
      "Epoch 18/40, Validation Loss: 0.4369625008630893, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 19/40, Training Loss: 0.3823602012018832\n",
      "Epoch 19/40, Validation Loss: 0.4305243631386008, Validation Accuracy: 0.81483913328956\n",
      "Epoch 20/40, Training Loss: 0.38031792479354565\n",
      "Epoch 20/40, Validation Loss: 0.4339828988663969, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 21/40, Training Loss: 0.3786587782810366\n",
      "Epoch 21/40, Validation Loss: 0.44072101013588655, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 22/40, Training Loss: 0.37944760184803505\n",
      "Epoch 22/40, Validation Loss: 0.4328153104916293, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 23/40, Training Loss: 0.37792515051685605\n",
      "Epoch 23/40, Validation Loss: 0.43269528784052863, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 24/40, Training Loss: 0.37839057808864146\n",
      "Epoch 24/40, Validation Loss: 0.43503020287379235, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 25/40, Training Loss: 0.3758071773780847\n",
      "Epoch 25/40, Validation Loss: 0.4335389611608695, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 26/40, Training Loss: 0.37639380092891495\n",
      "Epoch 26/40, Validation Loss: 0.4379631114918836, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 27/40, Training Loss: 0.3751834653357039\n",
      "Epoch 27/40, Validation Loss: 0.4356460668078346, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 28/40, Training Loss: 0.37395239133495356\n",
      "Epoch 28/40, Validation Loss: 0.4382235386764816, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 29/40, Training Loss: 0.3729424853894732\n",
      "Epoch 29/40, Validation Loss: 0.4494362161129089, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 30/40, Training Loss: 0.371912245406449\n",
      "Epoch 30/40, Validation Loss: 0.4550373826019895, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 31/40, Training Loss: 0.3722391971814742\n",
      "Epoch 31/40, Validation Loss: 0.435322798851936, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 32/40, Training Loss: 0.37163953350250684\n",
      "Epoch 32/40, Validation Loss: 0.4370085735712688, Validation Accuracy: 0.8233749179251477\n",
      "Epoch 33/40, Training Loss: 0.371250016957013\n",
      "Epoch 33/40, Validation Loss: 0.4316851555989051, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 34/40, Training Loss: 0.3704661452736989\n",
      "Epoch 34/40, Validation Loss: 0.43403604524258854, Validation Accuracy: 0.8227183191070256\n",
      "Epoch 35/40, Training Loss: 0.37071980666515864\n",
      "Epoch 35/40, Validation Loss: 0.4363374231451469, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 36/40, Training Loss: 0.37022775907333444\n",
      "Epoch 36/40, Validation Loss: 0.45726117084085627, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 37/40, Training Loss: 0.36905567110406134\n",
      "Epoch 37/40, Validation Loss: 0.4345419811211643, Validation Accuracy: 0.8220617202889035\n",
      "Epoch 38/40, Training Loss: 0.36617707330097987\n",
      "Epoch 38/40, Validation Loss: 0.43883778640503035, Validation Accuracy: 0.81483913328956\n",
      "Epoch 39/40, Training Loss: 0.36750350611924815\n",
      "Epoch 39/40, Validation Loss: 0.43388972697165157, Validation Accuracy: 0.814182534471438\n",
      "Epoch 40/40, Training Loss: 0.36710524625020236\n",
      "Epoch 40/40, Validation Loss: 0.4418801115045607, Validation Accuracy: 0.8017071569271176\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.5155447900217036\n",
      "Epoch 1/40, Validation Loss: 0.4443356027309807, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 2/40, Training Loss: 0.4419659404792967\n",
      "Epoch 2/40, Validation Loss: 0.4156511773340677, Validation Accuracy: 0.8160315374507228\n",
      "Epoch 3/40, Training Loss: 0.42694163004674623\n",
      "Epoch 3/40, Validation Loss: 0.40660140989104493, Validation Accuracy: 0.8219448094612353\n",
      "Epoch 4/40, Training Loss: 0.4205778817844203\n",
      "Epoch 4/40, Validation Loss: 0.41782271569467966, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 5/40, Training Loss: 0.4163974485802525\n",
      "Epoch 5/40, Validation Loss: 0.4053395126034452, Validation Accuracy: 0.8193166885676741\n",
      "Epoch 6/40, Training Loss: 0.41233010532877107\n",
      "Epoch 6/40, Validation Loss: 0.4176144215780559, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 7/40, Training Loss: 0.41067527632994133\n",
      "Epoch 7/40, Validation Loss: 0.40276714468969727, Validation Accuracy: 0.8298291721419185\n",
      "Epoch 8/40, Training Loss: 0.40659060922703094\n",
      "Epoch 8/40, Validation Loss: 0.3995171972301774, Validation Accuracy: 0.8324572930354797\n",
      "Epoch 9/40, Training Loss: 0.405623774662653\n",
      "Epoch 9/40, Validation Loss: 0.41156766157967883, Validation Accuracy: 0.8219448094612353\n",
      "Epoch 10/40, Training Loss: 0.4032234853118893\n",
      "Epoch 10/40, Validation Loss: 0.41106433907026396, Validation Accuracy: 0.8193166885676741\n",
      "Epoch 11/40, Training Loss: 0.39930054460336845\n",
      "Epoch 11/40, Validation Loss: 0.4011226796315915, Validation Accuracy: 0.8324572930354797\n",
      "Epoch 12/40, Training Loss: 0.4001560391286227\n",
      "Epoch 12/40, Validation Loss: 0.4011310667911281, Validation Accuracy: 0.828515111695138\n",
      "Epoch 13/40, Training Loss: 0.3973406329653238\n",
      "Epoch 13/40, Validation Loss: 0.3974853799975823, Validation Accuracy: 0.8337713534822602\n",
      "Epoch 14/40, Training Loss: 0.39757718666996855\n",
      "Epoch 14/40, Validation Loss: 0.3978029980631399, Validation Accuracy: 0.8258869908015769\n",
      "Epoch 15/40, Training Loss: 0.3933612128323692\n",
      "Epoch 15/40, Validation Loss: 0.4017892266033676, Validation Accuracy: 0.8272010512483574\n",
      "Epoch 16/40, Training Loss: 0.3957334863281078\n",
      "Epoch 16/40, Validation Loss: 0.40078469217603746, Validation Accuracy: 0.828515111695138\n",
      "Epoch 17/40, Training Loss: 0.3944470905979944\n",
      "Epoch 17/40, Validation Loss: 0.3967731166728504, Validation Accuracy: 0.8318002628120894\n",
      "Epoch 18/40, Training Loss: 0.3928517436124678\n",
      "Epoch 18/40, Validation Loss: 0.39650786973301966, Validation Accuracy: 0.835742444152431\n",
      "Epoch 19/40, Training Loss: 0.3915420019427153\n",
      "Epoch 19/40, Validation Loss: 0.40508046437600986, Validation Accuracy: 0.8186596583442839\n",
      "Epoch 20/40, Training Loss: 0.3899557121987809\n",
      "Epoch 20/40, Validation Loss: 0.40768463585857323, Validation Accuracy: 0.8245729303547963\n",
      "Epoch 21/40, Training Loss: 0.3895546902078656\n",
      "Epoch 21/40, Validation Loss: 0.40447096328655774, Validation Accuracy: 0.8212877792378449\n",
      "Epoch 22/40, Training Loss: 0.38809889565732847\n",
      "Epoch 22/40, Validation Loss: 0.40968712555800435, Validation Accuracy: 0.8258869908015769\n",
      "Epoch 23/40, Training Loss: 0.3863400139325247\n",
      "Epoch 23/40, Validation Loss: 0.40027681530419135, Validation Accuracy: 0.828515111695138\n",
      "Epoch 24/40, Training Loss: 0.3859756353343018\n",
      "Epoch 24/40, Validation Loss: 0.4038921882208261, Validation Accuracy: 0.8226018396846255\n",
      "Epoch 25/40, Training Loss: 0.3843277829193224\n",
      "Epoch 25/40, Validation Loss: 0.4062117601974004, Validation Accuracy: 0.8291721419185283\n",
      "Epoch 26/40, Training Loss: 0.38406323714382223\n",
      "Epoch 26/40, Validation Loss: 0.40122599021107425, Validation Accuracy: 0.8272010512483574\n",
      "Epoch 27/40, Training Loss: 0.38383436827795714\n",
      "Epoch 27/40, Validation Loss: 0.3963199607852398, Validation Accuracy: 0.831143232588699\n",
      "Epoch 28/40, Training Loss: 0.3830476591456437\n",
      "Epoch 28/40, Validation Loss: 0.4179155990939724, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 29/40, Training Loss: 0.3812111471425204\n",
      "Epoch 29/40, Validation Loss: 0.39749390382261174, Validation Accuracy: 0.8272010512483574\n",
      "Epoch 30/40, Training Loss: 0.38113569979631684\n",
      "Epoch 30/40, Validation Loss: 0.4086252719319928, Validation Accuracy: 0.8252299605781866\n",
      "Epoch 31/40, Training Loss: 0.3805154044317996\n",
      "Epoch 31/40, Validation Loss: 0.4005763242167484, Validation Accuracy: 0.8304862023653088\n",
      "Epoch 32/40, Training Loss: 0.38063716773540174\n",
      "Epoch 32/40, Validation Loss: 0.39638151200146887, Validation Accuracy: 0.8291721419185283\n",
      "Epoch 33/40, Training Loss: 0.37864102886652384\n",
      "Epoch 33/40, Validation Loss: 0.3965637832002334, Validation Accuracy: 0.8265440210249672\n",
      "Epoch 34/40, Training Loss: 0.38050678050697945\n",
      "Epoch 34/40, Validation Loss: 0.4030285619823408, Validation Accuracy: 0.8265440210249672\n",
      "Epoch 35/40, Training Loss: 0.37997751163802745\n",
      "Epoch 35/40, Validation Loss: 0.4032161725363182, Validation Accuracy: 0.8278580814717477\n",
      "Epoch 36/40, Training Loss: 0.3768953015719812\n",
      "Epoch 36/40, Validation Loss: 0.4050287644217932, Validation Accuracy: 0.8278580814717477\n",
      "Epoch 37/40, Training Loss: 0.37746385128049087\n",
      "Epoch 37/40, Validation Loss: 0.39714827617211024, Validation Accuracy: 0.8245729303547963\n",
      "Epoch 38/40, Training Loss: 0.3774862781440805\n",
      "Epoch 38/40, Validation Loss: 0.4000830961323065, Validation Accuracy: 0.8298291721419185\n",
      "Epoch 39/40, Training Loss: 0.3761467631231612\n",
      "Epoch 39/40, Validation Loss: 0.40387594399495896, Validation Accuracy: 0.8265440210249672\n",
      "Epoch 40/40, Training Loss: 0.3746235921998506\n",
      "Epoch 40/40, Validation Loss: 0.40254144538291464, Validation Accuracy: 0.828515111695138\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.5117204661561748\n",
      "Epoch 1/40, Validation Loss: 0.4509901712546174, Validation Accuracy: 0.7956636005256241\n",
      "Epoch 2/40, Training Loss: 0.4352478535645434\n",
      "Epoch 2/40, Validation Loss: 0.43050860917849065, Validation Accuracy: 0.804862023653088\n",
      "Epoch 3/40, Training Loss: 0.4216213148585924\n",
      "Epoch 3/40, Validation Loss: 0.4280914877448719, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 4/40, Training Loss: 0.414969406973111\n",
      "Epoch 4/40, Validation Loss: 0.4242772282886256, Validation Accuracy: 0.804862023653088\n",
      "Epoch 5/40, Training Loss: 0.40912663207201194\n",
      "Epoch 5/40, Validation Loss: 0.4208212022654985, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 6/40, Training Loss: 0.40563714338999407\n",
      "Epoch 6/40, Validation Loss: 0.42006691756867925, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 7/40, Training Loss: 0.4019027509997914\n",
      "Epoch 7/40, Validation Loss: 0.42276293907256024, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 8/40, Training Loss: 0.4008555265920838\n",
      "Epoch 8/40, Validation Loss: 0.4249972533239588, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 9/40, Training Loss: 0.39814845840703317\n",
      "Epoch 9/40, Validation Loss: 0.4214518834978186, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 10/40, Training Loss: 0.39729668311481403\n",
      "Epoch 10/40, Validation Loss: 0.42234662357054614, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 11/40, Training Loss: 0.3953016786359427\n",
      "Epoch 11/40, Validation Loss: 0.4220732544495173, Validation Accuracy: 0.8134034165571616\n",
      "Epoch 12/40, Training Loss: 0.39264832435082886\n",
      "Epoch 12/40, Validation Loss: 0.4434367260744512, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 13/40, Training Loss: 0.3898334332504689\n",
      "Epoch 13/40, Validation Loss: 0.4318120709440003, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 14/40, Training Loss: 0.3879982266975982\n",
      "Epoch 14/40, Validation Loss: 0.41815931270025786, Validation Accuracy: 0.80946123521682\n",
      "Epoch 15/40, Training Loss: 0.38909360464280984\n",
      "Epoch 15/40, Validation Loss: 0.42102222761909686, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 16/40, Training Loss: 0.38599532139133125\n",
      "Epoch 16/40, Validation Loss: 0.4184766349465591, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 17/40, Training Loss: 0.38694955832923805\n",
      "Epoch 17/40, Validation Loss: 0.42153228154279176, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 18/40, Training Loss: 0.38603182256299995\n",
      "Epoch 18/40, Validation Loss: 0.4475394588363654, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 19/40, Training Loss: 0.3871500752035167\n",
      "Epoch 19/40, Validation Loss: 0.420435572150334, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 20/40, Training Loss: 0.3830872872194124\n",
      "Epoch 20/40, Validation Loss: 0.42257372875995347, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 21/40, Training Loss: 0.38190227245369296\n",
      "Epoch 21/40, Validation Loss: 0.4190448013997359, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 22/40, Training Loss: 0.3802312655750848\n",
      "Epoch 22/40, Validation Loss: 0.4246041615693513, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 23/40, Training Loss: 0.37996520543485646\n",
      "Epoch 23/40, Validation Loss: 0.4259452278389356, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 24/40, Training Loss: 0.3789602782371945\n",
      "Epoch 24/40, Validation Loss: 0.4213676666402068, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 25/40, Training Loss: 0.3783713951951328\n",
      "Epoch 25/40, Validation Loss: 0.41928318588560476, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 26/40, Training Loss: 0.37618768685974\n",
      "Epoch 26/40, Validation Loss: 0.42924894960060794, Validation Accuracy: 0.797634691195795\n",
      "Epoch 27/40, Training Loss: 0.3776508222316976\n",
      "Epoch 27/40, Validation Loss: 0.41977948877784904, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 28/40, Training Loss: 0.3765077410397802\n",
      "Epoch 28/40, Validation Loss: 0.42560516398263537, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 29/40, Training Loss: 0.37547011554651843\n",
      "Epoch 29/40, Validation Loss: 0.4220667082075205, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 30/40, Training Loss: 0.3750510262154297\n",
      "Epoch 30/40, Validation Loss: 0.4219338063257917, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 31/40, Training Loss: 0.37562560160544134\n",
      "Epoch 31/40, Validation Loss: 0.428638780353035, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 32/40, Training Loss: 0.3754373445050923\n",
      "Epoch 32/40, Validation Loss: 0.43466913870764967, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 33/40, Training Loss: 0.37185981527968187\n",
      "Epoch 33/40, Validation Loss: 0.4227063779753306, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 34/40, Training Loss: 0.3729867323294399\n",
      "Epoch 34/40, Validation Loss: 0.4267093565471041, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 35/40, Training Loss: 0.3720850179025664\n",
      "Epoch 35/40, Validation Loss: 0.41975767869521813, Validation Accuracy: 0.812089356110381\n",
      "Epoch 36/40, Training Loss: 0.3707241433919493\n",
      "Epoch 36/40, Validation Loss: 0.43330341854488663, Validation Accuracy: 0.8134034165571616\n",
      "Epoch 37/40, Training Loss: 0.37030547944794645\n",
      "Epoch 37/40, Validation Loss: 0.42741351820411483, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 38/40, Training Loss: 0.369890936687002\n",
      "Epoch 38/40, Validation Loss: 0.4320309331045725, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 39/40, Training Loss: 0.3709240575563016\n",
      "Epoch 39/40, Validation Loss: 0.42342095329616397, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 40/40, Training Loss: 0.36971118779769874\n",
      "Epoch 40/40, Validation Loss: 0.42574703529555136, Validation Accuracy: 0.8088042049934296\n",
      "Average Validation Accuracy: 0.8113771922937214\n",
      "Number of Epochs: 40\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/50, Training Loss: 0.5111316268056083\n",
      "Epoch 1/50, Validation Loss: 0.4611511388062183, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 2/50, Training Loss: 0.43857106250610567\n",
      "Epoch 2/50, Validation Loss: 0.4438989497136071, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 3/50, Training Loss: 0.4213870028204962\n",
      "Epoch 3/50, Validation Loss: 0.42438752405072383, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 4/50, Training Loss: 0.41673831520431\n",
      "Epoch 4/50, Validation Loss: 0.41806777412588686, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 5/50, Training Loss: 0.4117084167839035\n",
      "Epoch 5/50, Validation Loss: 0.41448628340716137, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 6/50, Training Loss: 0.4060124594454221\n",
      "Epoch 6/50, Validation Loss: 0.41586622422200226, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 7/50, Training Loss: 0.4063504903706822\n",
      "Epoch 7/50, Validation Loss: 0.41969841400756264, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 8/50, Training Loss: 0.4016946597205685\n",
      "Epoch 8/50, Validation Loss: 0.42406231266353767, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 9/50, Training Loss: 0.40061508721410444\n",
      "Epoch 9/50, Validation Loss: 0.41199410837436223, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 10/50, Training Loss: 0.3977868992033515\n",
      "Epoch 10/50, Validation Loss: 0.4216560774253613, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 11/50, Training Loss: 0.3961386363220027\n",
      "Epoch 11/50, Validation Loss: 0.4157388501103324, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 12/50, Training Loss: 0.39354905835169507\n",
      "Epoch 12/50, Validation Loss: 0.4214442878259414, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 13/50, Training Loss: 0.39568915387268455\n",
      "Epoch 13/50, Validation Loss: 0.41268378127541844, Validation Accuracy: 0.8227183191070256\n",
      "Epoch 14/50, Training Loss: 0.3924073103394878\n",
      "Epoch 14/50, Validation Loss: 0.41726121189394544, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 15/50, Training Loss: 0.39090371342116764\n",
      "Epoch 15/50, Validation Loss: 0.41394148250134827, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 16/50, Training Loss: 0.38987757079792146\n",
      "Epoch 16/50, Validation Loss: 0.41800666237688816, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 17/50, Training Loss: 0.3847937410663119\n",
      "Epoch 17/50, Validation Loss: 0.4258445829387111, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 18/50, Training Loss: 0.388357778057808\n",
      "Epoch 18/50, Validation Loss: 0.4203311020401136, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 19/50, Training Loss: 0.3863626206855918\n",
      "Epoch 19/50, Validation Loss: 0.4242536646572395, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 20/50, Training Loss: 0.38172701025122574\n",
      "Epoch 20/50, Validation Loss: 0.4170511979707249, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 21/50, Training Loss: 0.38297554814889834\n",
      "Epoch 21/50, Validation Loss: 0.4136406183242798, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 22/50, Training Loss: 0.3812286452270477\n",
      "Epoch 22/50, Validation Loss: 0.414882729970972, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 23/50, Training Loss: 0.3822181291897779\n",
      "Epoch 23/50, Validation Loss: 0.42501660982507683, Validation Accuracy: 0.8069599474720945\n",
      "Epoch 24/50, Training Loss: 0.38432153077732545\n",
      "Epoch 24/50, Validation Loss: 0.4132239109987676, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 25/50, Training Loss: 0.3804271774527829\n",
      "Epoch 25/50, Validation Loss: 0.41480987068480224, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 26/50, Training Loss: 0.3790166247684968\n",
      "Epoch 26/50, Validation Loss: 0.41504901355005686, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 27/50, Training Loss: 0.37890091337009363\n",
      "Epoch 27/50, Validation Loss: 0.42536823722626527, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 28/50, Training Loss: 0.3778345656539668\n",
      "Epoch 28/50, Validation Loss: 0.4164068802450028, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 29/50, Training Loss: 0.3767270892027404\n",
      "Epoch 29/50, Validation Loss: 0.41359829611062066, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 30/50, Training Loss: 0.3772219185842069\n",
      "Epoch 30/50, Validation Loss: 0.4208118135977478, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 31/50, Training Loss: 0.3750209220467512\n",
      "Epoch 31/50, Validation Loss: 0.4132926086578226, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 32/50, Training Loss: 0.37452215265746663\n",
      "Epoch 32/50, Validation Loss: 0.4188409852770923, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 33/50, Training Loss: 0.3749348766138665\n",
      "Epoch 33/50, Validation Loss: 0.41686438596490477, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 34/50, Training Loss: 0.37393553237726523\n",
      "Epoch 34/50, Validation Loss: 0.4286239490264061, Validation Accuracy: 0.81483913328956\n",
      "Epoch 35/50, Training Loss: 0.37353899737140484\n",
      "Epoch 35/50, Validation Loss: 0.42034261139275514, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 36/50, Training Loss: 0.3721998761214922\n",
      "Epoch 36/50, Validation Loss: 0.4213093061643745, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 37/50, Training Loss: 0.37414400059524483\n",
      "Epoch 37/50, Validation Loss: 0.41653018704181566, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 38/50, Training Loss: 0.37133425232169665\n",
      "Epoch 38/50, Validation Loss: 0.429243989015749, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 39/50, Training Loss: 0.3716512322719172\n",
      "Epoch 39/50, Validation Loss: 0.4170704378175954, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 40/50, Training Loss: 0.37165922459870027\n",
      "Epoch 40/50, Validation Loss: 0.44512134654866775, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 41/50, Training Loss: 0.3699051403975862\n",
      "Epoch 41/50, Validation Loss: 0.41825831853126355, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 42/50, Training Loss: 0.37236275659810525\n",
      "Epoch 42/50, Validation Loss: 0.4165997678774814, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 43/50, Training Loss: 0.3687884551020745\n",
      "Epoch 43/50, Validation Loss: 0.41629051926170346, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 44/50, Training Loss: 0.36922308222300265\n",
      "Epoch 44/50, Validation Loss: 0.41550927803271415, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 45/50, Training Loss: 0.36883820902331294\n",
      "Epoch 45/50, Validation Loss: 0.4356537841123904, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 46/50, Training Loss: 0.3676125441489648\n",
      "Epoch 46/50, Validation Loss: 0.42745729785471065, Validation Accuracy: 0.8069599474720945\n",
      "Epoch 47/50, Training Loss: 0.3673602122803686\n",
      "Epoch 47/50, Validation Loss: 0.42043041876707404, Validation Accuracy: 0.824688115561392\n",
      "Epoch 48/50, Training Loss: 0.3663158646669835\n",
      "Epoch 48/50, Validation Loss: 0.4309878919897747, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 49/50, Training Loss: 0.36658872783751156\n",
      "Epoch 49/50, Validation Loss: 0.41986516268231483, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 50/50, Training Loss: 0.36479363755232547\n",
      "Epoch 50/50, Validation Loss: 0.41817567207855394, Validation Accuracy: 0.8187787261982928\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/50, Training Loss: 0.5077174651849614\n",
      "Epoch 1/50, Validation Loss: 0.4441770647520794, Validation Accuracy: 0.804333552199606\n",
      "Epoch 2/50, Training Loss: 0.43829973302097147\n",
      "Epoch 2/50, Validation Loss: 0.4211889446093774, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 3/50, Training Loss: 0.42242804660738065\n",
      "Epoch 3/50, Validation Loss: 0.4176331718905746, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 4/50, Training Loss: 0.41654324000627974\n",
      "Epoch 4/50, Validation Loss: 0.42402896660024114, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 5/50, Training Loss: 0.41135267718765994\n",
      "Epoch 5/50, Validation Loss: 0.41498680549298284, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 6/50, Training Loss: 0.40639847549279845\n",
      "Epoch 6/50, Validation Loss: 0.416936439164568, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 7/50, Training Loss: 0.4048455816124055\n",
      "Epoch 7/50, Validation Loss: 0.42155218458885607, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 8/50, Training Loss: 0.40187978240957095\n",
      "Epoch 8/50, Validation Loss: 0.40914485451438665, Validation Accuracy: 0.814182534471438\n",
      "Epoch 9/50, Training Loss: 0.40078497253690804\n",
      "Epoch 9/50, Validation Loss: 0.40801489679874237, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 10/50, Training Loss: 0.39790714556092194\n",
      "Epoch 10/50, Validation Loss: 0.4084396380638577, Validation Accuracy: 0.814182534471438\n",
      "Epoch 11/50, Training Loss: 0.39716458255596204\n",
      "Epoch 11/50, Validation Loss: 0.41389454866110964, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 12/50, Training Loss: 0.39298515410952056\n",
      "Epoch 12/50, Validation Loss: 0.4102306489330468, Validation Accuracy: 0.81483913328956\n",
      "Epoch 13/50, Training Loss: 0.39123399602615927\n",
      "Epoch 13/50, Validation Loss: 0.4210372652897504, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 14/50, Training Loss: 0.3943677283970155\n",
      "Epoch 14/50, Validation Loss: 0.4192147997953973, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 15/50, Training Loss: 0.3916354810823919\n",
      "Epoch 15/50, Validation Loss: 0.41026033439639353, Validation Accuracy: 0.814182534471438\n",
      "Epoch 16/50, Training Loss: 0.3897877291402244\n",
      "Epoch 16/50, Validation Loss: 0.4095360276372177, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 17/50, Training Loss: 0.3880835720619035\n",
      "Epoch 17/50, Validation Loss: 0.4289384162619086, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 18/50, Training Loss: 0.387100097627973\n",
      "Epoch 18/50, Validation Loss: 0.4108052872296871, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 19/50, Training Loss: 0.38542369480814365\n",
      "Epoch 19/50, Validation Loss: 0.43086823569464433, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 20/50, Training Loss: 0.38544174340453363\n",
      "Epoch 20/50, Validation Loss: 0.41821172827591446, Validation Accuracy: 0.799080761654629\n",
      "Epoch 21/50, Training Loss: 0.3855406824362481\n",
      "Epoch 21/50, Validation Loss: 0.4105315899515417, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 22/50, Training Loss: 0.3834095314301531\n",
      "Epoch 22/50, Validation Loss: 0.41106646490424714, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 23/50, Training Loss: 0.383636225890026\n",
      "Epoch 23/50, Validation Loss: 0.4197518388004437, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 24/50, Training Loss: 0.38010593067629755\n",
      "Epoch 24/50, Validation Loss: 0.41415393263764716, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 25/50, Training Loss: 0.38237306425773254\n",
      "Epoch 25/50, Validation Loss: 0.4144697219074865, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 26/50, Training Loss: 0.3778033076915059\n",
      "Epoch 26/50, Validation Loss: 0.41147740951285783, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 27/50, Training Loss: 0.3805478746584785\n",
      "Epoch 27/50, Validation Loss: 0.4122979585471422, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 28/50, Training Loss: 0.3801841998125703\n",
      "Epoch 28/50, Validation Loss: 0.41041744416530845, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 29/50, Training Loss: 0.3791815206736052\n",
      "Epoch 29/50, Validation Loss: 0.41650788457722876, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 30/50, Training Loss: 0.37605853324506694\n",
      "Epoch 30/50, Validation Loss: 0.4128501537251067, Validation Accuracy: 0.8240315167432699\n",
      "Epoch 31/50, Training Loss: 0.3795891893817371\n",
      "Epoch 31/50, Validation Loss: 0.4101484241110336, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 32/50, Training Loss: 0.376283607262326\n",
      "Epoch 32/50, Validation Loss: 0.4153121428866505, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 33/50, Training Loss: 0.37484047830280826\n",
      "Epoch 33/50, Validation Loss: 0.41079486507668855, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 34/50, Training Loss: 0.3743083848131532\n",
      "Epoch 34/50, Validation Loss: 0.4119486783616518, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 35/50, Training Loss: 0.3754092177615704\n",
      "Epoch 35/50, Validation Loss: 0.42101078446837464, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 36/50, Training Loss: 0.37558779201110987\n",
      "Epoch 36/50, Validation Loss: 0.4133638443756868, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 37/50, Training Loss: 0.3715412026012116\n",
      "Epoch 37/50, Validation Loss: 0.4130550658242553, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 38/50, Training Loss: 0.37308968591877795\n",
      "Epoch 38/50, Validation Loss: 0.4128787123954109, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 39/50, Training Loss: 0.3717752631088802\n",
      "Epoch 39/50, Validation Loss: 0.41330955422322474, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 40/50, Training Loss: 0.3717178430095354\n",
      "Epoch 40/50, Validation Loss: 0.4139369382176802, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 41/50, Training Loss: 0.373509559438141\n",
      "Epoch 41/50, Validation Loss: 0.4126139526250553, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 42/50, Training Loss: 0.3718829397209908\n",
      "Epoch 42/50, Validation Loss: 0.419378571958325, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 43/50, Training Loss: 0.3723022675391023\n",
      "Epoch 43/50, Validation Loss: 0.4159600316639502, Validation Accuracy: 0.804333552199606\n",
      "Epoch 44/50, Training Loss: 0.37033584738380015\n",
      "Epoch 44/50, Validation Loss: 0.41411300483817987, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 45/50, Training Loss: 0.3683227179547542\n",
      "Epoch 45/50, Validation Loss: 0.41265311700667384, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 46/50, Training Loss: 0.36849833864063575\n",
      "Epoch 46/50, Validation Loss: 0.41412616332905144, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 47/50, Training Loss: 0.3685759640692335\n",
      "Epoch 47/50, Validation Loss: 0.4130023910239807, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 48/50, Training Loss: 0.36995922232882716\n",
      "Epoch 48/50, Validation Loss: 0.4274617061994151, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 49/50, Training Loss: 0.3697041319976524\n",
      "Epoch 49/50, Validation Loss: 0.42487717255540386, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 50/50, Training Loss: 0.3674834807234721\n",
      "Epoch 50/50, Validation Loss: 0.4164393378899516, Validation Accuracy: 0.8174655285620486\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/50, Training Loss: 0.5060680965132757\n",
      "Epoch 1/50, Validation Loss: 0.47000829268890526, Validation Accuracy: 0.7813525935653316\n",
      "Epoch 2/50, Training Loss: 0.4343767392490636\n",
      "Epoch 2/50, Validation Loss: 0.4664669671724916, Validation Accuracy: 0.7787261982928431\n",
      "Epoch 3/50, Training Loss: 0.41892418022856626\n",
      "Epoch 3/50, Validation Loss: 0.44774069700448615, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 4/50, Training Loss: 0.4086526110768318\n",
      "Epoch 4/50, Validation Loss: 0.45749521952766087, Validation Accuracy: 0.7846355876559422\n",
      "Epoch 5/50, Training Loss: 0.4083137351071115\n",
      "Epoch 5/50, Validation Loss: 0.4564522058064245, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 6/50, Training Loss: 0.40493079150716466\n",
      "Epoch 6/50, Validation Loss: 0.4341063451372984, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 7/50, Training Loss: 0.3999795185944696\n",
      "Epoch 7/50, Validation Loss: 0.43457229656815843, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 8/50, Training Loss: 0.39852727556557166\n",
      "Epoch 8/50, Validation Loss: 0.4388749292266618, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 9/50, Training Loss: 0.39663056302766786\n",
      "Epoch 9/50, Validation Loss: 0.435459457298848, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 10/50, Training Loss: 0.39344819504132106\n",
      "Epoch 10/50, Validation Loss: 0.48391571948402295, Validation Accuracy: 0.7649376231122784\n",
      "Epoch 11/50, Training Loss: 0.3913110019125807\n",
      "Epoch 11/50, Validation Loss: 0.4388080036014084, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 12/50, Training Loss: 0.3911863959191509\n",
      "Epoch 12/50, Validation Loss: 0.43325222866775476, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 13/50, Training Loss: 0.386797356711373\n",
      "Epoch 13/50, Validation Loss: 0.4469326709089947, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 14/50, Training Loss: 0.38795680551254375\n",
      "Epoch 14/50, Validation Loss: 0.44116439260737433, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 15/50, Training Loss: 0.38547598598451593\n",
      "Epoch 15/50, Validation Loss: 0.44374783161579, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 16/50, Training Loss: 0.38437268673258973\n",
      "Epoch 16/50, Validation Loss: 0.4502637364672429, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 17/50, Training Loss: 0.3849867378994627\n",
      "Epoch 17/50, Validation Loss: 0.4324962478326097, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 18/50, Training Loss: 0.38424159847004363\n",
      "Epoch 18/50, Validation Loss: 0.44074339438132276, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 19/50, Training Loss: 0.3807247891103032\n",
      "Epoch 19/50, Validation Loss: 0.4333901320540234, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 20/50, Training Loss: 0.3802709554388063\n",
      "Epoch 20/50, Validation Loss: 0.48915110208601226, Validation Accuracy: 0.7616546290216678\n",
      "Epoch 21/50, Training Loss: 0.3789933730317695\n",
      "Epoch 21/50, Validation Loss: 0.4851441761644567, Validation Accuracy: 0.7636244254760342\n",
      "Epoch 22/50, Training Loss: 0.3796694857554799\n",
      "Epoch 22/50, Validation Loss: 0.43367430241534694, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 23/50, Training Loss: 0.3768794066284898\n",
      "Epoch 23/50, Validation Loss: 0.4576760699231353, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 24/50, Training Loss: 0.3764690279745524\n",
      "Epoch 24/50, Validation Loss: 0.4384639328004334, Validation Accuracy: 0.8069599474720945\n",
      "Epoch 25/50, Training Loss: 0.3772510929214047\n",
      "Epoch 25/50, Validation Loss: 0.44022241724333216, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 26/50, Training Loss: 0.3750327614593146\n",
      "Epoch 26/50, Validation Loss: 0.43885070359071043, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 27/50, Training Loss: 0.37376555303732556\n",
      "Epoch 27/50, Validation Loss: 0.4382378718576818, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 28/50, Training Loss: 0.37377021037863467\n",
      "Epoch 28/50, Validation Loss: 0.4333019225775259, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 29/50, Training Loss: 0.373128110000233\n",
      "Epoch 29/50, Validation Loss: 0.46082905309606365, Validation Accuracy: 0.7846355876559422\n",
      "Epoch 30/50, Training Loss: 0.37191641119521435\n",
      "Epoch 30/50, Validation Loss: 0.43895236824526995, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 31/50, Training Loss: 0.37198681882008167\n",
      "Epoch 31/50, Validation Loss: 0.4505934054763373, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 32/50, Training Loss: 0.3728338022889897\n",
      "Epoch 32/50, Validation Loss: 0.4432782439846565, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 33/50, Training Loss: 0.37167457217384825\n",
      "Epoch 33/50, Validation Loss: 0.43450390524108995, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 34/50, Training Loss: 0.36974134842261397\n",
      "Epoch 34/50, Validation Loss: 0.4337646653046783, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 35/50, Training Loss: 0.3715617846785568\n",
      "Epoch 35/50, Validation Loss: 0.44076357493225815, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 36/50, Training Loss: 0.3691072045798533\n",
      "Epoch 36/50, Validation Loss: 0.43895891177619156, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 37/50, Training Loss: 0.3694728467310351\n",
      "Epoch 37/50, Validation Loss: 0.4497928618750881, Validation Accuracy: 0.799080761654629\n",
      "Epoch 38/50, Training Loss: 0.36918547838984983\n",
      "Epoch 38/50, Validation Loss: 0.4401164959862594, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 39/50, Training Loss: 0.36834887508058484\n",
      "Epoch 39/50, Validation Loss: 0.44360307309561997, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 40/50, Training Loss: 0.3673231141675958\n",
      "Epoch 40/50, Validation Loss: 0.4350402209303142, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 41/50, Training Loss: 0.36508972033995185\n",
      "Epoch 41/50, Validation Loss: 0.4426146557271793, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 42/50, Training Loss: 0.3675704564009439\n",
      "Epoch 42/50, Validation Loss: 0.4361112891642757, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 43/50, Training Loss: 0.3666630401043832\n",
      "Epoch 43/50, Validation Loss: 0.436371808320635, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 44/50, Training Loss: 0.3658247519812481\n",
      "Epoch 44/50, Validation Loss: 0.43412838270643933, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 45/50, Training Loss: 0.3645722077587458\n",
      "Epoch 45/50, Validation Loss: 0.4377095035389456, Validation Accuracy: 0.8220617202889035\n",
      "Epoch 46/50, Training Loss: 0.3628784977535172\n",
      "Epoch 46/50, Validation Loss: 0.4327000804069935, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 47/50, Training Loss: 0.36588245407822406\n",
      "Epoch 47/50, Validation Loss: 0.4819095268533492, Validation Accuracy: 0.7701904136572554\n",
      "Epoch 48/50, Training Loss: 0.364848276925349\n",
      "Epoch 48/50, Validation Loss: 0.4634914509903308, Validation Accuracy: 0.7820091923834537\n",
      "Epoch 49/50, Training Loss: 0.3641929778067537\n",
      "Epoch 49/50, Validation Loss: 0.43352247968179547, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 50/50, Training Loss: 0.3612767260306542\n",
      "Epoch 50/50, Validation Loss: 0.43511802704604974, Validation Accuracy: 0.8063033486539725\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/50, Training Loss: 0.5151724562127133\n",
      "Epoch 1/50, Validation Loss: 0.45104798214285785, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 2/50, Training Loss: 0.44127577936320794\n",
      "Epoch 2/50, Validation Loss: 0.4170251288963238, Validation Accuracy: 0.8226018396846255\n",
      "Epoch 3/50, Training Loss: 0.4252944387143522\n",
      "Epoch 3/50, Validation Loss: 0.4070525036159298, Validation Accuracy: 0.8298291721419185\n",
      "Epoch 4/50, Training Loss: 0.4212525812444568\n",
      "Epoch 4/50, Validation Loss: 0.40875697379727016, Validation Accuracy: 0.8252299605781866\n",
      "Epoch 5/50, Training Loss: 0.41387218916959806\n",
      "Epoch 5/50, Validation Loss: 0.4246446457325788, Validation Accuracy: 0.8173455978975033\n",
      "Epoch 6/50, Training Loss: 0.4125028371693581\n",
      "Epoch 6/50, Validation Loss: 0.4059628128264275, Validation Accuracy: 0.828515111695138\n",
      "Epoch 7/50, Training Loss: 0.40906892574130704\n",
      "Epoch 7/50, Validation Loss: 0.42190240735080853, Validation Accuracy: 0.816688567674113\n",
      "Epoch 8/50, Training Loss: 0.4044953036339577\n",
      "Epoch 8/50, Validation Loss: 0.3981046990652359, Validation Accuracy: 0.8245729303547963\n",
      "Epoch 9/50, Training Loss: 0.4042766665810049\n",
      "Epoch 9/50, Validation Loss: 0.3972468589339893, Validation Accuracy: 0.8298291721419185\n",
      "Epoch 10/50, Training Loss: 0.400708011476191\n",
      "Epoch 10/50, Validation Loss: 0.3993299294906761, Validation Accuracy: 0.8219448094612353\n",
      "Epoch 11/50, Training Loss: 0.40182429726120683\n",
      "Epoch 11/50, Validation Loss: 0.4018452201058103, Validation Accuracy: 0.8258869908015769\n",
      "Epoch 12/50, Training Loss: 0.4008731732286728\n",
      "Epoch 12/50, Validation Loss: 0.3988084330355154, Validation Accuracy: 0.831143232588699\n",
      "Epoch 13/50, Training Loss: 0.3975241231265187\n",
      "Epoch 13/50, Validation Loss: 0.3992559306265016, Validation Accuracy: 0.8212877792378449\n",
      "Epoch 14/50, Training Loss: 0.3951655021108433\n",
      "Epoch 14/50, Validation Loss: 0.4024197825508592, Validation Accuracy: 0.828515111695138\n",
      "Epoch 15/50, Training Loss: 0.3956763052144467\n",
      "Epoch 15/50, Validation Loss: 0.40344897182707073, Validation Accuracy: 0.8265440210249672\n",
      "Epoch 16/50, Training Loss: 0.3922446565580337\n",
      "Epoch 16/50, Validation Loss: 0.3972448465750792, Validation Accuracy: 0.8232588699080158\n",
      "Epoch 17/50, Training Loss: 0.3932058485542617\n",
      "Epoch 17/50, Validation Loss: 0.4083811655952668, Validation Accuracy: 0.8245729303547963\n",
      "Epoch 18/50, Training Loss: 0.3923406704693172\n",
      "Epoch 18/50, Validation Loss: 0.3961287914185312, Validation Accuracy: 0.8212877792378449\n",
      "Epoch 19/50, Training Loss: 0.39051474160038113\n",
      "Epoch 19/50, Validation Loss: 0.39734127867908375, Validation Accuracy: 0.831143232588699\n",
      "Epoch 20/50, Training Loss: 0.38887252958779883\n",
      "Epoch 20/50, Validation Loss: 0.39873361525111173, Validation Accuracy: 0.8160315374507228\n",
      "Epoch 21/50, Training Loss: 0.38810853060735806\n",
      "Epoch 21/50, Validation Loss: 0.3965268789922224, Validation Accuracy: 0.8331143232588699\n",
      "Epoch 22/50, Training Loss: 0.3892066006736923\n",
      "Epoch 22/50, Validation Loss: 0.3994002866787904, Validation Accuracy: 0.8304862023653088\n",
      "Epoch 23/50, Training Loss: 0.3856769144398177\n",
      "Epoch 23/50, Validation Loss: 0.3968571003487441, Validation Accuracy: 0.8298291721419185\n",
      "Epoch 24/50, Training Loss: 0.38554798345279506\n",
      "Epoch 24/50, Validation Loss: 0.3987101473265293, Validation Accuracy: 0.8298291721419185\n",
      "Epoch 25/50, Training Loss: 0.384720886522156\n",
      "Epoch 25/50, Validation Loss: 0.4038986611223892, Validation Accuracy: 0.8180026281208935\n",
      "Epoch 26/50, Training Loss: 0.3854421719938047\n",
      "Epoch 26/50, Validation Loss: 0.39799749716160654, Validation Accuracy: 0.8212877792378449\n",
      "Epoch 27/50, Training Loss: 0.3818778356639888\n",
      "Epoch 27/50, Validation Loss: 0.3986495049153479, Validation Accuracy: 0.8318002628120894\n",
      "Epoch 28/50, Training Loss: 0.38274071976698915\n",
      "Epoch 28/50, Validation Loss: 0.400107338917271, Validation Accuracy: 0.8265440210249672\n",
      "Epoch 29/50, Training Loss: 0.3807689754605254\n",
      "Epoch 29/50, Validation Loss: 0.39768364230726716, Validation Accuracy: 0.8265440210249672\n",
      "Epoch 30/50, Training Loss: 0.38264380729808584\n",
      "Epoch 30/50, Validation Loss: 0.39907795540422825, Validation Accuracy: 0.8252299605781866\n",
      "Epoch 31/50, Training Loss: 0.3811834395381566\n",
      "Epoch 31/50, Validation Loss: 0.400384203384567, Validation Accuracy: 0.8219448094612353\n",
      "Epoch 32/50, Training Loss: 0.3784664608440374\n",
      "Epoch 32/50, Validation Loss: 0.3984210379519232, Validation Accuracy: 0.8265440210249672\n",
      "Epoch 33/50, Training Loss: 0.3796812616034443\n",
      "Epoch 33/50, Validation Loss: 0.3970768287660876, Validation Accuracy: 0.8252299605781866\n",
      "Epoch 34/50, Training Loss: 0.378400331974186\n",
      "Epoch 34/50, Validation Loss: 0.40067388233363005, Validation Accuracy: 0.8324572930354797\n",
      "Epoch 35/50, Training Loss: 0.378150419901636\n",
      "Epoch 35/50, Validation Loss: 0.41177997810288247, Validation Accuracy: 0.823915900131406\n",
      "Epoch 36/50, Training Loss: 0.3775811616302006\n",
      "Epoch 36/50, Validation Loss: 0.3969920286274861, Validation Accuracy: 0.823915900131406\n",
      "Epoch 37/50, Training Loss: 0.3784761168796012\n",
      "Epoch 37/50, Validation Loss: 0.39795285940209296, Validation Accuracy: 0.8278580814717477\n",
      "Epoch 38/50, Training Loss: 0.3755727015445473\n",
      "Epoch 38/50, Validation Loss: 0.43048880325327993, Validation Accuracy: 0.8153745072273325\n",
      "Epoch 39/50, Training Loss: 0.37670765399659084\n",
      "Epoch 39/50, Validation Loss: 0.3974911777634193, Validation Accuracy: 0.8258869908015769\n",
      "Epoch 40/50, Training Loss: 0.3777847218319891\n",
      "Epoch 40/50, Validation Loss: 0.3969697542196013, Validation Accuracy: 0.8232588699080158\n",
      "Epoch 41/50, Training Loss: 0.37656966268312275\n",
      "Epoch 41/50, Validation Loss: 0.3969394254122729, Validation Accuracy: 0.8232588699080158\n",
      "Epoch 42/50, Training Loss: 0.37329451777432066\n",
      "Epoch 42/50, Validation Loss: 0.39724372053294593, Validation Accuracy: 0.8226018396846255\n",
      "Epoch 43/50, Training Loss: 0.3761158829794468\n",
      "Epoch 43/50, Validation Loss: 0.40107943843172483, Validation Accuracy: 0.8265440210249672\n",
      "Epoch 44/50, Training Loss: 0.3744037622375673\n",
      "Epoch 44/50, Validation Loss: 0.40022068107451914, Validation Accuracy: 0.8232588699080158\n",
      "Epoch 45/50, Training Loss: 0.37161630934734985\n",
      "Epoch 45/50, Validation Loss: 0.40294203894573666, Validation Accuracy: 0.8160315374507228\n",
      "Epoch 46/50, Training Loss: 0.3732642832644812\n",
      "Epoch 46/50, Validation Loss: 0.4027622515598985, Validation Accuracy: 0.8278580814717477\n",
      "Epoch 47/50, Training Loss: 0.37341050303289347\n",
      "Epoch 47/50, Validation Loss: 0.3986855137859183, Validation Accuracy: 0.8265440210249672\n",
      "Epoch 48/50, Training Loss: 0.3715635994913697\n",
      "Epoch 48/50, Validation Loss: 0.3999483544594018, Validation Accuracy: 0.831143232588699\n",
      "Epoch 49/50, Training Loss: 0.3739148013029746\n",
      "Epoch 49/50, Validation Loss: 0.39786683341868573, Validation Accuracy: 0.823915900131406\n",
      "Epoch 50/50, Training Loss: 0.3710066804276129\n",
      "Epoch 50/50, Validation Loss: 0.40423095056601843, Validation Accuracy: 0.8173455978975033\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/50, Training Loss: 0.5112622048011602\n",
      "Epoch 1/50, Validation Loss: 0.4527228058398706, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 2/50, Training Loss: 0.4365704734846363\n",
      "Epoch 2/50, Validation Loss: 0.42999472902083274, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 3/50, Training Loss: 0.4207976754520118\n",
      "Epoch 3/50, Validation Loss: 0.4364544985455056, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 4/50, Training Loss: 0.4168740222597216\n",
      "Epoch 4/50, Validation Loss: 0.42080448671239207, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 5/50, Training Loss: 0.4092533532676734\n",
      "Epoch 5/50, Validation Loss: 0.42062087852449315, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 6/50, Training Loss: 0.4051594455724\n",
      "Epoch 6/50, Validation Loss: 0.42474562379273134, Validation Accuracy: 0.7943495400788436\n",
      "Epoch 7/50, Training Loss: 0.40296308241608575\n",
      "Epoch 7/50, Validation Loss: 0.42041684930939327, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 8/50, Training Loss: 0.3988907504680119\n",
      "Epoch 8/50, Validation Loss: 0.4240925681743166, Validation Accuracy: 0.8147174770039421\n",
      "Epoch 9/50, Training Loss: 0.39734841046947744\n",
      "Epoch 9/50, Validation Loss: 0.429699861605442, Validation Accuracy: 0.812089356110381\n",
      "Epoch 10/50, Training Loss: 0.39665133746590203\n",
      "Epoch 10/50, Validation Loss: 0.4183924576823468, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 11/50, Training Loss: 0.39473099812004825\n",
      "Epoch 11/50, Validation Loss: 0.42647478215552437, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 12/50, Training Loss: 0.3921395543024061\n",
      "Epoch 12/50, Validation Loss: 0.4181716068311355, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 13/50, Training Loss: 0.38998324408873014\n",
      "Epoch 13/50, Validation Loss: 0.4193089002285016, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 14/50, Training Loss: 0.39196430501623414\n",
      "Epoch 14/50, Validation Loss: 0.4253282266381289, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 15/50, Training Loss: 0.3896326639266621\n",
      "Epoch 15/50, Validation Loss: 0.41740912571549416, Validation Accuracy: 0.812089356110381\n",
      "Epoch 16/50, Training Loss: 0.38765246844471596\n",
      "Epoch 16/50, Validation Loss: 0.42336214914020753, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 17/50, Training Loss: 0.3854549292308765\n",
      "Epoch 17/50, Validation Loss: 0.418401823891083, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 18/50, Training Loss: 0.38463453867343156\n",
      "Epoch 18/50, Validation Loss: 0.41933067613013125, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 19/50, Training Loss: 0.383255565084341\n",
      "Epoch 19/50, Validation Loss: 0.422966195816535, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 20/50, Training Loss: 0.3828648242322127\n",
      "Epoch 20/50, Validation Loss: 0.4285912679030477, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 21/50, Training Loss: 0.38289034853535375\n",
      "Epoch 21/50, Validation Loss: 0.42382451255089015, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 22/50, Training Loss: 0.3814936061817517\n",
      "Epoch 22/50, Validation Loss: 0.4210614591095772, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 23/50, Training Loss: 0.3797227419091491\n",
      "Epoch 23/50, Validation Loss: 0.4230181531522286, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 24/50, Training Loss: 0.3801549927055288\n",
      "Epoch 24/50, Validation Loss: 0.4222145335095403, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 25/50, Training Loss: 0.37634015734016585\n",
      "Epoch 25/50, Validation Loss: 0.4313511312134681, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 26/50, Training Loss: 0.37834475093137404\n",
      "Epoch 26/50, Validation Loss: 0.4279474439489514, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 27/50, Training Loss: 0.3768011967839766\n",
      "Epoch 27/50, Validation Loss: 0.4249116399847166, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 28/50, Training Loss: 0.37589874643627114\n",
      "Epoch 28/50, Validation Loss: 0.4230461202815409, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 29/50, Training Loss: 0.375785357991033\n",
      "Epoch 29/50, Validation Loss: 0.41870541720412163, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 30/50, Training Loss: 0.37395434087421014\n",
      "Epoch 30/50, Validation Loss: 0.42913015512505753, Validation Accuracy: 0.80946123521682\n",
      "Epoch 31/50, Training Loss: 0.3745327006556152\n",
      "Epoch 31/50, Validation Loss: 0.42399016346450874, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 32/50, Training Loss: 0.37464320666481815\n",
      "Epoch 32/50, Validation Loss: 0.41992113187284996, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 33/50, Training Loss: 0.37370207137244893\n",
      "Epoch 33/50, Validation Loss: 0.4210424160204477, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 34/50, Training Loss: 0.37178826860086184\n",
      "Epoch 34/50, Validation Loss: 0.4278102153570864, Validation Accuracy: 0.80946123521682\n",
      "Epoch 35/50, Training Loss: 0.37284450364003346\n",
      "Epoch 35/50, Validation Loss: 0.42562072909393234, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 36/50, Training Loss: 0.3703317108302526\n",
      "Epoch 36/50, Validation Loss: 0.4242819729626803, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 37/50, Training Loss: 0.37104990058077447\n",
      "Epoch 37/50, Validation Loss: 0.4257776591712268, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 38/50, Training Loss: 0.36970443331839375\n",
      "Epoch 38/50, Validation Loss: 0.4341651944745898, Validation Accuracy: 0.797634691195795\n",
      "Epoch 39/50, Training Loss: 0.3695496025096791\n",
      "Epoch 39/50, Validation Loss: 0.4225978750384447, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 40/50, Training Loss: 0.3680568345507064\n",
      "Epoch 40/50, Validation Loss: 0.42389484704594027, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 41/50, Training Loss: 0.36750572534116704\n",
      "Epoch 41/50, Validation Loss: 0.4245767536334186, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 42/50, Training Loss: 0.3675603361805202\n",
      "Epoch 42/50, Validation Loss: 0.42207546509724325, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 43/50, Training Loss: 0.3676574795196454\n",
      "Epoch 43/50, Validation Loss: 0.42191166487273746, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 44/50, Training Loss: 0.3669002043019755\n",
      "Epoch 44/50, Validation Loss: 0.4375264251468147, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 45/50, Training Loss: 0.3672551468327602\n",
      "Epoch 45/50, Validation Loss: 0.424982608569035, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 46/50, Training Loss: 0.3674648645483055\n",
      "Epoch 46/50, Validation Loss: 0.43560500278171754, Validation Accuracy: 0.804862023653088\n",
      "Epoch 47/50, Training Loss: 0.3681023067494077\n",
      "Epoch 47/50, Validation Loss: 0.4250911563264294, Validation Accuracy: 0.80946123521682\n",
      "Epoch 48/50, Training Loss: 0.3645190090341909\n",
      "Epoch 48/50, Validation Loss: 0.4417775006213893, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 49/50, Training Loss: 0.363768312566745\n",
      "Epoch 49/50, Validation Loss: 0.4265714936465493, Validation Accuracy: 0.812089356110381\n",
      "Epoch 50/50, Training Loss: 0.36465075675623\n",
      "Epoch 50/50, Validation Loss: 0.42471778542486005, Validation Accuracy: 0.8101182654402103\n",
      "Average Validation Accuracy: 0.8140022933504054\n",
      "Number of Epochs: 50\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/60, Training Loss: 0.5079636498112378\n",
      "Epoch 1/60, Validation Loss: 0.44909344106444515, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 2/60, Training Loss: 0.4356942533899167\n",
      "Epoch 2/60, Validation Loss: 0.43841779795694724, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 3/60, Training Loss: 0.4222337319625644\n",
      "Epoch 3/60, Validation Loss: 0.43246533793850717, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 4/60, Training Loss: 0.4154470851962648\n",
      "Epoch 4/60, Validation Loss: 0.4179400292795678, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 5/60, Training Loss: 0.41210989276646315\n",
      "Epoch 5/60, Validation Loss: 0.4210778069316717, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 6/60, Training Loss: 0.4082462575452847\n",
      "Epoch 6/60, Validation Loss: 0.46263562277427517, Validation Accuracy: 0.804333552199606\n",
      "Epoch 7/60, Training Loss: 0.4060845156530226\n",
      "Epoch 7/60, Validation Loss: 0.43513494546656833, Validation Accuracy: 0.814182534471438\n",
      "Epoch 8/60, Training Loss: 0.40332537941302216\n",
      "Epoch 8/60, Validation Loss: 0.4159890081323878, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 9/60, Training Loss: 0.40034247448379445\n",
      "Epoch 9/60, Validation Loss: 0.41885203992977194, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 10/60, Training Loss: 0.3976100276510312\n",
      "Epoch 10/60, Validation Loss: 0.4187361969958737, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 11/60, Training Loss: 0.3966054522244167\n",
      "Epoch 11/60, Validation Loss: 0.4144443339078214, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 12/60, Training Loss: 0.39390512660458643\n",
      "Epoch 12/60, Validation Loss: 0.41288986363258035, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 13/60, Training Loss: 0.39348169776985026\n",
      "Epoch 13/60, Validation Loss: 0.41975417506944446, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 14/60, Training Loss: 0.3931626112608537\n",
      "Epoch 14/60, Validation Loss: 0.41580435380105574, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 15/60, Training Loss: 0.3909888303547785\n",
      "Epoch 15/60, Validation Loss: 0.4136012406795437, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 16/60, Training Loss: 0.38909513998062906\n",
      "Epoch 16/60, Validation Loss: 0.4151266569086394, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 17/60, Training Loss: 0.38752142535009254\n",
      "Epoch 17/60, Validation Loss: 0.4157989510768995, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 18/60, Training Loss: 0.3855552285362103\n",
      "Epoch 18/60, Validation Loss: 0.42051311601831026, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 19/60, Training Loss: 0.3858818226833669\n",
      "Epoch 19/60, Validation Loss: 0.41390320487047366, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 20/60, Training Loss: 0.384011280798693\n",
      "Epoch 20/60, Validation Loss: 0.42127009684034666, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 21/60, Training Loss: 0.3830603645024259\n",
      "Epoch 21/60, Validation Loss: 0.41467783658604346, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 22/60, Training Loss: 0.3805711601721489\n",
      "Epoch 22/60, Validation Loss: 0.43424594267734684, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 23/60, Training Loss: 0.3826188099939679\n",
      "Epoch 23/60, Validation Loss: 0.41464498393354615, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 24/60, Training Loss: 0.38107591985756645\n",
      "Epoch 24/60, Validation Loss: 0.41772053901749756, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 25/60, Training Loss: 0.38090188793466473\n",
      "Epoch 25/60, Validation Loss: 0.424946241227042, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 26/60, Training Loss: 0.37935966937717175\n",
      "Epoch 26/60, Validation Loss: 0.4181285665531433, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 27/60, Training Loss: 0.3800263305847335\n",
      "Epoch 27/60, Validation Loss: 0.4260238244622478, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 28/60, Training Loss: 0.3785885232219624\n",
      "Epoch 28/60, Validation Loss: 0.42946338663316524, Validation Accuracy: 0.799080761654629\n",
      "Epoch 29/60, Training Loss: 0.37864571323818735\n",
      "Epoch 29/60, Validation Loss: 0.42238706447847224, Validation Accuracy: 0.814182534471438\n",
      "Epoch 30/60, Training Loss: 0.37552577304089163\n",
      "Epoch 30/60, Validation Loss: 0.4184078843337703, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 31/60, Training Loss: 0.3764823979241016\n",
      "Epoch 31/60, Validation Loss: 0.4219024561306569, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 32/60, Training Loss: 0.377111041566401\n",
      "Epoch 32/60, Validation Loss: 0.4141648232507768, Validation Accuracy: 0.8220617202889035\n",
      "Epoch 33/60, Training Loss: 0.37538495613384276\n",
      "Epoch 33/60, Validation Loss: 0.414949677640777, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 34/60, Training Loss: 0.3768361409896315\n",
      "Epoch 34/60, Validation Loss: 0.42544731029665284, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 35/60, Training Loss: 0.3731664195461223\n",
      "Epoch 35/60, Validation Loss: 0.4207272185646583, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 36/60, Training Loss: 0.3718057504202437\n",
      "Epoch 36/60, Validation Loss: 0.41569554596086133, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 37/60, Training Loss: 0.3767589681740273\n",
      "Epoch 37/60, Validation Loss: 0.41766095006380094, Validation Accuracy: 0.814182534471438\n",
      "Epoch 38/60, Training Loss: 0.37412826894364487\n",
      "Epoch 38/60, Validation Loss: 0.41542754445166485, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 39/60, Training Loss: 0.37197819054908954\n",
      "Epoch 39/60, Validation Loss: 0.41905029490590096, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 40/60, Training Loss: 0.36911799148057545\n",
      "Epoch 40/60, Validation Loss: 0.42379410188469585, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 41/60, Training Loss: 0.37143433199134557\n",
      "Epoch 41/60, Validation Loss: 0.42109065539939866, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 42/60, Training Loss: 0.3696957444869901\n",
      "Epoch 42/60, Validation Loss: 0.41692237410674854, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 43/60, Training Loss: 0.3689268421591932\n",
      "Epoch 43/60, Validation Loss: 0.41749036060499894, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 44/60, Training Loss: 0.3693824691546401\n",
      "Epoch 44/60, Validation Loss: 0.4171891803438751, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 45/60, Training Loss: 0.3668882002873136\n",
      "Epoch 45/60, Validation Loss: 0.4209822143150094, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 46/60, Training Loss: 0.3670927553664981\n",
      "Epoch 46/60, Validation Loss: 0.42169008407917324, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 47/60, Training Loss: 0.3677448624881899\n",
      "Epoch 47/60, Validation Loss: 0.4200663579462086, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 48/60, Training Loss: 0.3673323830137435\n",
      "Epoch 48/60, Validation Loss: 0.4217883804764267, Validation Accuracy: 0.814182534471438\n",
      "Epoch 49/60, Training Loss: 0.36696508160139635\n",
      "Epoch 49/60, Validation Loss: 0.42389143745936647, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 50/60, Training Loss: 0.36889323644985367\n",
      "Epoch 50/60, Validation Loss: 0.4222642187692264, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 51/60, Training Loss: 0.3656390453065474\n",
      "Epoch 51/60, Validation Loss: 0.42226833469814656, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 52/60, Training Loss: 0.36766116069800897\n",
      "Epoch 52/60, Validation Loss: 0.4205481341274465, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 53/60, Training Loss: 0.36604003807202257\n",
      "Epoch 53/60, Validation Loss: 0.44043784567120814, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 54/60, Training Loss: 0.3642092980395543\n",
      "Epoch 54/60, Validation Loss: 0.4180171156097301, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 55/60, Training Loss: 0.3649889709735949\n",
      "Epoch 55/60, Validation Loss: 0.4194783682774031, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 56/60, Training Loss: 0.3638042631629962\n",
      "Epoch 56/60, Validation Loss: 0.42218958335826223, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 57/60, Training Loss: 0.3644057450488484\n",
      "Epoch 57/60, Validation Loss: 0.421068873119916, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 58/60, Training Loss: 0.36436478898242075\n",
      "Epoch 58/60, Validation Loss: 0.4193571480820004, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 59/60, Training Loss: 0.36265095847407036\n",
      "Epoch 59/60, Validation Loss: 0.458803003663636, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 60/60, Training Loss: 0.3661470308684771\n",
      "Epoch 60/60, Validation Loss: 0.42006426024694404, Validation Accuracy: 0.814182534471438\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/60, Training Loss: 0.5030850864105963\n",
      "Epoch 1/60, Validation Loss: 0.4416568183306, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 2/60, Training Loss: 0.4368013304773122\n",
      "Epoch 2/60, Validation Loss: 0.42266843023256484, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 3/60, Training Loss: 0.4233039142246165\n",
      "Epoch 3/60, Validation Loss: 0.4336906264960298, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 4/60, Training Loss: 0.41535133705168886\n",
      "Epoch 4/60, Validation Loss: 0.4570360733537462, Validation Accuracy: 0.7728168089297439\n",
      "Epoch 5/60, Training Loss: 0.4136932111611673\n",
      "Epoch 5/60, Validation Loss: 0.41295773707603284, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 6/60, Training Loss: 0.4080915239167808\n",
      "Epoch 6/60, Validation Loss: 0.4196754273378256, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 7/60, Training Loss: 0.4052247592978903\n",
      "Epoch 7/60, Validation Loss: 0.4115829732639627, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 8/60, Training Loss: 0.4025794922660186\n",
      "Epoch 8/60, Validation Loss: 0.4113589805789799, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 9/60, Training Loss: 0.4002691347816876\n",
      "Epoch 9/60, Validation Loss: 0.41380141958282257, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 10/60, Training Loss: 0.39937687598735955\n",
      "Epoch 10/60, Validation Loss: 0.416319146830374, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 11/60, Training Loss: 0.3974133559436662\n",
      "Epoch 11/60, Validation Loss: 0.41214013714050746, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 12/60, Training Loss: 0.3946337006555924\n",
      "Epoch 12/60, Validation Loss: 0.41090411363237817, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 13/60, Training Loss: 0.39488255499991687\n",
      "Epoch 13/60, Validation Loss: 0.409544575379196, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 14/60, Training Loss: 0.39358013410737197\n",
      "Epoch 14/60, Validation Loss: 0.4198508466501277, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 15/60, Training Loss: 0.3907128091745098\n",
      "Epoch 15/60, Validation Loss: 0.4169018689679538, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 16/60, Training Loss: 0.3896747824841049\n",
      "Epoch 16/60, Validation Loss: 0.4077679939782588, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 17/60, Training Loss: 0.38969262622375034\n",
      "Epoch 17/60, Validation Loss: 0.4135466013591327, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 18/60, Training Loss: 0.3867767321586296\n",
      "Epoch 18/60, Validation Loss: 0.40848909918199344, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 19/60, Training Loss: 0.3850713032456677\n",
      "Epoch 19/60, Validation Loss: 0.41430749003019635, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 20/60, Training Loss: 0.3875883495352008\n",
      "Epoch 20/60, Validation Loss: 0.4128005215166751, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 21/60, Training Loss: 0.38618603338465446\n",
      "Epoch 21/60, Validation Loss: 0.4203741017885077, Validation Accuracy: 0.8174655285620486\n",
      "Epoch 22/60, Training Loss: 0.3818027445914473\n",
      "Epoch 22/60, Validation Loss: 0.40889880513645593, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 23/60, Training Loss: 0.38172102061019636\n",
      "Epoch 23/60, Validation Loss: 0.41038516210635917, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 24/60, Training Loss: 0.38246426381307636\n",
      "Epoch 24/60, Validation Loss: 0.4116274956321217, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 25/60, Training Loss: 0.38095710866563903\n",
      "Epoch 25/60, Validation Loss: 0.4096120714322123, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 26/60, Training Loss: 0.38043628454091044\n",
      "Epoch 26/60, Validation Loss: 0.4228487595213645, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 27/60, Training Loss: 0.3807031839714432\n",
      "Epoch 27/60, Validation Loss: 0.40976887085128827, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 28/60, Training Loss: 0.37820294604262733\n",
      "Epoch 28/60, Validation Loss: 0.40983933442472165, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 29/60, Training Loss: 0.3769630246411941\n",
      "Epoch 29/60, Validation Loss: 0.46214011817419637, Validation Accuracy: 0.7787261982928431\n",
      "Epoch 30/60, Training Loss: 0.3779631671385737\n",
      "Epoch 30/60, Validation Loss: 0.4128365931515606, Validation Accuracy: 0.8220617202889035\n",
      "Epoch 31/60, Training Loss: 0.3760456649875\n",
      "Epoch 31/60, Validation Loss: 0.4109642494430873, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 32/60, Training Loss: 0.3742578115871572\n",
      "Epoch 32/60, Validation Loss: 0.41268272544818085, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 33/60, Training Loss: 0.3748163757772427\n",
      "Epoch 33/60, Validation Loss: 0.41166858564262615, Validation Accuracy: 0.8069599474720945\n",
      "Epoch 34/60, Training Loss: 0.37454424313516443\n",
      "Epoch 34/60, Validation Loss: 0.4285895541866178, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 35/60, Training Loss: 0.37637848453962897\n",
      "Epoch 35/60, Validation Loss: 0.41055391051109236, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 36/60, Training Loss: 0.37504582558795224\n",
      "Epoch 36/60, Validation Loss: 0.42100722842035493, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 37/60, Training Loss: 0.37535812446647115\n",
      "Epoch 37/60, Validation Loss: 0.419227126371408, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 38/60, Training Loss: 0.37434825027395735\n",
      "Epoch 38/60, Validation Loss: 0.4183932066509861, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 39/60, Training Loss: 0.3706646106961205\n",
      "Epoch 39/60, Validation Loss: 0.43034999871246166, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 40/60, Training Loss: 0.3715211479066629\n",
      "Epoch 40/60, Validation Loss: 0.4373009415216627, Validation Accuracy: 0.788575180564675\n",
      "Epoch 41/60, Training Loss: 0.3725274751045964\n",
      "Epoch 41/60, Validation Loss: 0.41607007377961386, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 42/60, Training Loss: 0.36922421537613465\n",
      "Epoch 42/60, Validation Loss: 0.4116472111459022, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 43/60, Training Loss: 0.36887603023839904\n",
      "Epoch 43/60, Validation Loss: 0.41274962216830224, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 44/60, Training Loss: 0.3699551710902941\n",
      "Epoch 44/60, Validation Loss: 0.41132877594962014, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 45/60, Training Loss: 0.36979849736775783\n",
      "Epoch 45/60, Validation Loss: 0.4162196347207143, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 46/60, Training Loss: 0.3692853113347933\n",
      "Epoch 46/60, Validation Loss: 0.41199675614882203, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 47/60, Training Loss: 0.3699925125300337\n",
      "Epoch 47/60, Validation Loss: 0.41782893621757705, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 48/60, Training Loss: 0.3683593110658052\n",
      "Epoch 48/60, Validation Loss: 0.41750182171415595, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 49/60, Training Loss: 0.370575680497672\n",
      "Epoch 49/60, Validation Loss: 0.4166636123999719, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 50/60, Training Loss: 0.36618212913957443\n",
      "Epoch 50/60, Validation Loss: 0.4126639610585508, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 51/60, Training Loss: 0.36716125729026916\n",
      "Epoch 51/60, Validation Loss: 0.41889642549590916, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 52/60, Training Loss: 0.36774911858591197\n",
      "Epoch 52/60, Validation Loss: 0.41448658689154383, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 53/60, Training Loss: 0.36578674987447385\n",
      "Epoch 53/60, Validation Loss: 0.45385964852099486, Validation Accuracy: 0.7813525935653316\n",
      "Epoch 54/60, Training Loss: 0.36515485520750834\n",
      "Epoch 54/60, Validation Loss: 0.4189858349010894, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 55/60, Training Loss: 0.36532647768402193\n",
      "Epoch 55/60, Validation Loss: 0.4196895902186476, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 56/60, Training Loss: 0.36399924758029734\n",
      "Epoch 56/60, Validation Loss: 0.41921865243308676, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 57/60, Training Loss: 0.3646402202761705\n",
      "Epoch 57/60, Validation Loss: 0.4149171456167991, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 58/60, Training Loss: 0.36609701819600554\n",
      "Epoch 58/60, Validation Loss: 0.42507629134053493, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 59/60, Training Loss: 0.36340813772395997\n",
      "Epoch 59/60, Validation Loss: 0.4138243557563471, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 60/60, Training Loss: 0.36503160710683646\n",
      "Epoch 60/60, Validation Loss: 0.4514720982174677, Validation Accuracy: 0.8089297439264609\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/60, Training Loss: 0.5116960172030557\n",
      "Epoch 1/60, Validation Loss: 0.4734948601632218, Validation Accuracy: 0.7767564018384767\n",
      "Epoch 2/60, Training Loss: 0.43455268283254833\n",
      "Epoch 2/60, Validation Loss: 0.4465159368725659, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 3/60, Training Loss: 0.41756748057060983\n",
      "Epoch 3/60, Validation Loss: 0.43585571293665476, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 4/60, Training Loss: 0.40938799707047896\n",
      "Epoch 4/60, Validation Loss: 0.4375257386938128, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 5/60, Training Loss: 0.40567523187265936\n",
      "Epoch 5/60, Validation Loss: 0.43748224782147954, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 6/60, Training Loss: 0.40186918413955863\n",
      "Epoch 6/60, Validation Loss: 0.4335003522522162, Validation Accuracy: 0.81483913328956\n",
      "Epoch 7/60, Training Loss: 0.400055354661516\n",
      "Epoch 7/60, Validation Loss: 0.43551927099872323, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 8/60, Training Loss: 0.3980303538518315\n",
      "Epoch 8/60, Validation Loss: 0.4339272921895169, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 9/60, Training Loss: 0.39617294573721296\n",
      "Epoch 9/60, Validation Loss: 0.46709416688697813, Validation Accuracy: 0.767564018384767\n",
      "Epoch 10/60, Training Loss: 0.3954762740114464\n",
      "Epoch 10/60, Validation Loss: 0.458590045824881, Validation Accuracy: 0.7839789888378201\n",
      "Epoch 11/60, Training Loss: 0.39233157813079717\n",
      "Epoch 11/60, Validation Loss: 0.4303445084537355, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 12/60, Training Loss: 0.39088897985403775\n",
      "Epoch 12/60, Validation Loss: 0.43875861806668226, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 13/60, Training Loss: 0.3906264047277725\n",
      "Epoch 13/60, Validation Loss: 0.4445400416061126, Validation Accuracy: 0.799080761654629\n",
      "Epoch 14/60, Training Loss: 0.387046694120006\n",
      "Epoch 14/60, Validation Loss: 0.4429371092000401, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 15/60, Training Loss: 0.38717925931349045\n",
      "Epoch 15/60, Validation Loss: 0.43357467220325746, Validation Accuracy: 0.81483913328956\n",
      "Epoch 16/60, Training Loss: 0.384914485923457\n",
      "Epoch 16/60, Validation Loss: 0.44166949917976767, Validation Accuracy: 0.804333552199606\n",
      "Epoch 17/60, Training Loss: 0.38284995045092474\n",
      "Epoch 17/60, Validation Loss: 0.4399331863481961, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 18/60, Training Loss: 0.3822298288110673\n",
      "Epoch 18/60, Validation Loss: 0.43104576668580163, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 19/60, Training Loss: 0.3831911215416872\n",
      "Epoch 19/60, Validation Loss: 0.4360528899922343, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 20/60, Training Loss: 0.38019426363053443\n",
      "Epoch 20/60, Validation Loss: 0.4451901060163351, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 21/60, Training Loss: 0.38028016168712164\n",
      "Epoch 21/60, Validation Loss: 0.43205097424968375, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 22/60, Training Loss: 0.37778806193118175\n",
      "Epoch 22/60, Validation Loss: 0.4360575022868305, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 23/60, Training Loss: 0.3777234144557727\n",
      "Epoch 23/60, Validation Loss: 0.4855060287682993, Validation Accuracy: 0.7570584372948129\n",
      "Epoch 24/60, Training Loss: 0.37674338395005763\n",
      "Epoch 24/60, Validation Loss: 0.43215796189548455, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 25/60, Training Loss: 0.3746923205193396\n",
      "Epoch 25/60, Validation Loss: 0.4365175017765211, Validation Accuracy: 0.8233749179251477\n",
      "Epoch 26/60, Training Loss: 0.3743422651159873\n",
      "Epoch 26/60, Validation Loss: 0.43144965962219145, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 27/60, Training Loss: 0.3745901726352496\n",
      "Epoch 27/60, Validation Loss: 0.4331652689383838, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 28/60, Training Loss: 0.37397533237660335\n",
      "Epoch 28/60, Validation Loss: 0.4325440909118631, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 29/60, Training Loss: 0.3741637597892072\n",
      "Epoch 29/60, Validation Loss: 0.43904709331301184, Validation Accuracy: 0.8207485226526592\n",
      "Epoch 30/60, Training Loss: 0.37326099798376633\n",
      "Epoch 30/60, Validation Loss: 0.4350171384367487, Validation Accuracy: 0.8240315167432699\n",
      "Epoch 31/60, Training Loss: 0.3712406321538715\n",
      "Epoch 31/60, Validation Loss: 0.4334709167929064, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 32/60, Training Loss: 0.3693994205650382\n",
      "Epoch 32/60, Validation Loss: 0.4486462399265997, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 33/60, Training Loss: 0.37107318154783075\n",
      "Epoch 33/60, Validation Loss: 0.4339243720641545, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 34/60, Training Loss: 0.3711355350852951\n",
      "Epoch 34/60, Validation Loss: 0.45093912060289637, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 35/60, Training Loss: 0.37187919560868754\n",
      "Epoch 35/60, Validation Loss: 0.4318057426509901, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 36/60, Training Loss: 0.37009919625450305\n",
      "Epoch 36/60, Validation Loss: 0.43674641596007097, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 37/60, Training Loss: 0.36797413865490536\n",
      "Epoch 37/60, Validation Loss: 0.4405899148639194, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 38/60, Training Loss: 0.3674033912108952\n",
      "Epoch 38/60, Validation Loss: 0.43657550314217025, Validation Accuracy: 0.81483913328956\n",
      "Epoch 39/60, Training Loss: 0.3682464284876122\n",
      "Epoch 39/60, Validation Loss: 0.43707424098947595, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 40/60, Training Loss: 0.3674851312079611\n",
      "Epoch 40/60, Validation Loss: 0.4354644372513157, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 41/60, Training Loss: 0.36584182123695147\n",
      "Epoch 41/60, Validation Loss: 0.43224472955785964, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 42/60, Training Loss: 0.3663164909557486\n",
      "Epoch 42/60, Validation Loss: 0.43740251939256153, Validation Accuracy: 0.8233749179251477\n",
      "Epoch 43/60, Training Loss: 0.36530378286352777\n",
      "Epoch 43/60, Validation Loss: 0.4438679761921314, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 44/60, Training Loss: 0.36498292425544715\n",
      "Epoch 44/60, Validation Loss: 0.43731758072582216, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 45/60, Training Loss: 0.36453773203523454\n",
      "Epoch 45/60, Validation Loss: 0.43805908884716593, Validation Accuracy: 0.804333552199606\n",
      "Epoch 46/60, Training Loss: 0.3642893310127843\n",
      "Epoch 46/60, Validation Loss: 0.43429895113978084, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 47/60, Training Loss: 0.3644034366399597\n",
      "Epoch 47/60, Validation Loss: 0.43377865563239415, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 48/60, Training Loss: 0.36439240904979586\n",
      "Epoch 48/60, Validation Loss: 0.44429460687670097, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 49/60, Training Loss: 0.3642865279958317\n",
      "Epoch 49/60, Validation Loss: 0.43337612245134344, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 50/60, Training Loss: 0.3622506241903217\n",
      "Epoch 50/60, Validation Loss: 0.4447183118187164, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 51/60, Training Loss: 0.3619031976527116\n",
      "Epoch 51/60, Validation Loss: 0.43388131459814094, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 52/60, Training Loss: 0.36102183125033155\n",
      "Epoch 52/60, Validation Loss: 0.435281127847302, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 53/60, Training Loss: 0.360587160249688\n",
      "Epoch 53/60, Validation Loss: 0.43415907947395327, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 54/60, Training Loss: 0.36111630107278586\n",
      "Epoch 54/60, Validation Loss: 0.4340504637105069, Validation Accuracy: 0.814182534471438\n",
      "Epoch 55/60, Training Loss: 0.36091802064867157\n",
      "Epoch 55/60, Validation Loss: 0.434803109021165, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 56/60, Training Loss: 0.36194795960184\n",
      "Epoch 56/60, Validation Loss: 0.4391126924716131, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 57/60, Training Loss: 0.36041387726902335\n",
      "Epoch 57/60, Validation Loss: 0.43830528617860914, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 58/60, Training Loss: 0.35934817906850436\n",
      "Epoch 58/60, Validation Loss: 0.44122869285379407, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 59/60, Training Loss: 0.3591210734578255\n",
      "Epoch 59/60, Validation Loss: 0.4702639936966851, Validation Accuracy: 0.778069599474721\n",
      "Epoch 60/60, Training Loss: 0.3578508778712333\n",
      "Epoch 60/60, Validation Loss: 0.437754167058549, Validation Accuracy: 0.8076165462902167\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/60, Training Loss: 0.513245418413574\n",
      "Epoch 1/60, Validation Loss: 0.4466816822349713, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 2/60, Training Loss: 0.4394651155263733\n",
      "Epoch 2/60, Validation Loss: 0.421162200925862, Validation Accuracy: 0.8180026281208935\n",
      "Epoch 3/60, Training Loss: 0.4256547862502534\n",
      "Epoch 3/60, Validation Loss: 0.4201872018970432, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 4/60, Training Loss: 0.420289749724502\n",
      "Epoch 4/60, Validation Loss: 0.40607643359540646, Validation Accuracy: 0.8134034165571616\n",
      "Epoch 5/60, Training Loss: 0.414505287427993\n",
      "Epoch 5/60, Validation Loss: 0.4085649981295095, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 6/60, Training Loss: 0.41241518186107085\n",
      "Epoch 6/60, Validation Loss: 0.3991243520761348, Validation Accuracy: 0.8291721419185283\n",
      "Epoch 7/60, Training Loss: 0.40705360246827127\n",
      "Epoch 7/60, Validation Loss: 0.412922772281457, Validation Accuracy: 0.8226018396846255\n",
      "Epoch 8/60, Training Loss: 0.4075597899225284\n",
      "Epoch 8/60, Validation Loss: 0.39959676668086913, Validation Accuracy: 0.8272010512483574\n",
      "Epoch 9/60, Training Loss: 0.4046917618289003\n",
      "Epoch 9/60, Validation Loss: 0.3974596581650966, Validation Accuracy: 0.8344283837056504\n",
      "Epoch 10/60, Training Loss: 0.40190825158158155\n",
      "Epoch 10/60, Validation Loss: 0.4067177136784605, Validation Accuracy: 0.8160315374507228\n",
      "Epoch 11/60, Training Loss: 0.4015543988546518\n",
      "Epoch 11/60, Validation Loss: 0.40761791350056675, Validation Accuracy: 0.8226018396846255\n",
      "Epoch 12/60, Training Loss: 0.40021592844033177\n",
      "Epoch 12/60, Validation Loss: 0.40984830467020655, Validation Accuracy: 0.8219448094612353\n",
      "Epoch 13/60, Training Loss: 0.3981827620485323\n",
      "Epoch 13/60, Validation Loss: 0.39775584102730166, Validation Accuracy: 0.823915900131406\n",
      "Epoch 14/60, Training Loss: 0.39704542330361103\n",
      "Epoch 14/60, Validation Loss: 0.4062633382556326, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 15/60, Training Loss: 0.39644378195382324\n",
      "Epoch 15/60, Validation Loss: 0.402259228278088, Validation Accuracy: 0.8219448094612353\n",
      "Epoch 16/60, Training Loss: 0.39384628923272524\n",
      "Epoch 16/60, Validation Loss: 0.4186695284595352, Validation Accuracy: 0.8193166885676741\n",
      "Epoch 17/60, Training Loss: 0.3939212293723437\n",
      "Epoch 17/60, Validation Loss: 0.39917898343885755, Validation Accuracy: 0.831143232588699\n",
      "Epoch 18/60, Training Loss: 0.3894542063686635\n",
      "Epoch 18/60, Validation Loss: 0.39605914357640043, Validation Accuracy: 0.8278580814717477\n",
      "Epoch 19/60, Training Loss: 0.38858522908894094\n",
      "Epoch 19/60, Validation Loss: 0.3998844220317627, Validation Accuracy: 0.8272010512483574\n",
      "Epoch 20/60, Training Loss: 0.3891492749605905\n",
      "Epoch 20/60, Validation Loss: 0.3987767760939311, Validation Accuracy: 0.8278580814717477\n",
      "Epoch 21/60, Training Loss: 0.38923191549036446\n",
      "Epoch 21/60, Validation Loss: 0.41011361157550863, Validation Accuracy: 0.8252299605781866\n",
      "Epoch 22/60, Training Loss: 0.38657490577636744\n",
      "Epoch 22/60, Validation Loss: 0.4074555977944928, Validation Accuracy: 0.8153745072273325\n",
      "Epoch 23/60, Training Loss: 0.38635796901043945\n",
      "Epoch 23/60, Validation Loss: 0.4018298747378806, Validation Accuracy: 0.8252299605781866\n",
      "Epoch 24/60, Training Loss: 0.38443084173588926\n",
      "Epoch 24/60, Validation Loss: 0.39568072539895616, Validation Accuracy: 0.8278580814717477\n",
      "Epoch 25/60, Training Loss: 0.3843221595642839\n",
      "Epoch 25/60, Validation Loss: 0.39623589225659506, Validation Accuracy: 0.8304862023653088\n",
      "Epoch 26/60, Training Loss: 0.3843133780577286\n",
      "Epoch 26/60, Validation Loss: 0.4031740576808989, Validation Accuracy: 0.8206307490144547\n",
      "Epoch 27/60, Training Loss: 0.381401100511274\n",
      "Epoch 27/60, Validation Loss: 0.41486877240045533, Validation Accuracy: 0.8193166885676741\n",
      "Epoch 28/60, Training Loss: 0.38266064634844854\n",
      "Epoch 28/60, Validation Loss: 0.39641263378852326, Validation Accuracy: 0.8258869908015769\n",
      "Epoch 29/60, Training Loss: 0.38299214553938604\n",
      "Epoch 29/60, Validation Loss: 0.4219512379684373, Validation Accuracy: 0.8173455978975033\n",
      "Epoch 30/60, Training Loss: 0.3823432732725472\n",
      "Epoch 30/60, Validation Loss: 0.3978500221197674, Validation Accuracy: 0.8258869908015769\n",
      "Epoch 31/60, Training Loss: 0.38119753031671205\n",
      "Epoch 31/60, Validation Loss: 0.4049254835178559, Validation Accuracy: 0.8291721419185283\n",
      "Epoch 32/60, Training Loss: 0.3795612668496339\n",
      "Epoch 32/60, Validation Loss: 0.40584983509424, Validation Accuracy: 0.8193166885676741\n",
      "Epoch 33/60, Training Loss: 0.3810341347136053\n",
      "Epoch 33/60, Validation Loss: 0.4239665718934455, Validation Accuracy: 0.8153745072273325\n",
      "Epoch 34/60, Training Loss: 0.37879049247057417\n",
      "Epoch 34/60, Validation Loss: 0.398079062631617, Validation Accuracy: 0.8291721419185283\n",
      "Epoch 35/60, Training Loss: 0.3770678783241376\n",
      "Epoch 35/60, Validation Loss: 0.3969020489993364, Validation Accuracy: 0.8258869908015769\n",
      "Epoch 36/60, Training Loss: 0.37648169600509906\n",
      "Epoch 36/60, Validation Loss: 0.3982811318759207, Validation Accuracy: 0.823915900131406\n",
      "Epoch 37/60, Training Loss: 0.37593120428442645\n",
      "Epoch 37/60, Validation Loss: 0.39872439724456576, Validation Accuracy: 0.8186596583442839\n",
      "Epoch 38/60, Training Loss: 0.37789655082768653\n",
      "Epoch 38/60, Validation Loss: 0.3966668326973291, Validation Accuracy: 0.8258869908015769\n",
      "Epoch 39/60, Training Loss: 0.3770146273526307\n",
      "Epoch 39/60, Validation Loss: 0.3980458990344046, Validation Accuracy: 0.8258869908015769\n",
      "Epoch 40/60, Training Loss: 0.3754019979240857\n",
      "Epoch 40/60, Validation Loss: 0.39676974189141034, Validation Accuracy: 0.8226018396846255\n",
      "Epoch 41/60, Training Loss: 0.37629339705145576\n",
      "Epoch 41/60, Validation Loss: 0.40026579480325675, Validation Accuracy: 0.8212877792378449\n",
      "Epoch 42/60, Training Loss: 0.37465169239701246\n",
      "Epoch 42/60, Validation Loss: 0.4004752726064927, Validation Accuracy: 0.8298291721419185\n",
      "Epoch 43/60, Training Loss: 0.37351844445105614\n",
      "Epoch 43/60, Validation Loss: 0.4053993203643105, Validation Accuracy: 0.8265440210249672\n",
      "Epoch 44/60, Training Loss: 0.3732961823777577\n",
      "Epoch 44/60, Validation Loss: 0.4058915188253238, Validation Accuracy: 0.8278580814717477\n",
      "Epoch 45/60, Training Loss: 0.37183687606156657\n",
      "Epoch 45/60, Validation Loss: 0.4158120803164406, Validation Accuracy: 0.823915900131406\n",
      "Epoch 46/60, Training Loss: 0.37214962050827155\n",
      "Epoch 46/60, Validation Loss: 0.4067073057927386, Validation Accuracy: 0.8252299605781866\n",
      "Epoch 47/60, Training Loss: 0.3721234817937838\n",
      "Epoch 47/60, Validation Loss: 0.3985527627150582, Validation Accuracy: 0.8252299605781866\n",
      "Epoch 48/60, Training Loss: 0.3704845310870822\n",
      "Epoch 48/60, Validation Loss: 0.3987018830820684, Validation Accuracy: 0.8245729303547963\n",
      "Epoch 49/60, Training Loss: 0.3706037432463776\n",
      "Epoch 49/60, Validation Loss: 0.4239369001073753, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 50/60, Training Loss: 0.3725549718145076\n",
      "Epoch 50/60, Validation Loss: 0.4117538763005384, Validation Accuracy: 0.8134034165571616\n",
      "Epoch 51/60, Training Loss: 0.3714102822749477\n",
      "Epoch 51/60, Validation Loss: 0.39826474749332014, Validation Accuracy: 0.8232588699080158\n",
      "Epoch 52/60, Training Loss: 0.3709563283968394\n",
      "Epoch 52/60, Validation Loss: 0.4002657046746365, Validation Accuracy: 0.8226018396846255\n",
      "Epoch 53/60, Training Loss: 0.36744762644210827\n",
      "Epoch 53/60, Validation Loss: 0.40047899898902284, Validation Accuracy: 0.8199737187910644\n",
      "Epoch 54/60, Training Loss: 0.36888909339904785\n",
      "Epoch 54/60, Validation Loss: 0.41191567613192254, Validation Accuracy: 0.8226018396846255\n",
      "Epoch 55/60, Training Loss: 0.3690314215664163\n",
      "Epoch 55/60, Validation Loss: 0.3988208202596422, Validation Accuracy: 0.8206307490144547\n",
      "Epoch 56/60, Training Loss: 0.36825765262595\n",
      "Epoch 56/60, Validation Loss: 0.39904598338792774, Validation Accuracy: 0.8265440210249672\n",
      "Epoch 57/60, Training Loss: 0.36919105221612714\n",
      "Epoch 57/60, Validation Loss: 0.40542401747865825, Validation Accuracy: 0.8180026281208935\n",
      "Epoch 58/60, Training Loss: 0.3696552880274577\n",
      "Epoch 58/60, Validation Loss: 0.39912645517804546, Validation Accuracy: 0.8278580814717477\n",
      "Epoch 59/60, Training Loss: 0.36779827594737524\n",
      "Epoch 59/60, Validation Loss: 0.40285849706781784, Validation Accuracy: 0.8278580814717477\n",
      "Epoch 60/60, Training Loss: 0.36627893367405795\n",
      "Epoch 60/60, Validation Loss: 0.4272191383003096, Validation Accuracy: 0.8219448094612353\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/60, Training Loss: 0.5048251753560514\n",
      "Epoch 1/60, Validation Loss: 0.456337332179409, Validation Accuracy: 0.797634691195795\n",
      "Epoch 2/60, Training Loss: 0.4377245249573796\n",
      "Epoch 2/60, Validation Loss: 0.45128881069222043, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 3/60, Training Loss: 0.4192602289278363\n",
      "Epoch 3/60, Validation Loss: 0.44067475779947496, Validation Accuracy: 0.7871222076215506\n",
      "Epoch 4/60, Training Loss: 0.4138433637777026\n",
      "Epoch 4/60, Validation Loss: 0.42450567393402777, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 5/60, Training Loss: 0.40773531218643577\n",
      "Epoch 5/60, Validation Loss: 0.42061054296011385, Validation Accuracy: 0.797634691195795\n",
      "Epoch 6/60, Training Loss: 0.4060707746606486\n",
      "Epoch 6/60, Validation Loss: 0.42016674108140134, Validation Accuracy: 0.797634691195795\n",
      "Epoch 7/60, Training Loss: 0.4030183568655506\n",
      "Epoch 7/60, Validation Loss: 0.4207133357339973, Validation Accuracy: 0.7956636005256241\n",
      "Epoch 8/60, Training Loss: 0.39999851104351164\n",
      "Epoch 8/60, Validation Loss: 0.41947454040509247, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 9/60, Training Loss: 0.3968736703783821\n",
      "Epoch 9/60, Validation Loss: 0.42691068915913555, Validation Accuracy: 0.7943495400788436\n",
      "Epoch 10/60, Training Loss: 0.3968443003265564\n",
      "Epoch 10/60, Validation Loss: 0.42001432792834587, Validation Accuracy: 0.8140604467805519\n",
      "Epoch 11/60, Training Loss: 0.39371474579054855\n",
      "Epoch 11/60, Validation Loss: 0.4175389648185975, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 12/60, Training Loss: 0.3916299949422127\n",
      "Epoch 12/60, Validation Loss: 0.4237116173845935, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 13/60, Training Loss: 0.39250914183423274\n",
      "Epoch 13/60, Validation Loss: 0.4177958916931252, Validation Accuracy: 0.80946123521682\n",
      "Epoch 14/60, Training Loss: 0.39103210301888897\n",
      "Epoch 14/60, Validation Loss: 0.42198099233990255, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 15/60, Training Loss: 0.38709493069432854\n",
      "Epoch 15/60, Validation Loss: 0.4181887511241967, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 16/60, Training Loss: 0.3866495369417774\n",
      "Epoch 16/60, Validation Loss: 0.42502329065537575, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 17/60, Training Loss: 0.38570074582584885\n",
      "Epoch 17/60, Validation Loss: 0.41912791804844485, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 18/60, Training Loss: 0.38481135770991404\n",
      "Epoch 18/60, Validation Loss: 0.4194272169404473, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 19/60, Training Loss: 0.3822558321880074\n",
      "Epoch 19/60, Validation Loss: 0.42052775818405974, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 20/60, Training Loss: 0.3824421880165423\n",
      "Epoch 20/60, Validation Loss: 0.42636009300351924, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 21/60, Training Loss: 0.3824825769441882\n",
      "Epoch 21/60, Validation Loss: 0.4205735714335716, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 22/60, Training Loss: 0.3803285101863734\n",
      "Epoch 22/60, Validation Loss: 0.4229102055566551, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 23/60, Training Loss: 0.38015775376652167\n",
      "Epoch 23/60, Validation Loss: 0.42426156220440775, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 24/60, Training Loss: 0.3791064391220648\n",
      "Epoch 24/60, Validation Loss: 0.4357139171388839, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 25/60, Training Loss: 0.378082988817939\n",
      "Epoch 25/60, Validation Loss: 0.4212112773882703, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 26/60, Training Loss: 0.37851520703025066\n",
      "Epoch 26/60, Validation Loss: 0.4218121423771244, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 27/60, Training Loss: 0.37792219423011847\n",
      "Epoch 27/60, Validation Loss: 0.4244079815506623, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 28/60, Training Loss: 0.37840478549518297\n",
      "Epoch 28/60, Validation Loss: 0.419943635230055, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 29/60, Training Loss: 0.37442148313552065\n",
      "Epoch 29/60, Validation Loss: 0.4212693220287249, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 30/60, Training Loss: 0.37551313217758664\n",
      "Epoch 30/60, Validation Loss: 0.4215317046689113, Validation Accuracy: 0.8134034165571616\n",
      "Epoch 31/60, Training Loss: 0.373059191880381\n",
      "Epoch 31/60, Validation Loss: 0.420613169104485, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 32/60, Training Loss: 0.3715942374032157\n",
      "Epoch 32/60, Validation Loss: 0.428432202483503, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 33/60, Training Loss: 0.37104539723768637\n",
      "Epoch 33/60, Validation Loss: 0.440379842184484, Validation Accuracy: 0.7943495400788436\n",
      "Epoch 34/60, Training Loss: 0.3743420259103062\n",
      "Epoch 34/60, Validation Loss: 0.42832252442719737, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 35/60, Training Loss: 0.37229627549276734\n",
      "Epoch 35/60, Validation Loss: 0.423033695648478, Validation Accuracy: 0.8134034165571616\n",
      "Epoch 36/60, Training Loss: 0.3722900076820625\n",
      "Epoch 36/60, Validation Loss: 0.4234573890342918, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 37/60, Training Loss: 0.3696665914479907\n",
      "Epoch 37/60, Validation Loss: 0.4210700882764543, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 38/60, Training Loss: 0.37251525195291035\n",
      "Epoch 38/60, Validation Loss: 0.4313670369401496, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 39/60, Training Loss: 0.37031333326432964\n",
      "Epoch 39/60, Validation Loss: 0.42223510212455123, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 40/60, Training Loss: 0.3692978135263669\n",
      "Epoch 40/60, Validation Loss: 0.427080097291326, Validation Accuracy: 0.80946123521682\n",
      "Epoch 41/60, Training Loss: 0.3683120415416446\n",
      "Epoch 41/60, Validation Loss: 0.4216022807032026, Validation Accuracy: 0.80946123521682\n",
      "Epoch 42/60, Training Loss: 0.36850768266113726\n",
      "Epoch 42/60, Validation Loss: 0.43923714280577075, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 43/60, Training Loss: 0.3670798475191662\n",
      "Epoch 43/60, Validation Loss: 0.4217294055129845, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 44/60, Training Loss: 0.36735058451692265\n",
      "Epoch 44/60, Validation Loss: 0.4458128482015579, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 45/60, Training Loss: 0.366933096542446\n",
      "Epoch 45/60, Validation Loss: 0.4246687822590012, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 46/60, Training Loss: 0.36587862233848867\n",
      "Epoch 46/60, Validation Loss: 0.4292108694296233, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 47/60, Training Loss: 0.3663625382669172\n",
      "Epoch 47/60, Validation Loss: 0.42387197840549246, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 48/60, Training Loss: 0.3646815020170581\n",
      "Epoch 48/60, Validation Loss: 0.4285608114703944, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 49/60, Training Loss: 0.36446066572773334\n",
      "Epoch 49/60, Validation Loss: 0.4265181319739338, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 50/60, Training Loss: 0.36560283566328877\n",
      "Epoch 50/60, Validation Loss: 0.42659023872708307, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 51/60, Training Loss: 0.3644736036756064\n",
      "Epoch 51/60, Validation Loss: 0.4238679277666732, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 52/60, Training Loss: 0.3641754382013727\n",
      "Epoch 52/60, Validation Loss: 0.425653316899744, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 53/60, Training Loss: 0.36392452181109136\n",
      "Epoch 53/60, Validation Loss: 0.4326392401555914, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 54/60, Training Loss: 0.36299242684006533\n",
      "Epoch 54/60, Validation Loss: 0.42755673566335783, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 55/60, Training Loss: 0.36256522261916496\n",
      "Epoch 55/60, Validation Loss: 0.42597465040113447, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 56/60, Training Loss: 0.36196146807645563\n",
      "Epoch 56/60, Validation Loss: 0.4262429908873679, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 57/60, Training Loss: 0.36202897254641603\n",
      "Epoch 57/60, Validation Loss: 0.42487180548481135, Validation Accuracy: 0.80946123521682\n",
      "Epoch 58/60, Training Loss: 0.36269300750253863\n",
      "Epoch 58/60, Validation Loss: 0.434356393814282, Validation Accuracy: 0.812089356110381\n",
      "Epoch 59/60, Training Loss: 0.3585267865986336\n",
      "Epoch 59/60, Validation Loss: 0.4268188733285712, Validation Accuracy: 0.812089356110381\n",
      "Epoch 60/60, Training Loss: 0.3611404698860301\n",
      "Epoch 60/60, Validation Loss: 0.42692278561070174, Validation Accuracy: 0.8028909329829172\n",
      "Average Validation Accuracy: 0.8111129134264535\n",
      "Number of Epochs: 60\n"
     ]
    }
   ],
   "source": [
    "epochs = [10, 20, 30, 40, 50, 60]\n",
    "average_val_accuracy_dict = {}\n",
    "for num_epoch in epochs:\n",
    "    val_accuracies = []\n",
    "    for train_idx, val_idx in skf.split(combined_features, labels):\n",
    "        # Create TensorDatasets for the current fold\n",
    "        train_dataset = TensorDataset(torch.tensor(combined_features[train_idx]), torch.tensor(labels_numpy[train_idx].reshape(-1,1), dtype=torch.float32))\n",
    "        val_dataset = TensorDataset(torch.tensor(combined_features[val_idx]), torch.tensor(labels_numpy[val_idx].reshape(-1,1), dtype=torch.float32))\n",
    "\n",
    "        # Create DataLoaders for the current fold\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "        # Train and validate your model for the current fold\n",
    "        # Train and validate your model for the current fold and store the validation accuracy\n",
    "        val_accuracy = train_and_validate(train_dataloader, val_dataloader, len(val_dataset), num_epoch)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Calculate the average validation accuracy across all folds\n",
    "    average_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "    average_val_accuracy_dict[num_epoch] = average_val_accuracy\n",
    "    print(f'Average Validation Accuracy: {average_val_accuracy}')\n",
    "    print(f'Number of Epochs: {num_epoch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the average_val_accuracy_dict dictionary, plot a graph with number of epochs on x-axis and average validation accuracy on y-axis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the keys and values as separate lists\n",
    "keys = list(average_val_accuracy_dict.keys())\n",
    "values = list(average_val_accuracy_dict.values())\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(keys, values)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.title('Scatter plot of  validation accuracy vs epochs')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this graph, we can see that epoch = 20 is the optimal parameter as it will give us a higher validation accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performed with CombinedModelMoreHLs 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5212539559293763\n",
      "Epoch 1/10, Validation Loss: 0.46027894185475654, Validation Accuracy: 0.7852921864740644\n",
      "Epoch 2/10, Training Loss: 0.4625066204920528\n",
      "Epoch 2/10, Validation Loss: 0.4172707948424117, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 3/10, Training Loss: 0.4483260045370718\n",
      "Epoch 3/10, Validation Loss: 0.42814220780633505, Validation Accuracy: 0.804333552199606\n",
      "Epoch 4/10, Training Loss: 0.4401030810329858\n",
      "Epoch 4/10, Validation Loss: 0.42160315595138137, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 5/10, Training Loss: 0.43544550469814947\n",
      "Epoch 5/10, Validation Loss: 0.43752659407702726, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 6/10, Training Loss: 0.4314051143864165\n",
      "Epoch 6/10, Validation Loss: 0.4215296328808937, Validation Accuracy: 0.8194353250164149\n",
      "Epoch 7/10, Training Loss: 0.42755096117059\n",
      "Epoch 7/10, Validation Loss: 0.40877900235062337, Validation Accuracy: 0.8187787261982928\n",
      "Epoch 8/10, Training Loss: 0.4227981003700435\n",
      "Epoch 8/10, Validation Loss: 0.41648702370246665, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 9/10, Training Loss: 0.4211454829176658\n",
      "Epoch 9/10, Validation Loss: 0.42495813593268394, Validation Accuracy: 0.8128693368351937\n",
      "Epoch 10/10, Training Loss: 0.41623627313772055\n",
      "Epoch 10/10, Validation Loss: 0.4124521646278067, Validation Accuracy: 0.8207485226526592\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5255678224809995\n",
      "Epoch 1/10, Validation Loss: 0.46986737847328186, Validation Accuracy: 0.7820091923834537\n",
      "Epoch 2/10, Training Loss: 0.46722348281267906\n",
      "Epoch 2/10, Validation Loss: 0.43943517771671425, Validation Accuracy: 0.7820091923834537\n",
      "Epoch 3/10, Training Loss: 0.45280322104966236\n",
      "Epoch 3/10, Validation Loss: 0.4072934522864004, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 4/10, Training Loss: 0.442934893990752\n",
      "Epoch 4/10, Validation Loss: 0.42720230345989707, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 5/10, Training Loss: 0.43870898812833264\n",
      "Epoch 5/10, Validation Loss: 0.407787902384304, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 6/10, Training Loss: 0.4362421229071035\n",
      "Epoch 6/10, Validation Loss: 0.42293566538518323, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 7/10, Training Loss: 0.4308797506190191\n",
      "Epoch 7/10, Validation Loss: 0.40958007632545074, Validation Accuracy: 0.804333552199606\n",
      "Epoch 8/10, Training Loss: 0.4255218061513397\n",
      "Epoch 8/10, Validation Loss: 0.4105138078219798, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 9/10, Training Loss: 0.4251811648144575\n",
      "Epoch 9/10, Validation Loss: 0.42641984075502887, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 10/10, Training Loss: 0.4245367339931996\n",
      "Epoch 10/10, Validation Loss: 0.41119786685927534, Validation Accuracy: 0.8003939592908733\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5265108250335758\n",
      "Epoch 1/10, Validation Loss: 0.44802912628931524, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 2/10, Training Loss: 0.45176178113290955\n",
      "Epoch 2/10, Validation Loss: 0.4331704060015566, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 3/10, Training Loss: 0.4432618214291694\n",
      "Epoch 3/10, Validation Loss: 0.43953848549491525, Validation Accuracy: 0.804333552199606\n",
      "Epoch 4/10, Training Loss: 0.4374620114939576\n",
      "Epoch 4/10, Validation Loss: 0.4358505604213289, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 5/10, Training Loss: 0.43450738389895655\n",
      "Epoch 5/10, Validation Loss: 0.4369148119177221, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 6/10, Training Loss: 0.42535685128446793\n",
      "Epoch 6/10, Validation Loss: 0.43161201011389494, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 7/10, Training Loss: 0.42170224693699143\n",
      "Epoch 7/10, Validation Loss: 0.45057611303563666, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 8/10, Training Loss: 0.4284401445251124\n",
      "Epoch 8/10, Validation Loss: 0.42941861115493546, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 9/10, Training Loss: 0.4173210726518018\n",
      "Epoch 9/10, Validation Loss: 0.43272288969635025, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 10/10, Training Loss: 0.41203345430726457\n",
      "Epoch 10/10, Validation Loss: 0.43345209637520277, Validation Accuracy: 0.8082731451083388\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5229281712509203\n",
      "Epoch 1/10, Validation Loss: 0.4350744524863378, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 2/10, Training Loss: 0.46649402983271543\n",
      "Epoch 2/10, Validation Loss: 0.41148327515309396, Validation Accuracy: 0.8140604467805519\n",
      "Epoch 3/10, Training Loss: 0.45644532818728545\n",
      "Epoch 3/10, Validation Loss: 0.4017186638928404, Validation Accuracy: 0.8212877792378449\n",
      "Epoch 4/10, Training Loss: 0.4494080024617394\n",
      "Epoch 4/10, Validation Loss: 0.4127473022437689, Validation Accuracy: 0.8134034165571616\n",
      "Epoch 5/10, Training Loss: 0.4395567058754249\n",
      "Epoch 5/10, Validation Loss: 0.4041653554398976, Validation Accuracy: 0.8298291721419185\n",
      "Epoch 6/10, Training Loss: 0.43563752719188925\n",
      "Epoch 6/10, Validation Loss: 0.41052980027624764, Validation Accuracy: 0.8180026281208935\n",
      "Epoch 7/10, Training Loss: 0.43420197167421576\n",
      "Epoch 7/10, Validation Loss: 0.4038071743315037, Validation Accuracy: 0.8258869908015769\n",
      "Epoch 8/10, Training Loss: 0.4288655038522141\n",
      "Epoch 8/10, Validation Loss: 0.4049498989827034, Validation Accuracy: 0.8258869908015769\n",
      "Epoch 9/10, Training Loss: 0.4265169604947874\n",
      "Epoch 9/10, Validation Loss: 0.4116296496885921, Validation Accuracy: 0.816688567674113\n",
      "Epoch 10/10, Training Loss: 0.4270098781961156\n",
      "Epoch 10/10, Validation Loss: 0.41702827765406425, Validation Accuracy: 0.8134034165571616\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5305480362744782\n",
      "Epoch 1/10, Validation Loss: 0.43640390896672354, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 2/10, Training Loss: 0.4576329657529283\n",
      "Epoch 2/10, Validation Loss: 0.43403826342378765, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 3/10, Training Loss: 0.4463043654058862\n",
      "Epoch 3/10, Validation Loss: 0.4340574315393158, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 4/10, Training Loss: 0.4417329913010122\n",
      "Epoch 4/10, Validation Loss: 0.4570100693158922, Validation Accuracy: 0.7956636005256241\n",
      "Epoch 5/10, Training Loss: 0.4334816126998641\n",
      "Epoch 5/10, Validation Loss: 0.43086004021202085, Validation Accuracy: 0.7956636005256241\n",
      "Epoch 6/10, Training Loss: 0.43132615423323756\n",
      "Epoch 6/10, Validation Loss: 0.427872877923957, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 7/10, Training Loss: 0.4252551688746674\n",
      "Epoch 7/10, Validation Loss: 0.4191536867420594, Validation Accuracy: 0.80946123521682\n",
      "Epoch 8/10, Training Loss: 0.42421577131654337\n",
      "Epoch 8/10, Validation Loss: 0.4313268933142901, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 9/10, Training Loss: 0.4191338631160694\n",
      "Epoch 9/10, Validation Loss: 0.44405876756377555, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 10/10, Training Loss: 0.4150843830275645\n",
      "Epoch 10/10, Validation Loss: 0.4357354011269608, Validation Accuracy: 0.7982917214191853\n",
      "Average Validation Accuracy: 0.8082221530056437\n"
     ]
    }
   ],
   "source": [
    "val_accuracies = []\n",
    "for train_idx, val_idx in skf.split(combined_features, labels):\n",
    "    # Create TensorDatasets for the current fold\n",
    "    train_dataset = TensorDataset(torch.tensor(combined_features[train_idx]), torch.tensor(labels_numpy[train_idx].reshape(-1,1), dtype=torch.float32))\n",
    "    val_dataset = TensorDataset(torch.tensor(combined_features[val_idx]), torch.tensor(labels_numpy[val_idx].reshape(-1,1), dtype=torch.float32))\n",
    "\n",
    "    # Create DataLoaders for the current fold\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    # Train and validate your model for the current fold\n",
    "    # Train and validate your model for the current fold and store the validation accuracy\n",
    "    val_accuracy = train_and_validate(train_dataloader, val_dataloader, len(val_dataset))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Calculate the average validation accuracy across all folds\n",
    "average_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "print(f'Average Validation Accuracy: {average_val_accuracy}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performed with CombinedModelMoreHLs 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5313310567729586\n",
      "Epoch 1/10, Validation Loss: 0.43196900028988955, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 2/10, Training Loss: 0.4674192331046883\n",
      "Epoch 2/10, Validation Loss: 0.4297476159945052, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 3/10, Training Loss: 0.4453050988552764\n",
      "Epoch 3/10, Validation Loss: 0.42063600047252564, Validation Accuracy: 0.8168089297439265\n",
      "Epoch 4/10, Training Loss: 0.445266618307807\n",
      "Epoch 4/10, Validation Loss: 0.43529008583199835, Validation Accuracy: 0.8122127380170716\n",
      "Epoch 5/10, Training Loss: 0.43418479615973987\n",
      "Epoch 5/10, Validation Loss: 0.4165508486720592, Validation Accuracy: 0.8181221273801708\n",
      "Epoch 6/10, Training Loss: 0.4391445624312078\n",
      "Epoch 6/10, Validation Loss: 0.41631536039460393, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 7/10, Training Loss: 0.4288159793736584\n",
      "Epoch 7/10, Validation Loss: 0.4162027304358195, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 8/10, Training Loss: 0.42370397035335616\n",
      "Epoch 8/10, Validation Loss: 0.4165315847083224, Validation Accuracy: 0.81483913328956\n",
      "Epoch 9/10, Training Loss: 0.4230293633558071\n",
      "Epoch 9/10, Validation Loss: 0.41715156501500394, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 10/10, Training Loss: 0.4168839964311658\n",
      "Epoch 10/10, Validation Loss: 0.41430168220510033, Validation Accuracy: 0.8135259356533159\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.53390266949658\n",
      "Epoch 1/10, Validation Loss: 0.4338407937963908, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 2/10, Training Loss: 0.4589428276879581\n",
      "Epoch 2/10, Validation Loss: 0.43414398284716754, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 3/10, Training Loss: 0.4447372341112984\n",
      "Epoch 3/10, Validation Loss: 0.41106420291187873, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 4/10, Training Loss: 0.4463652879234374\n",
      "Epoch 4/10, Validation Loss: 0.41363344491698356, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 5/10, Training Loss: 0.43967312469765585\n",
      "Epoch 5/10, Validation Loss: 0.4063522356820746, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 6/10, Training Loss: 0.43161043069102945\n",
      "Epoch 6/10, Validation Loss: 0.4120567618474286, Validation Accuracy: 0.8154957321076822\n",
      "Epoch 7/10, Training Loss: 0.4301317134612971\n",
      "Epoch 7/10, Validation Loss: 0.42532714347584244, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 8/10, Training Loss: 0.4233185710957435\n",
      "Epoch 8/10, Validation Loss: 0.41540191054687936, Validation Accuracy: 0.8108995403808273\n",
      "Epoch 9/10, Training Loss: 0.42173822866532745\n",
      "Epoch 9/10, Validation Loss: 0.4371686278603464, Validation Accuracy: 0.799080761654629\n",
      "Epoch 10/10, Training Loss: 0.4196779130349361\n",
      "Epoch 10/10, Validation Loss: 0.41093660244493896, Validation Accuracy: 0.8161523309258043\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.526509699898129\n",
      "Epoch 1/10, Validation Loss: 0.4473663432942947, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 2/10, Training Loss: 0.4647916252199277\n",
      "Epoch 2/10, Validation Loss: 0.43616021900432894, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 3/10, Training Loss: 0.44380206994106136\n",
      "Epoch 3/10, Validation Loss: 0.4362109176941333, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 4/10, Training Loss: 0.4356129389136157\n",
      "Epoch 4/10, Validation Loss: 0.43272412623917555, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 5/10, Training Loss: 0.43347644746264447\n",
      "Epoch 5/10, Validation Loss: 0.4391116569238027, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 6/10, Training Loss: 0.4294745180941629\n",
      "Epoch 6/10, Validation Loss: 0.43163051600543617, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 7/10, Training Loss: 0.42418998493531873\n",
      "Epoch 7/10, Validation Loss: 0.4363169385734653, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 8/10, Training Loss: 0.42255970629377004\n",
      "Epoch 8/10, Validation Loss: 0.42835089229827467, Validation Accuracy: 0.81483913328956\n",
      "Epoch 9/10, Training Loss: 0.42292321900155133\n",
      "Epoch 9/10, Validation Loss: 0.4360761002183975, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 10/10, Training Loss: 0.41222274621210386\n",
      "Epoch 10/10, Validation Loss: 0.4328901423238881, Validation Accuracy: 0.8128693368351937\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5139484950035732\n",
      "Epoch 1/10, Validation Loss: 0.42617379619462015, Validation Accuracy: 0.80946123521682\n",
      "Epoch 2/10, Training Loss: 0.4670002078075265\n",
      "Epoch 2/10, Validation Loss: 0.4227817116978125, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 3/10, Training Loss: 0.4517970950956263\n",
      "Epoch 3/10, Validation Loss: 0.43360798755241314, Validation Accuracy: 0.7950065703022339\n",
      "Epoch 4/10, Training Loss: 0.44809128749832083\n",
      "Epoch 4/10, Validation Loss: 0.44038504185106275, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 5/10, Training Loss: 0.43652539395450995\n",
      "Epoch 5/10, Validation Loss: 0.40364045999866194, Validation Accuracy: 0.8134034165571616\n",
      "Epoch 6/10, Training Loss: 0.4335054069161024\n",
      "Epoch 6/10, Validation Loss: 0.4022780980388219, Validation Accuracy: 0.8226018396846255\n",
      "Epoch 7/10, Training Loss: 0.4308112514134389\n",
      "Epoch 7/10, Validation Loss: 0.4240804551003491, Validation Accuracy: 0.797634691195795\n",
      "Epoch 8/10, Training Loss: 0.43269384954017137\n",
      "Epoch 8/10, Validation Loss: 0.4084754425895776, Validation Accuracy: 0.816688567674113\n",
      "Epoch 9/10, Training Loss: 0.42810861180656223\n",
      "Epoch 9/10, Validation Loss: 0.4065748435342733, Validation Accuracy: 0.8278580814717477\n",
      "Epoch 10/10, Training Loss: 0.42150673414934964\n",
      "Epoch 10/10, Validation Loss: 0.39446077954404407, Validation Accuracy: 0.8212877792378449\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5178451303813089\n",
      "Epoch 1/10, Validation Loss: 0.4606375153425164, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 2/10, Training Loss: 0.46233322919197284\n",
      "Epoch 2/10, Validation Loss: 0.4243610791705978, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 3/10, Training Loss: 0.44496443952749093\n",
      "Epoch 3/10, Validation Loss: 0.4244797168962696, Validation Accuracy: 0.804862023653088\n",
      "Epoch 4/10, Training Loss: 0.4375402149683221\n",
      "Epoch 4/10, Validation Loss: 0.4295534589352252, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 5/10, Training Loss: 0.4309626718557726\n",
      "Epoch 5/10, Validation Loss: 0.4189981320356043, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 6/10, Training Loss: 0.4315311930183898\n",
      "Epoch 6/10, Validation Loss: 0.42120045550528384, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 7/10, Training Loss: 0.426584304454602\n",
      "Epoch 7/10, Validation Loss: 0.4176255805047317, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 8/10, Training Loss: 0.4241586326183922\n",
      "Epoch 8/10, Validation Loss: 0.4290977215140824, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 9/10, Training Loss: 0.41883886587901376\n",
      "Epoch 9/10, Validation Loss: 0.4176547646483514, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 10/10, Training Loss: 0.41620540154701846\n",
      "Epoch 10/10, Validation Loss: 0.4237504763192258, Validation Accuracy: 0.8028909329829172\n",
      "Average Validation Accuracy: 0.8133452631270153\n"
     ]
    }
   ],
   "source": [
    "val_accuracies = []\n",
    "for train_idx, val_idx in skf.split(combined_features, labels):\n",
    "    # Create TensorDatasets for the current fold\n",
    "    train_dataset = TensorDataset(torch.tensor(combined_features[train_idx]), torch.tensor(labels_numpy[train_idx].reshape(-1,1), dtype=torch.float32))\n",
    "    val_dataset = TensorDataset(torch.tensor(combined_features[val_idx]), torch.tensor(labels_numpy[val_idx].reshape(-1,1), dtype=torch.float32))\n",
    "\n",
    "    # Create DataLoaders for the current fold\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    # Train and validate your model for the current fold\n",
    "    # Train and validate your model for the current fold and store the validation accuracy\n",
    "    val_accuracy = train_and_validate(train_dataloader, val_dataloader, len(val_dataset))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Calculate the average validation accuracy across all folds\n",
    "average_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "print(f'Average Validation Accuracy: {average_val_accuracy}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performed with CombinedModelMoreHLs 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5300837656839938\n",
      "Epoch 1/10, Validation Loss: 0.460299644697243, Validation Accuracy: 0.7826657912015759\n",
      "Epoch 2/10, Training Loss: 0.4611240529560354\n",
      "Epoch 2/10, Validation Loss: 0.4158631797821422, Validation Accuracy: 0.8240315167432699\n",
      "Epoch 3/10, Training Loss: 0.4545359466704014\n",
      "Epoch 3/10, Validation Loss: 0.4325599910896174, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 4/10, Training Loss: 0.43679250963521127\n",
      "Epoch 4/10, Validation Loss: 0.41214321422541794, Validation Accuracy: 0.8200919238345371\n",
      "Epoch 5/10, Training Loss: 0.440173523608116\n",
      "Epoch 5/10, Validation Loss: 0.43197188345491105, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 6/10, Training Loss: 0.4341056599303728\n",
      "Epoch 6/10, Validation Loss: 0.4266218963561882, Validation Accuracy: 0.824688115561392\n",
      "Epoch 7/10, Training Loss: 0.4283784716304519\n",
      "Epoch 7/10, Validation Loss: 0.41462866819575817, Validation Accuracy: 0.8161523309258043\n",
      "Epoch 8/10, Training Loss: 0.41721143098328056\n",
      "Epoch 8/10, Validation Loss: 0.4191592959735874, Validation Accuracy: 0.8214051214707814\n",
      "Epoch 9/10, Training Loss: 0.41970063803663715\n",
      "Epoch 9/10, Validation Loss: 0.4252999755236959, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 10/10, Training Loss: 0.42520254761899706\n",
      "Epoch 10/10, Validation Loss: 0.40872524342260746, Validation Accuracy: 0.8214051214707814\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5306135073323731\n",
      "Epoch 1/10, Validation Loss: 0.4406269928294171, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 2/10, Training Loss: 0.46386451833438996\n",
      "Epoch 2/10, Validation Loss: 0.4165552373078325, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 3/10, Training Loss: 0.4538303809802676\n",
      "Epoch 3/10, Validation Loss: 0.42279093760841024, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 4/10, Training Loss: 0.4414825779226978\n",
      "Epoch 4/10, Validation Loss: 0.41596906412763435, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 5/10, Training Loss: 0.44334741594792976\n",
      "Epoch 5/10, Validation Loss: 0.4180120909635309, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 6/10, Training Loss: 0.43577206350882536\n",
      "Epoch 6/10, Validation Loss: 0.41816640722306925, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 7/10, Training Loss: 0.43061168153044277\n",
      "Epoch 7/10, Validation Loss: 0.41367577953527424, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 8/10, Training Loss: 0.4224570867045736\n",
      "Epoch 8/10, Validation Loss: 0.40470712514428414, Validation Accuracy: 0.8095863427445831\n",
      "Epoch 9/10, Training Loss: 0.42531720093229\n",
      "Epoch 9/10, Validation Loss: 0.4058083200544431, Validation Accuracy: 0.8135259356533159\n",
      "Epoch 10/10, Training Loss: 0.4221170685667144\n",
      "Epoch 10/10, Validation Loss: 0.4249157910552168, Validation Accuracy: 0.8017071569271176\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5278400924946536\n",
      "Epoch 1/10, Validation Loss: 0.45128837820747136, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 2/10, Training Loss: 0.4541319429659312\n",
      "Epoch 2/10, Validation Loss: 0.45290024795067246, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 3/10, Training Loss: 0.43941530745642704\n",
      "Epoch 3/10, Validation Loss: 0.4592400559502122, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 4/10, Training Loss: 0.43574755159243356\n",
      "Epoch 4/10, Validation Loss: 0.4396929235212232, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 5/10, Training Loss: 0.4335368668997851\n",
      "Epoch 5/10, Validation Loss: 0.4378791823105506, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 6/10, Training Loss: 0.4270561819803214\n",
      "Epoch 6/10, Validation Loss: 0.43787304890897927, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 7/10, Training Loss: 0.42565387671231597\n",
      "Epoch 7/10, Validation Loss: 0.43488433037479823, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 8/10, Training Loss: 0.4191549464014024\n",
      "Epoch 8/10, Validation Loss: 0.43601470626159256, Validation Accuracy: 0.8115561391989494\n",
      "Epoch 9/10, Training Loss: 0.4189844045279611\n",
      "Epoch 9/10, Validation Loss: 0.460847132488188, Validation Accuracy: 0.7820091923834537\n",
      "Epoch 10/10, Training Loss: 0.41974672062073165\n",
      "Epoch 10/10, Validation Loss: 0.4481505055031715, Validation Accuracy: 0.8056467498358503\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5288270115363473\n",
      "Epoch 1/10, Validation Loss: 0.41827454655894436, Validation Accuracy: 0.8147174770039421\n",
      "Epoch 2/10, Training Loss: 0.4585959096573626\n",
      "Epoch 2/10, Validation Loss: 0.42111649298894155, Validation Accuracy: 0.8278580814717477\n",
      "Epoch 3/10, Training Loss: 0.4542066858216064\n",
      "Epoch 3/10, Validation Loss: 0.40825331518280256, Validation Accuracy: 0.8232588699080158\n",
      "Epoch 4/10, Training Loss: 0.4453152704328846\n",
      "Epoch 4/10, Validation Loss: 0.4135139622476869, Validation Accuracy: 0.8272010512483574\n",
      "Epoch 5/10, Training Loss: 0.43981350473375147\n",
      "Epoch 5/10, Validation Loss: 0.40299294019088694, Validation Accuracy: 0.8370565045992115\n",
      "Epoch 6/10, Training Loss: 0.43419353817430695\n",
      "Epoch 6/10, Validation Loss: 0.4060188412120205, Validation Accuracy: 0.8140604467805519\n",
      "Epoch 7/10, Training Loss: 0.4349825339210941\n",
      "Epoch 7/10, Validation Loss: 0.40248228901636385, Validation Accuracy: 0.8180026281208935\n",
      "Epoch 8/10, Training Loss: 0.4313539949262862\n",
      "Epoch 8/10, Validation Loss: 0.40212514696652507, Validation Accuracy: 0.828515111695138\n",
      "Epoch 9/10, Training Loss: 0.4298367617686042\n",
      "Epoch 9/10, Validation Loss: 0.4108801271756672, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 10/10, Training Loss: 0.4183812921236115\n",
      "Epoch 10/10, Validation Loss: 0.40156211972197625, Validation Accuracy: 0.8199737187910644\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5267113418247443\n",
      "Epoch 1/10, Validation Loss: 0.4302943915479782, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 2/10, Training Loss: 0.4578881824970871\n",
      "Epoch 2/10, Validation Loss: 0.4571442104563975, Validation Accuracy: 0.7706964520367937\n",
      "Epoch 3/10, Training Loss: 0.4539187157971496\n",
      "Epoch 3/10, Validation Loss: 0.4209688896196285, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 4/10, Training Loss: 0.4380910076699623\n",
      "Epoch 4/10, Validation Loss: 0.4340789740446818, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 5/10, Training Loss: 0.4330477195295684\n",
      "Epoch 5/10, Validation Loss: 0.4328333117672442, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 6/10, Training Loss: 0.43399896858910253\n",
      "Epoch 6/10, Validation Loss: 0.43343970757611683, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 7/10, Training Loss: 0.42468142922077906\n",
      "Epoch 7/10, Validation Loss: 0.4171540505759886, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 8/10, Training Loss: 0.4255572214546635\n",
      "Epoch 8/10, Validation Loss: 0.43990343561181455, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 9/10, Training Loss: 0.420585682434751\n",
      "Epoch 9/10, Validation Loss: 0.42846634299908787, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 10/10, Training Loss: 0.41993512784734643\n",
      "Epoch 10/10, Validation Loss: 0.42454652248330765, Validation Accuracy: 0.8068331143232589\n",
      "Average Validation Accuracy: 0.8111131722696145\n"
     ]
    }
   ],
   "source": [
    "val_accuracies = []\n",
    "for train_idx, val_idx in skf.split(combined_features, labels):\n",
    "    # Create TensorDatasets for the current fold\n",
    "    train_dataset = TensorDataset(torch.tensor(combined_features[train_idx]), torch.tensor(labels_numpy[train_idx].reshape(-1,1), dtype=torch.float32))\n",
    "    val_dataset = TensorDataset(torch.tensor(combined_features[val_idx]), torch.tensor(labels_numpy[val_idx].reshape(-1,1), dtype=torch.float32))\n",
    "\n",
    "    # Create DataLoaders for the current fold\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    # Train and validate your model for the current fold\n",
    "    # Train and validate your model for the current fold and store the validation accuracy\n",
    "    val_accuracy = train_and_validate(train_dataloader, val_dataloader, len(val_dataset))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Calculate the average validation accuracy across all folds\n",
    "average_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "print(f'Average Validation Accuracy: {average_val_accuracy}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more Hidden layers did not seem to significantly affect the validation accuracy, and is difficult to search for the optimal number of layers because of time constraints. We will use the original CombinedModel for our training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Training of CombinedModel with Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 0.49409149911160727\n",
      "Epoch 2/20, Training Loss: 0.43100062931473015\n",
      "Epoch 3/20, Training Loss: 0.41683997809417356\n",
      "Epoch 4/20, Training Loss: 0.4104725889658101\n",
      "Epoch 5/20, Training Loss: 0.40978722899620024\n",
      "Epoch 6/20, Training Loss: 0.4078459976428822\n",
      "Epoch 7/20, Training Loss: 0.40195320415928837\n",
      "Epoch 8/20, Training Loss: 0.4029730767747309\n",
      "Epoch 9/20, Training Loss: 0.3991401407030262\n",
      "Epoch 10/20, Training Loss: 0.3972657438007598\n",
      "Epoch 11/20, Training Loss: 0.39512497596755747\n",
      "Epoch 12/20, Training Loss: 0.39288129453242077\n",
      "Epoch 13/20, Training Loss: 0.39348508504086305\n",
      "Epoch 14/20, Training Loss: 0.3932994085661441\n",
      "Epoch 15/20, Training Loss: 0.38916287017093987\n",
      "Epoch 16/20, Training Loss: 0.388913738963922\n",
      "Epoch 17/20, Training Loss: 0.3883396950472115\n",
      "Epoch 18/20, Training Loss: 0.38732523281526354\n",
      "Epoch 19/20, Training Loss: 0.38658176070204425\n",
      "Epoch 20/20, Training Loss: 0.3863579233278747\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 20\n",
    "# Create a TensorDataset for the entire dataset\n",
    "full_dataset = TensorDataset(torch.tensor(combined_features), torch.tensor(labels_numpy.reshape(-1,1), dtype=torch.float32))\n",
    "\n",
    "# Create a DataLoader for the entire dataset\n",
    "full_dataloader = DataLoader(full_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Train your model on the entire dataset (You can remove the validation loop from your train_and_validate function)\n",
    "def train_full(train_dataloader, num_epochs=20, device='cuda' if torch.cuda.is_available() else 'cpu', lr=1e-3):\n",
    "    # Replace with your custom model\n",
    "    model = CombinedModel(bert_output_size=768, num_numerical_features=len(numerical_features_columns), num_classes=1)\n",
    "    model.to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch_features, batch_labels in train_dataloader:\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(batch_features)\n",
    "            loss = loss_fn(logits, batch_labels)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Print the average training loss for the epoch\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {total_loss / len(train_dataloader)}')\n",
    "    return model\n",
    "\n",
    "# Train the model on the entire dataset\n",
    "optimized_model = train_full(full_dataloader)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming your test data is a numpy array\n",
    "test_combined_features = combined_features_test\n",
    "test_combined_features_tensor = torch.tensor(combined_features_test, dtype=torch.float32)\n",
    "optimized_model.eval()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Move the model and test features to the appropriate device\n",
    "optimized_model.to(device)\n",
    "test_combined_features_tensor = test_combined_features_tensor.to(device)\n",
    "\n",
    "# Perform a forward pass through the model to obtain predictions\n",
    "with torch.no_grad():\n",
    "    logits = optimized_model(test_combined_features_tensor)\n",
    "\n",
    "# Process the predictions to get the final predicted targets\n",
    "# If it's a binary classification problem, you can apply a threshold and convert the output to binary labels (0 or 1)\n",
    "threshold = 0\n",
    "predicted_targets = (logits > threshold).float().cpu().numpy()\n",
    "\n",
    "# If it's a multi-class problem, you can apply a softmax function and get the class with the highest probability\n",
    "# predicted_targets = torch.argmax(torch.softmax(logits, dim=1), dim=1).cpu().numpy()\n",
    "\n",
    "print(predicted_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_targets = predicted_targets.astype(int)\n",
    "df = pd.DataFrame(predicted_targets, columns=['target'])\n",
    "df = pd.concat([ test['id'],df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/BERT_CombinedNN.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
