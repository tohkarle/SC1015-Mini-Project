{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Model for Disaster Tweet Classification\n",
    "\n",
    "In this Notebook, we will train a BERT model to classify tweets as disaster-related or not. We will use the preprocessed `train_data_mod.csv`, which contains the text and numerical features, to train the BERT model. <br>\n",
    "We will be concatenating the `text` feature with `keyword_encoded`, `tweet_length` and `punctuation_count` as numerical values in the Neural Network Linear Layer.\n",
    "\n",
    "- Note: Instead of using `BertForSequenceClassifier` and `Trainer` in the `transformers` library for training, we are going to implement our own Feed Foward Neural Network with the last hidden states of the BERT output to improve our model training speed. This also leaves us with customization for adding more hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup, DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "train = pd.read_csv('../preprocessing/train_data_mod.csv')\n",
    "test = pd.read_csv('../preprocessing/test_data_mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mod = train.copy()\n",
    "test_mod = test.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the Dataset\n",
    "- We will use the raw text instead of the preprocessed text.\n",
    "- Drop the columns that we are not using.\n",
    "- Count the max length of tokens in text feature to ensure that the tokenizer max_length will not truncate off remaining text data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'keyword', 'location', 'text', 'target', 'preprocess_text',\n",
       "       'bigram', 'trigram', 'pos', 'keyword_encoded', 'tweet_length',\n",
       "       'punctuation_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "drop_cols = ['keyword', 'location', 'preprocess_text','bigram','trigram', 'pos']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mod.drop(drop_cols, axis=1, inplace=True)\n",
    "test_mod.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'text', 'target', 'keyword_encoded', 'tweet_length',\n",
       "       'punctuation_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'text', 'keyword_encoded', 'tweet_length', 'punctuation_count'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features_columns = ['tweet_length', 'punctuation_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(text_column, tokenizer):\n",
    "    max_len = 0\n",
    "    for text in text_column:\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        # print(tokens)\n",
    "        max_len = max(max_len, len(tokens))\n",
    "    print(\"Max length: \", max_len, \" tokens\")\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  104  tokens\n",
      "Max length:  99  tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length(train_mod['text'], tokenizer)\n",
    "max_length(test_mod['text'], tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the `Text` Feature\n",
    "- Use BERT Tokenizer which will output input_ids and attention mask to be used in BERT model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs =  tokenizer(train_mod['text'].tolist(), padding=True, truncation=True, max_length=128, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs_test = tokenizer(test_mod['text'].tolist(), padding=True, truncation=True, max_length=128, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_inputs_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encoded_inputs['input_ids']\n",
    "attention_mask = encoded_inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test = encoded_inputs_test['input_ids']\n",
    "attention_mask_test = encoded_inputs_test['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  3458,  9115,  ...,     0,     0,     0],\n",
      "        [  101,  4089,  1783,  ...,     0,     0,     0],\n",
      "        [  101,  1398,  3159,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 26528,   119,  ...,     0,     0,     0],\n",
      "        [  101,  3284, 11950,  ...,     0,     0,     0],\n",
      "        [  101,  1109,  6372,  ...,     0,     0,     0]])\n",
      "torch.Size([7613, 106])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "torch.Size([7613, 106])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)\n",
    "print(input_ids.shape)\n",
    "print(attention_mask)\n",
    "print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2066,  2171,  ...,     0,     0,     0],\n",
      "        [  101, 23599,  1164,  ...,     0,     0,     0],\n",
      "        [  101,  1175,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2565,  2800,  ...,     0,     0,     0],\n",
      "        [  101, 22157,  2349,  ...,     0,     0,     0],\n",
      "        [  101,   108,  1392,  ...,     0,     0,     0]])\n",
      "torch.Size([3263, 101])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "torch.Size([3263, 101])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids_test)\n",
    "print(input_ids_test.shape)\n",
    "print(attention_mask_test)\n",
    "print(attention_mask_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize `tweet_length` and `punctuation_count`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have a dataset df that contains both numerical and non-numerical features\n",
    "\n",
    "# Separate the numerical and non-numerical features\n",
    "numerical_features = train_mod[numerical_features_columns]\n",
    "non_numerical_features = train_mod[['text','target']]\n",
    "\n",
    "# Create an instance of the StandardScaler class\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the numerical features\n",
    "scaler.fit(numerical_features)\n",
    "\n",
    "# Transform the numerical features using the fitted scaler\n",
    "numerical_features_scaled = scaler.transform(numerical_features)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features_scaled_test = scaler.transform(test_mod[numerical_features_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scaled_numerical_features to a tensor\n",
    "numerical_tensor = torch.tensor(numerical_features_scaled, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_tensor_test = torch.tensor(numerical_features_scaled_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9501, -1.2671],\n",
       "        [-1.8658, -1.2671],\n",
       "        [ 0.9405, -0.8331],\n",
       "        ...,\n",
       "        [-1.0682,  0.9028],\n",
       "        [ 1.0587, -0.3992],\n",
       "        [-0.2116,  0.0348]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9840, -1.4841],\n",
       "        [-1.0978, -0.8331],\n",
       "        [-0.1525, -1.0501],\n",
       "        ...,\n",
       "        [-1.3636, -0.3992],\n",
       "        [-1.0682,  0.0348],\n",
       "        [-0.9796, -0.8331]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_tensor_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the hidden states from BERT\n",
    "- The last hidden states correspond to the text embedding of each token in the text feature.\n",
    "- We will only take the hidden state of [CLS] which is the starting token, as it contains the information for the entire tweet.\n",
    "- The reason for doing this instead of directly training the model with BERTSequenceClassifier is because we also want to concatenate extra numerical inputs into our hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 512\n",
    "dataset = TensorDataset(input_ids, attention_mask)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = TensorDataset(input_ids_test, attention_mask_test)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "bert_model = BertModel.from_pretrained('bert-base-cased')\n",
    "bert_model.eval()\n",
    "\n",
    "text_embeddings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_input_ids, batch_attention_masks in dataloader:\n",
    "        outputs = bert_model(input_ids=batch_input_ids, attention_mask=batch_attention_masks)\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        text_embeddings.append(batch_embeddings)\n",
    "\n",
    "# Concatenate all batch embeddings into a single tensor\n",
    "text_embeddings = torch.cat(text_embeddings, dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-cased')\n",
    "bert_model.eval()\n",
    "text_embeddings_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_input_ids, batch_attention_masks in dataloader_test:\n",
    "        outputs = bert_model(input_ids=batch_input_ids, attention_mask=batch_attention_masks)\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        text_embeddings_test.append(batch_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all batch embeddings into a single tensor\n",
    "text_embeddings_test = torch.cat(text_embeddings_test, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features_test = torch.cat([text_embeddings_test, numerical_tensor_test], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = torch.cat([text_embeddings, numerical_tensor], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7613, 770])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Neural Network class\n",
    "- This is a simple feed foward neural network that concatenates the numerical features with the bert hidden states to be passed into a linear layer.\n",
    "- More hidden layers can be added to generate a more complex Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "# Create a simple feed-forward neural network\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, bert_output_size, num_numerical_features, num_classes):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.layer = nn.Linear(bert_output_size + num_numerical_features, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModelMoreHLs(nn.Module):\n",
    "    def __init__(self, bert_output_size, num_numerical_features, num_classes, hidden_size=128, dropout_rate=0.5):\n",
    "        super(CombinedModelMoreHLs, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(bert_output_size + num_numerical_features, hidden_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.activation1 = nn.ReLU()\n",
    "\n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.activation2 = nn.ReLU()\n",
    "\n",
    "        self.layer3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        self.activation3 = nn.ReLU()\n",
    "\n",
    "        self.layer4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout4 = nn.Dropout(dropout_rate)\n",
    "        self.activation4 = nn.ReLU()\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.activation1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.activation2(x)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to `numpy` for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = combined_features.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29352632, -0.0725253 , -0.15692264, ..., -0.10713238,\n",
       "        -0.9500721 , -1.267124  ],\n",
       "       [ 0.2558439 ,  0.18093783, -0.17079301, ..., -0.0249753 ,\n",
       "        -1.8658271 , -1.267124  ],\n",
       "       [ 0.05271018,  0.02512372,  0.10772833, ...,  0.07605556,\n",
       "         0.94051886, -0.83313924],\n",
       "       ...,\n",
       "       [ 0.4800464 ,  0.09190952,  0.03730289, ...,  0.06442428,\n",
       "        -1.068234  ,  0.90280026],\n",
       "       [ 0.37591138,  0.06962702, -0.2249266 , ..., -0.06127468,\n",
       "         1.0586808 , -0.39915434],\n",
       "       [ 0.28238675,  0.10167535, -0.27841642, ...,  0.0055821 ,\n",
       "        -0.21156   ,  0.03483052]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features_test = combined_features_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_mod['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_numpy = labels.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaration of Train and Validate function\n",
    "- This uses cross fold validation with a total of 5 folds\n",
    "- Note that due to time constraints, we are only going to cross validate 1 cycle over 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_and_validate(train_dataloader, val_dataloader, len_val_dataset, num_epochs=10, device='cuda' if torch.cuda.is_available() else 'cpu', lr=1e-3):\n",
    "    # Replace with your custom model\n",
    "    # model = CombinedModel(bert_output_size=768, num_numerical_features=len(numerical_features_columns), num_classes=1)\n",
    "    model = CombinedModelMoreHLs(bert_output_size=768, num_numerical_features=len(numerical_features_columns), num_classes=1)\n",
    "    model.to(device)\n",
    "\n",
    "    print(\"Loaded Model to device\")\n",
    "    # Define the loss function and optimizer\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    print(\"Initialized Loss and Optimizer\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch_features, batch_labels in train_dataloader:\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(batch_features)\n",
    "            loss = loss_fn(logits, batch_labels)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Print the average training loss for the epoch\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {total_loss / len(train_dataloader)}')\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_labels in val_dataloader:\n",
    "                batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                logits = model(batch_features)\n",
    "                loss = loss_fn(logits, batch_labels)\n",
    "\n",
    "                # Calculate the number of correct predictions\n",
    "                predictions = (logits > 0).float()\n",
    "                correct_predictions += (predictions == batch_labels).sum().item()\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        # Print the average validation loss and accuracy for the epoch\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {total_val_loss / len(val_dataloader)}, Validation Accuracy: {correct_predictions / len_val_dataset}')\n",
    "    return correct_predictions / len_val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.5584e-01,  1.8094e-01, -1.7079e-01, -2.6513e-01, -4.3705e-01,\n",
       "         5.8956e-02,  3.7884e-01,  1.1668e-01,  1.8814e-01, -1.3791e+00,\n",
       "        -1.6295e-01,  3.5897e-01, -1.2012e-01, -1.8769e-01, -3.4638e-01,\n",
       "         1.7986e-01,  6.7315e-02,  2.1108e-01,  2.7141e-01,  3.2946e-02,\n",
       "        -4.3810e-02, -1.5269e-01,  5.6467e-01, -2.1989e-01,  3.0091e-01,\n",
       "        -1.2909e-01,  1.6395e-01,  1.9878e-01, -1.8192e-01,  1.0246e-01,\n",
       "         3.5770e-02,  2.9780e-02, -1.6495e-01,  2.9364e-01, -8.6084e-02,\n",
       "         2.2865e-01, -1.2303e-01, -3.8921e-01,  3.9487e-02, -3.6750e-01,\n",
       "        -3.9128e-01,  6.3324e-03,  3.2161e-01, -4.2472e-01,  3.1954e-03,\n",
       "        -8.1638e-01,  4.3500e-02, -7.2592e-03, -2.6870e-01, -1.9641e-02,\n",
       "        -7.7145e-02,  3.9884e-01,  5.6206e-01,  8.7265e-02,  3.3191e-01,\n",
       "        -1.6589e-02,  1.7489e-02,  4.9950e-02, -4.0167e-01,  1.2930e-01,\n",
       "         5.5091e-01,  6.6280e-03,  3.0802e-01, -9.7849e-02,  1.4942e-01,\n",
       "        -1.5388e-02, -1.5098e-01,  4.6848e-01, -4.9491e-01, -5.6170e-01,\n",
       "        -1.3467e-01,  1.6382e-01,  3.4321e-01,  9.1607e-01,  4.1354e-01,\n",
       "        -8.1195e-02,  4.5796e-01,  1.0327e-01, -9.0666e-02,  3.9845e-01,\n",
       "        -1.7436e-01,  4.2916e-02, -1.7960e-01, -5.1299e-02, -2.1247e-01,\n",
       "        -1.7351e-01,  7.8205e-02, -2.9716e-01, -1.6322e-01, -1.8872e-01,\n",
       "         1.1559e-01,  1.3945e-01, -2.8096e-01,  6.0584e-02,  6.6691e-02,\n",
       "         2.1263e-01,  2.0839e-01,  2.1947e-01,  5.9583e+00, -9.7344e-02,\n",
       "        -1.1845e-02, -3.2400e-02,  2.9534e-01, -4.4499e-01,  3.7119e-02,\n",
       "         5.9394e-02, -1.4633e-01, -4.5080e-01,  3.1574e-01,  2.6790e-01,\n",
       "         2.3094e-01, -7.9702e-02,  2.5965e-01, -3.6542e-02, -1.3294e-01,\n",
       "        -1.9662e-01, -8.1305e-02,  1.7207e-01,  8.0910e-03, -1.1548e-01,\n",
       "         1.5894e-01, -1.4847e-01,  1.0886e+00, -4.9367e-03, -1.9686e-01,\n",
       "        -6.3750e-02, -2.0864e-01, -3.3620e-02,  2.8638e-01, -2.9131e-01,\n",
       "        -4.9625e-01,  6.2192e-02, -6.0122e-02, -2.0028e-01,  2.9399e-01,\n",
       "         5.6190e-02,  2.9477e-02, -5.3384e-02, -4.5164e-01,  1.9808e-01,\n",
       "         3.2728e-01, -2.1080e-01,  1.5812e-01, -2.3991e-01, -4.8727e-01,\n",
       "         2.5331e+00, -3.2778e-01,  3.3084e-01,  8.7465e-02, -7.9441e-02,\n",
       "        -8.0000e-02, -1.3111e-01, -4.0113e-02,  1.1533e-01, -1.6333e-01,\n",
       "        -1.6302e-01,  1.2326e-01, -5.9064e-02,  6.9571e-02,  8.8359e-02,\n",
       "        -6.1890e-01, -1.7820e-02, -4.5770e-01,  2.7920e-01, -4.2677e-05,\n",
       "        -1.5460e-01,  1.6484e-01, -8.3067e-01,  3.4208e-01,  2.4214e-01,\n",
       "        -3.8160e-01,  7.4445e-02, -1.9473e+00,  4.0085e-01,  2.6107e-03,\n",
       "         2.4313e-01,  2.6311e-02,  1.7031e-01, -3.8638e-02, -3.3818e-01,\n",
       "        -1.2920e-01, -7.1459e-02,  5.1937e-01,  1.0502e-01, -1.8757e-01,\n",
       "         2.0447e-01,  3.2159e-01, -2.7495e-01,  2.8664e-01, -2.2670e-01,\n",
       "        -1.5075e-01, -1.5392e-02, -2.6003e-01, -6.7366e-02,  1.7465e-01,\n",
       "        -4.1054e-02, -1.9121e-01, -2.3577e-01,  4.1764e-01,  2.7649e-01,\n",
       "        -6.5901e-02, -1.7798e-01,  2.1882e-02,  4.7199e-01,  7.4936e-01,\n",
       "        -7.9934e-02,  2.5213e-01,  9.4877e-02, -9.6222e-02,  4.3018e-02,\n",
       "        -3.5052e-01, -2.0538e-01, -4.1237e-02,  2.2269e-01,  2.7501e-01,\n",
       "        -4.5480e-01, -8.8959e-02,  1.3101e-01,  1.1854e-01, -1.2701e-01,\n",
       "        -3.8450e-01,  1.4339e-02, -4.3462e-01, -4.0530e-01, -9.8764e-02,\n",
       "        -4.1048e-01, -1.0629e-01, -1.2877e-01, -1.6393e-01, -3.3398e-01,\n",
       "         3.7360e-01, -4.4224e-02, -1.8027e-01, -1.7306e-01,  2.6395e-01,\n",
       "        -1.3614e-01,  2.2732e-03, -8.6429e-03, -2.2215e-01,  2.9193e-01,\n",
       "         7.1176e-02, -2.9324e-02,  9.5116e-02, -2.3337e-01, -4.6791e-01,\n",
       "         2.9552e-01,  7.6263e-01,  1.2574e-01,  2.8395e-02,  3.6719e-01,\n",
       "         8.6094e-01,  1.6650e-01, -1.0006e-01, -4.2537e-01, -1.3057e-01,\n",
       "         1.5550e-02, -2.3669e-01, -1.2460e+00, -1.9309e-01, -1.4790e-01,\n",
       "         2.5760e-01, -3.1509e+00,  3.9029e-01,  1.6648e-01, -1.5511e-01,\n",
       "        -9.2267e-02,  1.8439e-01,  3.6567e-02, -7.7467e-02,  3.6813e-01,\n",
       "        -4.7977e-01, -4.7494e-02, -4.7527e-01, -4.8864e-02, -4.8356e-02,\n",
       "         2.5507e-01, -4.4813e-01,  2.3564e-01, -1.2059e-01, -2.0477e-01,\n",
       "        -1.2504e-02,  1.2588e-01, -1.5025e-01,  6.4780e-02, -1.0362e-01,\n",
       "         2.9969e-01,  6.5917e-01,  3.9747e-01, -1.2095e-01,  3.9952e+00,\n",
       "         2.0772e-01,  3.4756e-01,  3.6382e-01, -1.6808e-01, -3.0417e-01,\n",
       "         3.3594e-01, -8.1430e-01,  8.6207e-03,  1.7435e-01, -2.3136e-01,\n",
       "         3.8029e-02, -1.5382e-01, -4.3187e-01, -3.6664e-01, -2.8631e-01,\n",
       "        -1.7748e-02, -2.7889e-02,  9.0470e-02, -6.8909e-01,  1.1357e-01,\n",
       "         4.6275e-01,  4.3546e-02, -3.6439e-02,  2.9943e-02, -2.1631e-01,\n",
       "        -7.0298e-01, -4.4306e-01,  5.7771e-01, -4.6023e-02, -9.8678e-01,\n",
       "        -1.0090e-01,  2.8863e-01, -5.9122e-01,  1.7593e-01,  1.0409e-01,\n",
       "        -1.1267e-01,  1.0616e-01, -1.6009e-01,  5.2297e-02,  2.3301e-01,\n",
       "        -2.2751e-01,  2.0611e-02, -4.1883e-01, -3.5442e-01, -1.7016e-02,\n",
       "        -1.5741e-01, -4.2651e-01, -1.6736e-01, -3.8105e-01,  3.2924e-01,\n",
       "        -3.1063e-01,  1.7592e-01, -1.4280e-02, -6.6245e-02,  3.3747e-01,\n",
       "         1.2442e-01, -1.9632e-01, -2.5617e-01, -1.4798e-02,  7.0891e-01,\n",
       "        -1.3693e-01,  3.1428e-02,  1.6213e-01,  4.4093e-01, -3.9656e-01,\n",
       "        -9.4637e-02, -1.7004e-01, -9.7996e-02,  1.3358e-01, -2.1960e-01,\n",
       "        -3.9655e-01, -1.8899e+00,  4.6482e-01,  3.8109e-02, -1.4127e-01,\n",
       "        -1.1725e-01, -1.3309e-01,  1.0321e-01, -1.8469e-01,  2.8603e-01,\n",
       "         1.8268e-01,  2.5977e-01,  3.1583e-01,  1.4014e-01, -4.4890e-01,\n",
       "         2.5068e-01, -1.6856e-02,  1.1018e+00, -9.9824e-03, -3.9765e-01,\n",
       "        -5.0902e-01, -1.0307e-01,  2.8159e-01,  1.1057e-01, -3.7504e-01,\n",
       "         4.3605e-01,  1.3974e-01, -2.1019e-01,  1.8067e-01,  9.8000e-03,\n",
       "         5.5085e-01, -1.5598e-01, -1.9031e-01, -2.6892e-01, -3.6769e-01,\n",
       "        -5.1667e-02, -3.3363e-02,  1.1299e-02,  5.8907e-01,  1.8741e-01,\n",
       "        -3.1693e-01,  2.9613e-01,  1.4450e-01, -4.0647e-02,  4.2288e-02,\n",
       "         3.6653e-01,  1.2616e-01, -3.2860e-01, -1.0519e+00,  4.2975e-02,\n",
       "        -3.1935e-01, -1.4577e-01, -5.3905e-01,  1.5981e-01,  2.4747e-01,\n",
       "         2.3883e-01,  4.0672e-01, -1.5679e-01,  3.0330e-01,  1.6096e-02,\n",
       "         2.1308e-01,  7.6938e-02, -1.9118e-01,  6.4088e-02, -5.3771e-01,\n",
       "         2.9274e-01, -2.3624e-02, -4.6418e-01,  1.2255e-01,  4.2044e-02,\n",
       "        -4.9718e-01, -2.2280e-01,  2.3505e-01, -1.5908e-01, -4.0784e-01,\n",
       "        -3.6357e-01,  5.7035e-02, -1.7855e-01, -3.0057e-01,  4.8147e+00,\n",
       "        -4.8671e-01,  4.9361e-01,  1.9862e-01, -1.2134e-01, -1.4010e-01,\n",
       "         7.4349e-02, -1.2104e-01,  9.1511e-01, -2.1573e-01, -6.3340e-02,\n",
       "        -6.5185e-01,  2.1448e-01,  1.2659e-01, -3.4797e-01,  4.2923e-01,\n",
       "         8.0223e-02, -6.0715e-02, -3.0275e-02, -6.5153e-01, -4.9681e-02,\n",
       "        -3.3713e-01,  1.3827e-01, -1.4791e-01,  5.0011e-01,  3.1670e-01,\n",
       "        -1.7194e-01, -1.8313e-01, -2.7986e-01, -2.9287e-02, -5.8853e-01,\n",
       "         4.7260e-01,  3.0847e-01,  1.3734e-01, -7.0342e-02, -2.4027e-01,\n",
       "         1.6711e-01,  1.3177e-01,  2.3567e-01, -7.4628e-03,  7.7966e-02,\n",
       "        -1.6594e-02,  7.1786e-01,  6.1311e-02,  3.5798e-01,  4.1912e-01,\n",
       "         1.1117e-01,  1.9578e-02,  1.9777e-01,  4.9200e-01, -1.6749e-01,\n",
       "         6.4143e-02,  4.2801e-02, -3.9856e-01,  8.5342e-02,  2.3863e-01,\n",
       "        -7.7880e-02, -4.2924e-01,  2.9176e-01,  2.0381e-01, -6.1984e-02,\n",
       "        -9.2818e-02, -3.7880e-01,  2.3460e-02, -1.2960e-01, -3.9881e-01,\n",
       "         4.7126e-01, -2.1201e-01,  2.5346e-01, -3.1382e-01, -1.1686e-01,\n",
       "        -1.2509e-01, -6.7483e-01,  9.1491e-02,  1.9159e-01, -3.5051e-03,\n",
       "        -6.0814e-01,  9.2888e-03, -1.6188e-01, -6.6355e-02, -1.9919e-01,\n",
       "         1.9347e-01, -2.0049e-01, -3.5767e-01,  2.9907e-01, -2.2985e-01,\n",
       "        -9.6713e-01, -5.8820e-02,  2.2892e-02,  4.2655e-01,  1.4552e-01,\n",
       "        -4.5358e-02,  7.4401e-02, -1.5398e-01, -2.1143e-02, -1.3642e-01,\n",
       "        -4.4854e-01,  2.1592e-01, -1.9863e-01, -8.0210e-02,  4.1195e-01,\n",
       "         2.5769e-01,  3.9754e-01,  2.4976e-01,  2.7691e-01, -2.1657e-01,\n",
       "         7.1023e-02, -8.3307e-02, -9.0690e-02, -3.4582e-02,  4.9591e-01,\n",
       "         8.9904e-02,  3.9867e-03, -1.0844e-01, -2.0857e-01,  1.1273e-01,\n",
       "         1.1706e-01, -2.4674e-01, -7.3247e+00,  2.9290e-01, -6.3859e-02,\n",
       "         1.9705e-01, -2.9634e-01, -2.6639e-01,  4.2589e-01,  4.2104e-01,\n",
       "         3.5663e-02,  3.9136e-01, -2.0552e-01,  1.1738e-01, -1.9566e+00,\n",
       "         5.1983e-01, -1.0835e-01,  1.2019e-01, -7.3637e-02, -9.1325e-01,\n",
       "         5.1875e-02,  7.8767e-01, -1.1261e-01,  9.2622e-03,  1.8451e-01,\n",
       "        -2.1675e-02,  3.3171e-01, -7.8744e-02,  1.8096e-01,  6.4527e-02,\n",
       "         1.1947e-02, -1.5983e-01,  2.1775e-01, -1.4584e-02,  6.5998e-01,\n",
       "         2.3685e-02, -1.7734e-02, -6.7572e-02,  1.9491e-01,  2.9907e-01,\n",
       "         1.7701e-01,  2.1838e-02, -2.2836e-01,  1.7327e-01, -2.6770e-02,\n",
       "         5.2035e-03, -5.7000e-01, -1.3761e-01, -6.0303e-01, -2.2700e+00,\n",
       "         2.4201e-01, -1.6674e-01,  2.3427e-01, -6.4820e-02, -4.2545e-02,\n",
       "        -3.8779e-02, -6.5785e-01,  2.2516e-02, -2.3920e-01, -9.8150e-02,\n",
       "         3.8246e-01, -1.4513e-01, -2.3187e-01, -8.2546e-02,  3.9002e-01,\n",
       "         9.5561e-02, -2.3471e-02,  2.4149e-01, -4.2771e-01, -8.5547e-02,\n",
       "        -4.6934e-02, -5.8198e-02, -2.4009e-01,  2.1110e-02,  1.1704e-01,\n",
       "         1.3025e-01,  8.4316e-02,  1.2769e-01, -1.3716e-01,  4.5981e-02,\n",
       "        -2.6071e-01,  2.5933e-02, -3.9133e-01,  6.4549e-02,  1.8609e-01,\n",
       "         2.3116e-01,  1.3018e-01,  7.1499e-03,  1.3623e-01,  3.2371e-01,\n",
       "        -1.5884e-01, -9.9184e-02,  2.9454e-01,  3.1491e-02,  1.9647e-01,\n",
       "        -2.4653e-04, -2.4623e-01,  2.4469e-01, -2.6285e-01,  1.6534e-01,\n",
       "        -3.9740e-01, -4.6658e-01,  1.4874e-01,  1.5557e-01, -1.4532e-01,\n",
       "        -2.0556e-01, -1.4725e-01, -1.9443e-01,  2.4823e+00,  1.9104e-02,\n",
       "        -1.5080e-01,  3.8613e-02,  8.6687e-02,  2.9021e-01, -2.3004e-01,\n",
       "         1.8321e-02,  1.7618e+00,  1.0067e-01, -2.2675e-01,  7.5831e-03,\n",
       "         3.8657e-02, -5.0813e-02, -3.7062e-01,  5.2478e-01,  9.7300e-02,\n",
       "         2.5556e-01, -2.8044e-01, -9.3699e-03,  3.2395e-01, -3.9104e-01,\n",
       "         4.6522e-01, -5.5576e-02, -1.0181e-01, -2.0128e-01, -1.1570e-01,\n",
       "        -5.4399e-01,  7.8746e-02, -6.4373e-01,  3.7418e-01,  7.8972e-02,\n",
       "        -5.7750e-02,  1.0094e+00, -9.5065e-02,  1.7111e-01,  2.6285e-01,\n",
       "         5.6512e-02,  8.9754e-03, -3.5620e-01, -1.2590e-01, -7.0137e-02,\n",
       "        -7.1432e-01,  4.4468e-01, -2.3739e-01, -1.0051e-01, -1.7916e-01,\n",
       "        -6.0959e-01,  1.3074e-01,  6.9473e-02, -4.5596e-02, -6.3148e-01,\n",
       "         1.0044e-01,  3.9238e-01, -3.8896e-03, -2.8757e-01, -2.1926e-01,\n",
       "         1.8451e-01,  1.6005e-01,  1.0354e-01,  4.5509e-02, -4.7587e-03,\n",
       "         4.4632e-03, -7.5936e-02,  4.1854e-01, -5.5067e-01,  7.4686e-02,\n",
       "         2.8148e-02, -1.1504e-01, -6.4155e-01,  1.3935e-01,  1.6597e-01,\n",
       "        -2.1323e+00, -3.5825e-01,  1.4119e-01, -8.9194e-02, -5.2051e-02,\n",
       "        -3.1872e-01,  4.0992e-01,  1.2950e-01,  4.1786e-01,  2.0556e-01,\n",
       "         1.4412e-01,  1.3656e+00, -7.8694e-02, -2.1906e-01,  1.9554e-03,\n",
       "         3.1055e-02,  3.6197e-01, -1.4234e-01, -2.8314e-01, -8.1316e-01,\n",
       "        -1.8910e-01,  1.2677e+00, -6.6939e-02,  2.7426e-01,  6.2093e-01,\n",
       "         7.2051e-02,  1.0820e-02,  1.7770e-01,  2.8536e-01,  3.1812e-02,\n",
       "        -1.3905e-01,  1.7801e-01, -2.4975e-02, -1.8658e+00, -1.2671e+00])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(combined_features[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = torch.tensor(labels_numpy).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7613, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.type()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performed with CombinedModel\n",
    "- Here we perform the cross validation and print the validation accuracy for each epoch\n",
    "- Then the final average validation accuracy is printed after the cross validation completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5347162181135081\n",
      "Epoch 1/10, Validation Loss: 0.5010097459816808, Validation Accuracy: 0.767564018384767\n",
      "Epoch 2/10, Training Loss: 0.47742430151995086\n",
      "Epoch 2/10, Validation Loss: 0.4876218304740197, Validation Accuracy: 0.7806959947472094\n",
      "Epoch 3/10, Training Loss: 0.4624437052668549\n",
      "Epoch 3/10, Validation Loss: 0.4742159277824831, Validation Accuracy: 0.7820091923834537\n",
      "Epoch 4/10, Training Loss: 0.4534211536659187\n",
      "Epoch 4/10, Validation Loss: 0.47393152250357323, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 5/10, Training Loss: 0.4481302302262289\n",
      "Epoch 5/10, Validation Loss: 0.4651305778488439, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 6/10, Training Loss: 0.44344139387562204\n",
      "Epoch 6/10, Validation Loss: 0.46595514511094666, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 7/10, Training Loss: 0.4373610830545582\n",
      "Epoch 7/10, Validation Loss: 0.4614184647408455, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 8/10, Training Loss: 0.43640169409394575\n",
      "Epoch 8/10, Validation Loss: 0.4599231387932263, Validation Accuracy: 0.793827971109652\n",
      "Epoch 9/10, Training Loss: 0.43518955201849224\n",
      "Epoch 9/10, Validation Loss: 0.45895016489852786, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 10/10, Training Loss: 0.4318921364002966\n",
      "Epoch 10/10, Validation Loss: 0.4614957580391649, Validation Accuracy: 0.7951411687458962\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5368689765611033\n",
      "Epoch 1/10, Validation Loss: 0.49240345808223906, Validation Accuracy: 0.7649376231122784\n",
      "Epoch 2/10, Training Loss: 0.4810459722723235\n",
      "Epoch 2/10, Validation Loss: 0.475053579239321, Validation Accuracy: 0.7760998030203545\n",
      "Epoch 3/10, Training Loss: 0.46726255490398155\n",
      "Epoch 3/10, Validation Loss: 0.46809832578164123, Validation Accuracy: 0.7806959947472094\n",
      "Epoch 4/10, Training Loss: 0.4576334905299771\n",
      "Epoch 4/10, Validation Loss: 0.4544512140930323, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 5/10, Training Loss: 0.4524024541922442\n",
      "Epoch 5/10, Validation Loss: 0.44916372757931655, Validation Accuracy: 0.799080761654629\n",
      "Epoch 6/10, Training Loss: 0.44761237270367427\n",
      "Epoch 6/10, Validation Loss: 0.44615051417528645, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 7/10, Training Loss: 0.4435365741725356\n",
      "Epoch 7/10, Validation Loss: 0.4596637195434558, Validation Accuracy: 0.783322390019698\n",
      "Epoch 8/10, Training Loss: 0.4382826765593425\n",
      "Epoch 8/10, Validation Loss: 0.4451840837822535, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 9/10, Training Loss: 0.43681471858398496\n",
      "Epoch 9/10, Validation Loss: 0.44341711672656825, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 10/10, Training Loss: 0.43618223559981567\n",
      "Epoch 10/10, Validation Loss: 0.4439752775571109, Validation Accuracy: 0.7971109652002626\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5385558317926299\n",
      "Epoch 1/10, Validation Loss: 0.5323043339227507, Validation Accuracy: 0.7255416940249507\n",
      "Epoch 2/10, Training Loss: 0.478968786520595\n",
      "Epoch 2/10, Validation Loss: 0.5003990705334703, Validation Accuracy: 0.767564018384767\n",
      "Epoch 3/10, Training Loss: 0.4647023406202399\n",
      "Epoch 3/10, Validation Loss: 0.4695730293218378, Validation Accuracy: 0.7820091923834537\n",
      "Epoch 4/10, Training Loss: 0.45731510362756533\n",
      "Epoch 4/10, Validation Loss: 0.46322442208909237, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 5/10, Training Loss: 0.44852571505222105\n",
      "Epoch 5/10, Validation Loss: 0.46020522229958577, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 6/10, Training Loss: 0.4454102318078827\n",
      "Epoch 6/10, Validation Loss: 0.4567865138746681, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 7/10, Training Loss: 0.44068182328241706\n",
      "Epoch 7/10, Validation Loss: 0.4689027468883554, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 8/10, Training Loss: 0.437181826700454\n",
      "Epoch 8/10, Validation Loss: 0.4621890492698285, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 9/10, Training Loss: 0.4337515677875421\n",
      "Epoch 9/10, Validation Loss: 0.4542635685876402, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 10/10, Training Loss: 0.431432890087327\n",
      "Epoch 10/10, Validation Loss: 0.46180951901521355, Validation Accuracy: 0.7944845699277742\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5389218946180632\n",
      "Epoch 1/10, Validation Loss: 0.4946536101517877, Validation Accuracy: 0.771353482260184\n",
      "Epoch 2/10, Training Loss: 0.48208667911843367\n",
      "Epoch 2/10, Validation Loss: 0.4882499274861126, Validation Accuracy: 0.7647831800262812\n",
      "Epoch 3/10, Training Loss: 0.46933361381448785\n",
      "Epoch 3/10, Validation Loss: 0.4810949152442797, Validation Accuracy: 0.778580814717477\n",
      "Epoch 4/10, Training Loss: 0.45990087171121846\n",
      "Epoch 4/10, Validation Loss: 0.4540968498322352, Validation Accuracy: 0.7917214191852825\n",
      "Epoch 5/10, Training Loss: 0.45268996151804614\n",
      "Epoch 5/10, Validation Loss: 0.4490112187584657, Validation Accuracy: 0.7956636005256241\n",
      "Epoch 6/10, Training Loss: 0.44919740299149136\n",
      "Epoch 6/10, Validation Loss: 0.45013320130047374, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 7/10, Training Loss: 0.4430055329649467\n",
      "Epoch 7/10, Validation Loss: 0.4452563620596656, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 8/10, Training Loss: 0.4402472537470458\n",
      "Epoch 8/10, Validation Loss: 0.44532690766750205, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 9/10, Training Loss: 0.4363482826611814\n",
      "Epoch 9/10, Validation Loss: 0.4455172732979527, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 10/10, Training Loss: 0.436483221563689\n",
      "Epoch 10/10, Validation Loss: 0.44279988086660493, Validation Accuracy: 0.7950065703022339\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5381917324982916\n",
      "Epoch 1/10, Validation Loss: 0.4873603013641547, Validation Accuracy: 0.7818659658344284\n",
      "Epoch 2/10, Training Loss: 0.4808192548202717\n",
      "Epoch 2/10, Validation Loss: 0.47855997885240936, Validation Accuracy: 0.7844940867279895\n",
      "Epoch 3/10, Training Loss: 0.4646557100762532\n",
      "Epoch 3/10, Validation Loss: 0.46554995831394697, Validation Accuracy: 0.797634691195795\n",
      "Epoch 4/10, Training Loss: 0.45654490194100095\n",
      "Epoch 4/10, Validation Loss: 0.47395105702870804, Validation Accuracy: 0.7864651773981604\n",
      "Epoch 5/10, Training Loss: 0.45085444032481026\n",
      "Epoch 5/10, Validation Loss: 0.46595578402748905, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 6/10, Training Loss: 0.44617060912171685\n",
      "Epoch 6/10, Validation Loss: 0.4570771808009497, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 7/10, Training Loss: 0.4392168783140308\n",
      "Epoch 7/10, Validation Loss: 0.4584185474830148, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 8/10, Training Loss: 0.43941112674205635\n",
      "Epoch 8/10, Validation Loss: 0.4540712946138457, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 9/10, Training Loss: 0.4358281398539155\n",
      "Epoch 9/10, Validation Loss: 0.46716786406115085, Validation Accuracy: 0.7851511169513797\n",
      "Epoch 10/10, Training Loss: 0.4318308892642732\n",
      "Epoch 10/10, Validation Loss: 0.4696394258534721, Validation Accuracy: 0.7864651773981604\n",
      "Average Validation Accuracy: 0.7936416903148654\n"
     ]
    }
   ],
   "source": [
    "val_accuracies = []\n",
    "for train_idx, val_idx in skf.split(combined_features, labels):\n",
    "    # Create TensorDatasets for the current fold\n",
    "    train_dataset = TensorDataset(torch.tensor(combined_features[train_idx]), torch.tensor(labels_numpy[train_idx].reshape(-1,1), dtype=torch.float32))\n",
    "    val_dataset = TensorDataset(torch.tensor(combined_features[val_idx]), torch.tensor(labels_numpy[val_idx].reshape(-1,1), dtype=torch.float32))\n",
    "\n",
    "    # Create DataLoaders for the current fold\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    # Train and validate your model for the current fold\n",
    "    # Train and validate your model for the current fold and store the validation accuracy\n",
    "    val_accuracy = train_and_validate(train_dataloader, val_dataloader, len(val_dataset))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Calculate the average validation accuracy across all folds\n",
    "average_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "print(f'Average Validation Accuracy: {average_val_accuracy}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performed on CombinedModel but with different epoch sizes\n",
    "- To roughly identify a more optimal epoch rate, we will loop through different epoch sizes, and do a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5352119240039602\n",
      "Epoch 1/10, Validation Loss: 0.49624163294649876, Validation Accuracy: 0.7741300065659882\n",
      "Epoch 2/10, Training Loss: 0.47872721233705834\n",
      "Epoch 2/10, Validation Loss: 0.4849823412938892, Validation Accuracy: 0.7826657912015759\n",
      "Epoch 3/10, Training Loss: 0.4633874717874946\n",
      "Epoch 3/10, Validation Loss: 0.4758645262159602, Validation Accuracy: 0.7852921864740644\n",
      "Epoch 4/10, Training Loss: 0.45356030965571015\n",
      "Epoch 4/10, Validation Loss: 0.5070801740853574, Validation Accuracy: 0.7747866053841103\n",
      "Epoch 5/10, Training Loss: 0.45188547236224014\n",
      "Epoch 5/10, Validation Loss: 0.49505341571819095, Validation Accuracy: 0.7767564018384767\n",
      "Epoch 6/10, Training Loss: 0.4432294116773474\n",
      "Epoch 6/10, Validation Loss: 0.4624300138800556, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 7/10, Training Loss: 0.4396355959960795\n",
      "Epoch 7/10, Validation Loss: 0.46107327544096255, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 8/10, Training Loss: 0.4371316383184567\n",
      "Epoch 8/10, Validation Loss: 0.4597968949463355, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 9/10, Training Loss: 0.4324582435405786\n",
      "Epoch 9/10, Validation Loss: 0.46321135096212956, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 10/10, Training Loss: 0.4309972290174542\n",
      "Epoch 10/10, Validation Loss: 0.4639138206059396, Validation Accuracy: 0.7951411687458962\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5377942601565927\n",
      "Epoch 1/10, Validation Loss: 0.48564362135857186, Validation Accuracy: 0.7741300065659882\n",
      "Epoch 2/10, Training Loss: 0.48163522382968366\n",
      "Epoch 2/10, Validation Loss: 0.46486558265867034, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 3/10, Training Loss: 0.4664827563807251\n",
      "Epoch 3/10, Validation Loss: 0.4748683972040396, Validation Accuracy: 0.7741300065659882\n",
      "Epoch 4/10, Training Loss: 0.459683325004781\n",
      "Epoch 4/10, Validation Loss: 0.45006219324953267, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 5/10, Training Loss: 0.4533950427444432\n",
      "Epoch 5/10, Validation Loss: 0.45292988994904837, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 6/10, Training Loss: 0.44586045650907075\n",
      "Epoch 6/10, Validation Loss: 0.4471396388222722, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 7/10, Training Loss: 0.446027288540924\n",
      "Epoch 7/10, Validation Loss: 0.44327074363437624, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 8/10, Training Loss: 0.43962390024674536\n",
      "Epoch 8/10, Validation Loss: 0.4435281606673882, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 9/10, Training Loss: 0.43658046460566247\n",
      "Epoch 9/10, Validation Loss: 0.4409234046506944, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 10/10, Training Loss: 0.43435552272349204\n",
      "Epoch 10/10, Validation Loss: 0.4442821381447827, Validation Accuracy: 0.7957977675640184\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.535713972479809\n",
      "Epoch 1/10, Validation Loss: 0.5029541539194072, Validation Accuracy: 0.7662508207485227\n",
      "Epoch 2/10, Training Loss: 0.4821103811557368\n",
      "Epoch 2/10, Validation Loss: 0.4780053973431987, Validation Accuracy: 0.7787261982928431\n",
      "Epoch 3/10, Training Loss: 0.4641715057800448\n",
      "Epoch 3/10, Validation Loss: 0.46770438466084563, Validation Accuracy: 0.783322390019698\n",
      "Epoch 4/10, Training Loss: 0.4565125805401583\n",
      "Epoch 4/10, Validation Loss: 0.46435316507728935, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 5/10, Training Loss: 0.44912795709773623\n",
      "Epoch 5/10, Validation Loss: 0.465070822554109, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 6/10, Training Loss: 0.44422844553908963\n",
      "Epoch 6/10, Validation Loss: 0.45809646863587866, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 7/10, Training Loss: 0.4424472614105918\n",
      "Epoch 7/10, Validation Loss: 0.457699160379265, Validation Accuracy: 0.793827971109652\n",
      "Epoch 8/10, Training Loss: 0.43666997679027675\n",
      "Epoch 8/10, Validation Loss: 0.4623743239887722, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 9/10, Training Loss: 0.43147891287611223\n",
      "Epoch 9/10, Validation Loss: 0.4513558679460231, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 10/10, Training Loss: 0.4311275667855589\n",
      "Epoch 10/10, Validation Loss: 0.4517165072145262, Validation Accuracy: 0.7964543663821405\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5380016033417909\n",
      "Epoch 1/10, Validation Loss: 0.48802828819963945, Validation Accuracy: 0.7693823915900131\n",
      "Epoch 2/10, Training Loss: 0.4824037966843978\n",
      "Epoch 2/10, Validation Loss: 0.4666610506816684, Validation Accuracy: 0.7798948751642576\n",
      "Epoch 3/10, Training Loss: 0.46870513737514574\n",
      "Epoch 3/10, Validation Loss: 0.4713993262675108, Validation Accuracy: 0.7779237844940867\n",
      "Epoch 4/10, Training Loss: 0.45971283258924023\n",
      "Epoch 4/10, Validation Loss: 0.45340787837798685, Validation Accuracy: 0.7910643889618922\n",
      "Epoch 5/10, Training Loss: 0.45325164730095957\n",
      "Epoch 5/10, Validation Loss: 0.4553223327972502, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 6/10, Training Loss: 0.4472308567287571\n",
      "Epoch 6/10, Validation Loss: 0.46475871742083763, Validation Accuracy: 0.7884362680683311\n",
      "Epoch 7/10, Training Loss: 0.4432767417692528\n",
      "Epoch 7/10, Validation Loss: 0.4480095190917634, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 8/10, Training Loss: 0.441085720781892\n",
      "Epoch 8/10, Validation Loss: 0.4457349629380316, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 9/10, Training Loss: 0.43847198014849126\n",
      "Epoch 9/10, Validation Loss: 0.44508479915910365, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 10/10, Training Loss: 0.43602245044833404\n",
      "Epoch 10/10, Validation Loss: 0.44266899821411876, Validation Accuracy: 0.8028909329829172\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/10, Training Loss: 0.5397226113112267\n",
      "Epoch 1/10, Validation Loss: 0.4874519094902808, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 2/10, Training Loss: 0.47992265964626013\n",
      "Epoch 2/10, Validation Loss: 0.48763765710654683, Validation Accuracy: 0.7687253613666228\n",
      "Epoch 3/10, Training Loss: 0.4650420304436696\n",
      "Epoch 3/10, Validation Loss: 0.4731865171440609, Validation Accuracy: 0.7792378449408672\n",
      "Epoch 4/10, Training Loss: 0.4565243931619201\n",
      "Epoch 4/10, Validation Loss: 0.48273274185457776, Validation Accuracy: 0.7733245729303548\n",
      "Epoch 5/10, Training Loss: 0.45021035284625266\n",
      "Epoch 5/10, Validation Loss: 0.4569368234089532, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 6/10, Training Loss: 0.4449288131781607\n",
      "Epoch 6/10, Validation Loss: 0.4573935327651613, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 7/10, Training Loss: 0.43949681616283154\n",
      "Epoch 7/10, Validation Loss: 0.4574735256311781, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 8/10, Training Loss: 0.4378281390573096\n",
      "Epoch 8/10, Validation Loss: 0.4708404073891527, Validation Accuracy: 0.7923784494086727\n",
      "Epoch 9/10, Training Loss: 0.4353414948570134\n",
      "Epoch 9/10, Validation Loss: 0.4546390665763336, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 10/10, Training Loss: 0.43302256249262905\n",
      "Epoch 10/10, Validation Loss: 0.45289904031297923, Validation Accuracy: 0.8042049934296978\n",
      "Average Validation Accuracy: 0.798897845820934\n",
      "Number of Epochs: 10\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/20, Training Loss: 0.533349449983419\n",
      "Epoch 1/20, Validation Loss: 0.49412413066282324, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 2/20, Training Loss: 0.4755069975621431\n",
      "Epoch 2/20, Validation Loss: 0.49813801038483674, Validation Accuracy: 0.7715036112934996\n",
      "Epoch 3/20, Training Loss: 0.4639764194159214\n",
      "Epoch 3/20, Validation Loss: 0.48295798616883645, Validation Accuracy: 0.7826657912015759\n",
      "Epoch 4/20, Training Loss: 0.4540339174076641\n",
      "Epoch 4/20, Validation Loss: 0.47123246499537175, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 5/20, Training Loss: 0.4469790524971767\n",
      "Epoch 5/20, Validation Loss: 0.46837787295043154, Validation Accuracy: 0.7839789888378201\n",
      "Epoch 6/20, Training Loss: 0.4448945933654709\n",
      "Epoch 6/20, Validation Loss: 0.4612571825297715, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 7/20, Training Loss: 0.4397974926636131\n",
      "Epoch 7/20, Validation Loss: 0.48221466506963, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 8/20, Training Loss: 0.4365574011672044\n",
      "Epoch 8/20, Validation Loss: 0.4656838911210055, Validation Accuracy: 0.7879185817465528\n",
      "Epoch 9/20, Training Loss: 0.4341409400965911\n",
      "Epoch 9/20, Validation Loss: 0.4596559125247426, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 10/20, Training Loss: 0.43171618434935416\n",
      "Epoch 10/20, Validation Loss: 0.45836884048596727, Validation Accuracy: 0.793827971109652\n",
      "Epoch 11/20, Training Loss: 0.4275729259637397\n",
      "Epoch 11/20, Validation Loss: 0.45844781406574847, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 12/20, Training Loss: 0.42550552289277865\n",
      "Epoch 12/20, Validation Loss: 0.45717108585135474, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 13/20, Training Loss: 0.4258772564509253\n",
      "Epoch 13/20, Validation Loss: 0.45628021793995854, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 14/20, Training Loss: 0.4234006248140742\n",
      "Epoch 14/20, Validation Loss: 0.46392179171296316, Validation Accuracy: 0.7826657912015759\n",
      "Epoch 15/20, Training Loss: 0.42181048281197475\n",
      "Epoch 15/20, Validation Loss: 0.459699879805143, Validation Accuracy: 0.7839789888378201\n",
      "Epoch 16/20, Training Loss: 0.4189325205962176\n",
      "Epoch 16/20, Validation Loss: 0.4632574357872546, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 17/20, Training Loss: 0.41836245407856354\n",
      "Epoch 17/20, Validation Loss: 0.45806114761773203, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 18/20, Training Loss: 0.41554681281131395\n",
      "Epoch 18/20, Validation Loss: 0.45538902547971116, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 19/20, Training Loss: 0.41784563084717186\n",
      "Epoch 19/20, Validation Loss: 0.45695977355719236, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 20/20, Training Loss: 0.4142038551332757\n",
      "Epoch 20/20, Validation Loss: 0.4561605246942393, Validation Accuracy: 0.804333552199606\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/20, Training Loss: 0.5410908363818183\n",
      "Epoch 1/20, Validation Loss: 0.506364291133993, Validation Accuracy: 0.7590282337491793\n",
      "Epoch 2/20, Training Loss: 0.48353142056643494\n",
      "Epoch 2/20, Validation Loss: 0.464352471198087, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 3/20, Training Loss: 0.4674392336896398\n",
      "Epoch 3/20, Validation Loss: 0.45919547007658096, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 4/20, Training Loss: 0.45844901388320397\n",
      "Epoch 4/20, Validation Loss: 0.4519883305692548, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 5/20, Training Loss: 0.451864130619004\n",
      "Epoch 5/20, Validation Loss: 0.45093585410355275, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 6/20, Training Loss: 0.44718403631229725\n",
      "Epoch 6/20, Validation Loss: 0.44743947977326926, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 7/20, Training Loss: 0.44166015634151895\n",
      "Epoch 7/20, Validation Loss: 0.44425297442687117, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 8/20, Training Loss: 0.4398198741783933\n",
      "Epoch 8/20, Validation Loss: 0.4455820674476511, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 9/20, Training Loss: 0.4377884632587589\n",
      "Epoch 9/20, Validation Loss: 0.44556168390740275, Validation Accuracy: 0.793827971109652\n",
      "Epoch 10/20, Training Loss: 0.43473202874028466\n",
      "Epoch 10/20, Validation Loss: 0.4468150122666546, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 11/20, Training Loss: 0.4326730564705969\n",
      "Epoch 11/20, Validation Loss: 0.44183960845645187, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 12/20, Training Loss: 0.4315429484261459\n",
      "Epoch 12/20, Validation Loss: 0.4470768440222241, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 13/20, Training Loss: 0.4296115374881921\n",
      "Epoch 13/20, Validation Loss: 0.4440969622728088, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 14/20, Training Loss: 0.42613195043223423\n",
      "Epoch 14/20, Validation Loss: 0.4484976933810723, Validation Accuracy: 0.799080761654629\n",
      "Epoch 15/20, Training Loss: 0.4247394876940826\n",
      "Epoch 15/20, Validation Loss: 0.43977091644758953, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 16/20, Training Loss: 0.42314065331862044\n",
      "Epoch 16/20, Validation Loss: 0.44314965512115917, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 17/20, Training Loss: 0.4206113602154524\n",
      "Epoch 17/20, Validation Loss: 0.4398606314631033, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 18/20, Training Loss: 0.42321526437137386\n",
      "Epoch 18/20, Validation Loss: 0.439794517682953, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 19/20, Training Loss: 0.4189991223921613\n",
      "Epoch 19/20, Validation Loss: 0.4406211372094317, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 20/20, Training Loss: 0.4169774002094907\n",
      "Epoch 20/20, Validation Loss: 0.4408952976474587, Validation Accuracy: 0.8010505581089954\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/20, Training Loss: 0.539226684983321\n",
      "Epoch 1/20, Validation Loss: 0.5110914127520866, Validation Accuracy: 0.7583716349310571\n",
      "Epoch 2/20, Training Loss: 0.47904307659216755\n",
      "Epoch 2/20, Validation Loss: 0.48713510144131345, Validation Accuracy: 0.7754432042022325\n",
      "Epoch 3/20, Training Loss: 0.4644985871482396\n",
      "Epoch 3/20, Validation Loss: 0.4728767457978888, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 4/20, Training Loss: 0.4559827077244054\n",
      "Epoch 4/20, Validation Loss: 0.4645301292001889, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 5/20, Training Loss: 0.44785626299112175\n",
      "Epoch 5/20, Validation Loss: 0.4655859333838468, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 6/20, Training Loss: 0.44402663302155615\n",
      "Epoch 6/20, Validation Loss: 0.4876449445740403, Validation Accuracy: 0.7721602101116218\n",
      "Epoch 7/20, Training Loss: 0.44049129672250725\n",
      "Epoch 7/20, Validation Loss: 0.4578855520611658, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 8/20, Training Loss: 0.4391483654539416\n",
      "Epoch 8/20, Validation Loss: 0.4568727149857276, Validation Accuracy: 0.799080761654629\n",
      "Epoch 9/20, Training Loss: 0.43207141401104415\n",
      "Epoch 9/20, Validation Loss: 0.46264357447468174, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 10/20, Training Loss: 0.4336388247610703\n",
      "Epoch 10/20, Validation Loss: 0.45410046636746193, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 11/20, Training Loss: 0.42911489918006684\n",
      "Epoch 11/20, Validation Loss: 0.45296104860867503, Validation Accuracy: 0.8069599474720945\n",
      "Epoch 12/20, Training Loss: 0.4276898687221403\n",
      "Epoch 12/20, Validation Loss: 0.45709632177159426, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 13/20, Training Loss: 0.42725910562190794\n",
      "Epoch 13/20, Validation Loss: 0.45577699037668595, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 14/20, Training Loss: 0.4215411414389848\n",
      "Epoch 14/20, Validation Loss: 0.4534306927189153, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 15/20, Training Loss: 0.4236660303738643\n",
      "Epoch 15/20, Validation Loss: 0.45020227832475884, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 16/20, Training Loss: 0.4197678978645348\n",
      "Epoch 16/20, Validation Loss: 0.45556912616051304, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 17/20, Training Loss: 0.42010756892951456\n",
      "Epoch 17/20, Validation Loss: 0.4522308945382765, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 18/20, Training Loss: 0.4196769698887203\n",
      "Epoch 18/20, Validation Loss: 0.45177504950793, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 19/20, Training Loss: 0.4170467287810456\n",
      "Epoch 19/20, Validation Loss: 0.4530108148202846, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 20/20, Training Loss: 0.41624619377644984\n",
      "Epoch 20/20, Validation Loss: 0.4535761465030815, Validation Accuracy: 0.7997373604727511\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/20, Training Loss: 0.5442500858912318\n",
      "Epoch 1/20, Validation Loss: 0.49306543959372956, Validation Accuracy: 0.7614980289093298\n",
      "Epoch 2/20, Training Loss: 0.48222040568827956\n",
      "Epoch 2/20, Validation Loss: 0.47547270127459973, Validation Accuracy: 0.7798948751642576\n",
      "Epoch 3/20, Training Loss: 0.46839339771061117\n",
      "Epoch 3/20, Validation Loss: 0.46089411511315104, Validation Accuracy: 0.78580814717477\n",
      "Epoch 4/20, Training Loss: 0.4581513280474295\n",
      "Epoch 4/20, Validation Loss: 0.45495306443013445, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 5/20, Training Loss: 0.45288985448442104\n",
      "Epoch 5/20, Validation Loss: 0.46365172872368576, Validation Accuracy: 0.783180026281209\n",
      "Epoch 6/20, Training Loss: 0.44758011842650064\n",
      "Epoch 6/20, Validation Loss: 0.4502887504263074, Validation Accuracy: 0.797634691195795\n",
      "Epoch 7/20, Training Loss: 0.44537204364192456\n",
      "Epoch 7/20, Validation Loss: 0.4468207646804954, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 8/20, Training Loss: 0.4408574023936677\n",
      "Epoch 8/20, Validation Loss: 0.448807359131843, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 9/20, Training Loss: 0.43825845984531825\n",
      "Epoch 9/20, Validation Loss: 0.44428392378759635, Validation Accuracy: 0.7923784494086727\n",
      "Epoch 10/20, Training Loss: 0.43672203105383034\n",
      "Epoch 10/20, Validation Loss: 0.4440265308226902, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 11/20, Training Loss: 0.43225372619829155\n",
      "Epoch 11/20, Validation Loss: 0.4441311594040294, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 12/20, Training Loss: 0.4308558992083304\n",
      "Epoch 12/20, Validation Loss: 0.44254139186668146, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 13/20, Training Loss: 0.42963859082011413\n",
      "Epoch 13/20, Validation Loss: 0.4424119665438592, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 14/20, Training Loss: 0.42651659845719186\n",
      "Epoch 14/20, Validation Loss: 0.4398486347410691, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 15/20, Training Loss: 0.4253266694615754\n",
      "Epoch 15/20, Validation Loss: 0.44262912520329367, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 16/20, Training Loss: 0.426492360320304\n",
      "Epoch 16/20, Validation Loss: 0.4409985639427969, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 17/20, Training Loss: 0.4240429336571787\n",
      "Epoch 17/20, Validation Loss: 0.44026692539297474, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 18/20, Training Loss: 0.42345895425580304\n",
      "Epoch 18/20, Validation Loss: 0.45396146494212575, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 19/20, Training Loss: 0.4193312356008945\n",
      "Epoch 19/20, Validation Loss: 0.4462291600270421, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 20/20, Training Loss: 0.41813645906883273\n",
      "Epoch 20/20, Validation Loss: 0.4400555543328455, Validation Accuracy: 0.8081471747700394\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/20, Training Loss: 0.5346876040805043\n",
      "Epoch 1/20, Validation Loss: 0.49350817704387984, Validation Accuracy: 0.7706964520367937\n",
      "Epoch 2/20, Training Loss: 0.4824235367923584\n",
      "Epoch 2/20, Validation Loss: 0.477602884563476, Validation Accuracy: 0.7798948751642576\n",
      "Epoch 3/20, Training Loss: 0.46543302555174965\n",
      "Epoch 3/20, Validation Loss: 0.4773140440436558, Validation Accuracy: 0.7792378449408672\n",
      "Epoch 4/20, Training Loss: 0.45607485110795715\n",
      "Epoch 4/20, Validation Loss: 0.4640814456796147, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 5/20, Training Loss: 0.4505739379820861\n",
      "Epoch 5/20, Validation Loss: 0.46767457785250627, Validation Accuracy: 0.7844940867279895\n",
      "Epoch 6/20, Training Loss: 0.4454788753855729\n",
      "Epoch 6/20, Validation Loss: 0.46872391976923217, Validation Accuracy: 0.7877792378449409\n",
      "Epoch 7/20, Training Loss: 0.43964647585794997\n",
      "Epoch 7/20, Validation Loss: 0.459041209394083, Validation Accuracy: 0.7943495400788436\n",
      "Epoch 8/20, Training Loss: 0.4379213452534726\n",
      "Epoch 8/20, Validation Loss: 0.4509174174273201, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 9/20, Training Loss: 0.4356970723004635\n",
      "Epoch 9/20, Validation Loss: 0.4635113580688756, Validation Accuracy: 0.790407358738502\n",
      "Epoch 10/20, Training Loss: 0.43171180044533075\n",
      "Epoch 10/20, Validation Loss: 0.4543539125335778, Validation Accuracy: 0.797634691195795\n",
      "Epoch 11/20, Training Loss: 0.4309005125613976\n",
      "Epoch 11/20, Validation Loss: 0.45011520182899156, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 12/20, Training Loss: 0.42757765163625944\n",
      "Epoch 12/20, Validation Loss: 0.45395198000195136, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 13/20, Training Loss: 0.42470926737652365\n",
      "Epoch 13/20, Validation Loss: 0.4579038192464419, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 14/20, Training Loss: 0.4255173894579173\n",
      "Epoch 14/20, Validation Loss: 0.45450885129692664, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 15/20, Training Loss: 0.4240788628305663\n",
      "Epoch 15/20, Validation Loss: 0.45093038206169117, Validation Accuracy: 0.804862023653088\n",
      "Epoch 16/20, Training Loss: 0.4227754552494197\n",
      "Epoch 16/20, Validation Loss: 0.45550266918555604, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 17/20, Training Loss: 0.4190118929708567\n",
      "Epoch 17/20, Validation Loss: 0.4644384979031473, Validation Accuracy: 0.7910643889618922\n",
      "Epoch 18/20, Training Loss: 0.41673136417438666\n",
      "Epoch 18/20, Validation Loss: 0.45952162166072436, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 19/20, Training Loss: 0.4164539023040943\n",
      "Epoch 19/20, Validation Loss: 0.4484855905565292, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 20/20, Training Loss: 0.414842538212932\n",
      "Epoch 20/20, Validation Loss: 0.46785342488535414, Validation Accuracy: 0.7923784494086727\n",
      "Average Validation Accuracy: 0.8011294189920128\n",
      "Number of Epochs: 20\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/30, Training Loss: 0.5366709244259074\n",
      "Epoch 1/30, Validation Loss: 0.5110672188054829, Validation Accuracy: 0.7531188443860801\n",
      "Epoch 2/30, Training Loss: 0.4776905726768526\n",
      "Epoch 2/30, Validation Loss: 0.48667659903071936, Validation Accuracy: 0.7760998030203545\n",
      "Epoch 3/30, Training Loss: 0.4623297258057776\n",
      "Epoch 3/30, Validation Loss: 0.4768310956929991, Validation Accuracy: 0.7793827971109653\n",
      "Epoch 4/30, Training Loss: 0.45471823049264315\n",
      "Epoch 4/30, Validation Loss: 0.47102441623104807, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 5/30, Training Loss: 0.44862283342896797\n",
      "Epoch 5/30, Validation Loss: 0.4894561228093677, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 6/30, Training Loss: 0.44388204540206694\n",
      "Epoch 6/30, Validation Loss: 0.46796927031578195, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 7/30, Training Loss: 0.44023889840978964\n",
      "Epoch 7/30, Validation Loss: 0.4618892510914054, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 8/30, Training Loss: 0.4369549445827489\n",
      "Epoch 8/30, Validation Loss: 0.4613251297183686, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 9/30, Training Loss: 0.43513305390405216\n",
      "Epoch 9/30, Validation Loss: 0.4606905078310617, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 10/30, Training Loss: 0.43071577861279325\n",
      "Epoch 10/30, Validation Loss: 0.45725938896234125, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 11/30, Training Loss: 0.42873476360609214\n",
      "Epoch 11/30, Validation Loss: 0.4622870299438531, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 12/30, Training Loss: 0.4280715489324935\n",
      "Epoch 12/30, Validation Loss: 0.46483303448526647, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 13/30, Training Loss: 0.4242885776568116\n",
      "Epoch 13/30, Validation Loss: 0.4576033347174135, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 14/30, Training Loss: 0.42411232950884525\n",
      "Epoch 14/30, Validation Loss: 0.4565589757567925, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 15/30, Training Loss: 0.4213287909649645\n",
      "Epoch 15/30, Validation Loss: 0.4645152062333691, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 16/30, Training Loss: 0.42086162115508335\n",
      "Epoch 16/30, Validation Loss: 0.46056930900244186, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 17/30, Training Loss: 0.41877618562087926\n",
      "Epoch 17/30, Validation Loss: 0.4563983182437445, Validation Accuracy: 0.804333552199606\n",
      "Epoch 18/30, Training Loss: 0.41659603154487185\n",
      "Epoch 18/30, Validation Loss: 0.4608744458924413, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 19/30, Training Loss: 0.41543269052788656\n",
      "Epoch 19/30, Validation Loss: 0.4551083528246555, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 20/30, Training Loss: 0.41558311087644006\n",
      "Epoch 20/30, Validation Loss: 0.45973298253969375, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 21/30, Training Loss: 0.41311564073553236\n",
      "Epoch 21/30, Validation Loss: 0.46061988243179797, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 22/30, Training Loss: 0.4105759337544441\n",
      "Epoch 22/30, Validation Loss: 0.46076407291346194, Validation Accuracy: 0.7866053841103086\n",
      "Epoch 23/30, Training Loss: 0.4101486412167862\n",
      "Epoch 23/30, Validation Loss: 0.4568201941852482, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 24/30, Training Loss: 0.4112016089514797\n",
      "Epoch 24/30, Validation Loss: 0.4561910386640988, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 25/30, Training Loss: 0.4089722494127869\n",
      "Epoch 25/30, Validation Loss: 0.45765967532524265, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 26/30, Training Loss: 0.40854259235222196\n",
      "Epoch 26/30, Validation Loss: 0.4617706037550697, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 27/30, Training Loss: 0.40857046506223405\n",
      "Epoch 27/30, Validation Loss: 0.45598089462877567, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 28/30, Training Loss: 0.4104804485019424\n",
      "Epoch 28/30, Validation Loss: 0.4592886135099134, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 29/30, Training Loss: 0.40515237296210344\n",
      "Epoch 29/30, Validation Loss: 0.46524165434206965, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 30/30, Training Loss: 0.4040815252370722\n",
      "Epoch 30/30, Validation Loss: 0.45613364153663527, Validation Accuracy: 0.804333552199606\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/30, Training Loss: 0.5380846188645664\n",
      "Epoch 1/30, Validation Loss: 0.5366419819403069, Validation Accuracy: 0.7432698621142482\n",
      "Epoch 2/30, Training Loss: 0.48338494404876636\n",
      "Epoch 2/30, Validation Loss: 0.47557445046009195, Validation Accuracy: 0.778069599474721\n",
      "Epoch 3/30, Training Loss: 0.4673421368335332\n",
      "Epoch 3/30, Validation Loss: 0.4582142543964361, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 4/30, Training Loss: 0.4599925500788088\n",
      "Epoch 4/30, Validation Loss: 0.4547614954919091, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 5/30, Training Loss: 0.4538335524636304\n",
      "Epoch 5/30, Validation Loss: 0.44872060468839725, Validation Accuracy: 0.799080761654629\n",
      "Epoch 6/30, Training Loss: 0.44908444366351824\n",
      "Epoch 6/30, Validation Loss: 0.4606810982158671, Validation Accuracy: 0.783322390019698\n",
      "Epoch 7/30, Training Loss: 0.4452373606306831\n",
      "Epoch 7/30, Validation Loss: 0.4494218707513747, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 8/30, Training Loss: 0.43951656598001326\n",
      "Epoch 8/30, Validation Loss: 0.4426764708929037, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 9/30, Training Loss: 0.43569295256938834\n",
      "Epoch 9/30, Validation Loss: 0.44208305748423354, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 10/30, Training Loss: 0.43566665549095224\n",
      "Epoch 10/30, Validation Loss: 0.44944606575120183, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 11/30, Training Loss: 0.432515456152987\n",
      "Epoch 11/30, Validation Loss: 0.44993616197823855, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 12/30, Training Loss: 0.4314178815135962\n",
      "Epoch 12/30, Validation Loss: 0.44309484408632, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 13/30, Training Loss: 0.426172225885191\n",
      "Epoch 13/30, Validation Loss: 0.45706591489895476, Validation Accuracy: 0.7826657912015759\n",
      "Epoch 14/30, Training Loss: 0.42655524380720194\n",
      "Epoch 14/30, Validation Loss: 0.44418100546557865, Validation Accuracy: 0.793827971109652\n",
      "Epoch 15/30, Training Loss: 0.4242061777944796\n",
      "Epoch 15/30, Validation Loss: 0.44517136503654625, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 16/30, Training Loss: 0.4242921323561919\n",
      "Epoch 16/30, Validation Loss: 0.4435031071344283, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 17/30, Training Loss: 0.4211535487333777\n",
      "Epoch 17/30, Validation Loss: 0.4497484065670306, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 18/30, Training Loss: 0.42087597400927795\n",
      "Epoch 18/30, Validation Loss: 0.4790562734651472, Validation Accuracy: 0.7616546290216678\n",
      "Epoch 19/30, Training Loss: 0.419896019813348\n",
      "Epoch 19/30, Validation Loss: 0.43923365771380396, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 20/30, Training Loss: 0.4186359807320936\n",
      "Epoch 20/30, Validation Loss: 0.44224431332571346, Validation Accuracy: 0.793827971109652\n",
      "Epoch 21/30, Training Loss: 0.4179356915294498\n",
      "Epoch 21/30, Validation Loss: 0.4397925945944811, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 22/30, Training Loss: 0.41618846087982964\n",
      "Epoch 22/30, Validation Loss: 0.4472416480954405, Validation Accuracy: 0.7866053841103086\n",
      "Epoch 23/30, Training Loss: 0.4149296965518492\n",
      "Epoch 23/30, Validation Loss: 0.45107413825447334, Validation Accuracy: 0.7866053841103086\n",
      "Epoch 24/30, Training Loss: 0.41399551805822554\n",
      "Epoch 24/30, Validation Loss: 0.4391800093401165, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 25/30, Training Loss: 0.4127876781846282\n",
      "Epoch 25/30, Validation Loss: 0.4412489599933487, Validation Accuracy: 0.793827971109652\n",
      "Epoch 26/30, Training Loss: 0.40941684075149654\n",
      "Epoch 26/30, Validation Loss: 0.45281459241910443, Validation Accuracy: 0.7839789888378201\n",
      "Epoch 27/30, Training Loss: 0.4110889565321834\n",
      "Epoch 27/30, Validation Loss: 0.44669282052139336, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 28/30, Training Loss: 0.41161769037953827\n",
      "Epoch 28/30, Validation Loss: 0.44027186573253874, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 29/30, Training Loss: 0.4101557723806286\n",
      "Epoch 29/30, Validation Loss: 0.44062766945720966, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 30/30, Training Loss: 0.4089186933683598\n",
      "Epoch 30/30, Validation Loss: 0.45562798351400496, Validation Accuracy: 0.7879185817465528\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/30, Training Loss: 0.5352405533976755\n",
      "Epoch 1/30, Validation Loss: 0.49709327955832655, Validation Accuracy: 0.7623112278397899\n",
      "Epoch 2/30, Training Loss: 0.48044810575137303\n",
      "Epoch 2/30, Validation Loss: 0.47741537907828835, Validation Accuracy: 0.788575180564675\n",
      "Epoch 3/30, Training Loss: 0.46474445300308737\n",
      "Epoch 3/30, Validation Loss: 0.4793843000113028, Validation Accuracy: 0.783322390019698\n",
      "Epoch 4/30, Training Loss: 0.45494041573305144\n",
      "Epoch 4/30, Validation Loss: 0.46169236567632066, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 5/30, Training Loss: 0.4493855366341555\n",
      "Epoch 5/30, Validation Loss: 0.4619989867921899, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 6/30, Training Loss: 0.4450997622717866\n",
      "Epoch 6/30, Validation Loss: 0.46863941126624953, Validation Accuracy: 0.7879185817465528\n",
      "Epoch 7/30, Training Loss: 0.4418994285792034\n",
      "Epoch 7/30, Validation Loss: 0.45691298705120986, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 8/30, Training Loss: 0.43769626293008723\n",
      "Epoch 8/30, Validation Loss: 0.45580732483046216, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 9/30, Training Loss: 0.4350411932221235\n",
      "Epoch 9/30, Validation Loss: 0.4561477590215768, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 10/30, Training Loss: 0.43109944063358574\n",
      "Epoch 10/30, Validation Loss: 0.4549432728068991, Validation Accuracy: 0.799080761654629\n",
      "Epoch 11/30, Training Loss: 0.4309525086967338\n",
      "Epoch 11/30, Validation Loss: 0.4512082087900002, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 12/30, Training Loss: 0.4265068955621694\n",
      "Epoch 12/30, Validation Loss: 0.46032675182086014, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 13/30, Training Loss: 0.4263319039907981\n",
      "Epoch 13/30, Validation Loss: 0.4527160424290527, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 14/30, Training Loss: 0.4255140413214841\n",
      "Epoch 14/30, Validation Loss: 0.47112651015217394, Validation Accuracy: 0.783322390019698\n",
      "Epoch 15/30, Training Loss: 0.4237540110143933\n",
      "Epoch 15/30, Validation Loss: 0.4584356067380356, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 16/30, Training Loss: 0.41949533183235194\n",
      "Epoch 16/30, Validation Loss: 0.4502413643046199, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 17/30, Training Loss: 0.4195478666339099\n",
      "Epoch 17/30, Validation Loss: 0.454918666308775, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 18/30, Training Loss: 0.4183457131715115\n",
      "Epoch 18/30, Validation Loss: 0.45595540445668536, Validation Accuracy: 0.799080761654629\n",
      "Epoch 19/30, Training Loss: 0.4179004663772627\n",
      "Epoch 19/30, Validation Loss: 0.4529565372626195, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 20/30, Training Loss: 0.4151095371018714\n",
      "Epoch 20/30, Validation Loss: 0.45624674443175034, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 21/30, Training Loss: 0.4155541338769626\n",
      "Epoch 21/30, Validation Loss: 0.46397828482364484, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 22/30, Training Loss: 0.41541767840975224\n",
      "Epoch 22/30, Validation Loss: 0.4553609937819511, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 23/30, Training Loss: 0.41360126069094255\n",
      "Epoch 23/30, Validation Loss: 0.4532199556602857, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 24/30, Training Loss: 0.41230257989696945\n",
      "Epoch 24/30, Validation Loss: 0.4496041384979068, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 25/30, Training Loss: 0.4110701650117091\n",
      "Epoch 25/30, Validation Loss: 0.45986722160072224, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 26/30, Training Loss: 0.41072376526090415\n",
      "Epoch 26/30, Validation Loss: 0.46340867001270747, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 27/30, Training Loss: 0.4098396068365555\n",
      "Epoch 27/30, Validation Loss: 0.4675280172572866, Validation Accuracy: 0.7846355876559422\n",
      "Epoch 28/30, Training Loss: 0.40904232041220967\n",
      "Epoch 28/30, Validation Loss: 0.45765429423117515, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 29/30, Training Loss: 0.4095560768888066\n",
      "Epoch 29/30, Validation Loss: 0.44979292731634607, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 30/30, Training Loss: 0.4070441012278082\n",
      "Epoch 30/30, Validation Loss: 0.4620190639419393, Validation Accuracy: 0.7905449770190414\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/30, Training Loss: 0.5481125970916172\n",
      "Epoch 1/30, Validation Loss: 0.48989754774807637, Validation Accuracy: 0.7700394218134035\n",
      "Epoch 2/30, Training Loss: 0.4857578767057792\n",
      "Epoch 2/30, Validation Loss: 0.4773934433987628, Validation Accuracy: 0.7818659658344284\n",
      "Epoch 3/30, Training Loss: 0.4695347378377526\n",
      "Epoch 3/30, Validation Loss: 0.4614108733403745, Validation Accuracy: 0.78580814717477\n",
      "Epoch 4/30, Training Loss: 0.46093693800915886\n",
      "Epoch 4/30, Validation Loss: 0.4669811163117124, Validation Accuracy: 0.7805519053876478\n",
      "Epoch 5/30, Training Loss: 0.45395829202973936\n",
      "Epoch 5/30, Validation Loss: 0.45718052316242486, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 6/30, Training Loss: 0.4486815345588475\n",
      "Epoch 6/30, Validation Loss: 0.45137520368498657, Validation Accuracy: 0.7897503285151117\n",
      "Epoch 7/30, Training Loss: 0.4433179701143128\n",
      "Epoch 7/30, Validation Loss: 0.4477400512127352, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 8/30, Training Loss: 0.44235603274713975\n",
      "Epoch 8/30, Validation Loss: 0.4538184151209462, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 9/30, Training Loss: 0.4399255337266941\n",
      "Epoch 9/30, Validation Loss: 0.45174327847689233, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 10/30, Training Loss: 0.4373137620314369\n",
      "Epoch 10/30, Validation Loss: 0.44763999299697227, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 11/30, Training Loss: 0.43500768808339996\n",
      "Epoch 11/30, Validation Loss: 0.44150690016634175, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 12/30, Training Loss: 0.4309956248253193\n",
      "Epoch 12/30, Validation Loss: 0.4448166515346597, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 13/30, Training Loss: 0.4310666878666152\n",
      "Epoch 13/30, Validation Loss: 0.4746504470862019, Validation Accuracy: 0.7884362680683311\n",
      "Epoch 14/30, Training Loss: 0.42796112684987664\n",
      "Epoch 14/30, Validation Loss: 0.45889074039396816, Validation Accuracy: 0.7759526938239159\n",
      "Epoch 15/30, Training Loss: 0.42628622593803045\n",
      "Epoch 15/30, Validation Loss: 0.4392345920010075, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 16/30, Training Loss: 0.42640666210940814\n",
      "Epoch 16/30, Validation Loss: 0.44331502807155954, Validation Accuracy: 0.7917214191852825\n",
      "Epoch 17/30, Training Loss: 0.4250916053988333\n",
      "Epoch 17/30, Validation Loss: 0.4396790133018768, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 18/30, Training Loss: 0.42143751151390435\n",
      "Epoch 18/30, Validation Loss: 0.44826633686014494, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 19/30, Training Loss: 0.4225088823880032\n",
      "Epoch 19/30, Validation Loss: 0.44001544499038403, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 20/30, Training Loss: 0.4211705120627492\n",
      "Epoch 20/30, Validation Loss: 0.43885291469190757, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 21/30, Training Loss: 0.4202497256357526\n",
      "Epoch 21/30, Validation Loss: 0.4394673644248104, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 22/30, Training Loss: 0.41912981675170224\n",
      "Epoch 22/30, Validation Loss: 0.43699594456409907, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 23/30, Training Loss: 0.4183629156723423\n",
      "Epoch 23/30, Validation Loss: 0.43854010994521736, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 24/30, Training Loss: 0.4145926098165706\n",
      "Epoch 24/30, Validation Loss: 0.43665096965369754, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 25/30, Training Loss: 0.4159391047555239\n",
      "Epoch 25/30, Validation Loss: 0.4515913820079484, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 26/30, Training Loss: 0.4145228584001227\n",
      "Epoch 26/30, Validation Loss: 0.4381715729832649, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 27/30, Training Loss: 0.41392492615370924\n",
      "Epoch 27/30, Validation Loss: 0.43636247486422197, Validation Accuracy: 0.812089356110381\n",
      "Epoch 28/30, Training Loss: 0.41291598441797916\n",
      "Epoch 28/30, Validation Loss: 0.4356250903174203, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 29/30, Training Loss: 0.41278556605258326\n",
      "Epoch 29/30, Validation Loss: 0.4465521285554189, Validation Accuracy: 0.7864651773981604\n",
      "Epoch 30/30, Training Loss: 0.4103172703736567\n",
      "Epoch 30/30, Validation Loss: 0.4408584228321832, Validation Accuracy: 0.8009198423127464\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/30, Training Loss: 0.5375574559872858\n",
      "Epoch 1/30, Validation Loss: 0.4909865617830092, Validation Accuracy: 0.7726675427069645\n",
      "Epoch 2/30, Training Loss: 0.4787473593523183\n",
      "Epoch 2/30, Validation Loss: 0.47747249753063264, Validation Accuracy: 0.7759526938239159\n",
      "Epoch 3/30, Training Loss: 0.4649555035854575\n",
      "Epoch 3/30, Validation Loss: 0.47598949476530417, Validation Accuracy: 0.7871222076215506\n",
      "Epoch 4/30, Training Loss: 0.45935255195212177\n",
      "Epoch 4/30, Validation Loss: 0.4643742307942575, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 5/30, Training Loss: 0.4504585437124639\n",
      "Epoch 5/30, Validation Loss: 0.48101925830410414, Validation Accuracy: 0.7706964520367937\n",
      "Epoch 6/30, Training Loss: 0.4452949523867115\n",
      "Epoch 6/30, Validation Loss: 0.4569947272929222, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 7/30, Training Loss: 0.440202668680763\n",
      "Epoch 7/30, Validation Loss: 0.45718649099946645, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 8/30, Training Loss: 0.4360032248313189\n",
      "Epoch 8/30, Validation Loss: 0.45562447303252696, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 9/30, Training Loss: 0.43354827205692065\n",
      "Epoch 9/30, Validation Loss: 0.4760640820205524, Validation Accuracy: 0.7871222076215506\n",
      "Epoch 10/30, Training Loss: 0.43173630176762273\n",
      "Epoch 10/30, Validation Loss: 0.4516124008369695, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 11/30, Training Loss: 0.43015088361939735\n",
      "Epoch 11/30, Validation Loss: 0.4546927195334934, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 12/30, Training Loss: 0.4287694028561588\n",
      "Epoch 12/30, Validation Loss: 0.45064383620367, Validation Accuracy: 0.804862023653088\n",
      "Epoch 13/30, Training Loss: 0.42521492816175377\n",
      "Epoch 13/30, Validation Loss: 0.45188262231686976, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 14/30, Training Loss: 0.4228019207872431\n",
      "Epoch 14/30, Validation Loss: 0.4504011980214044, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 15/30, Training Loss: 0.4212162919596737\n",
      "Epoch 15/30, Validation Loss: 0.456894893140693, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 16/30, Training Loss: 0.4207838249742359\n",
      "Epoch 16/30, Validation Loss: 0.45147584417727604, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 17/30, Training Loss: 0.41949770690535937\n",
      "Epoch 17/30, Validation Loss: 0.4499864190504813, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 18/30, Training Loss: 0.4171291183377188\n",
      "Epoch 18/30, Validation Loss: 0.4577095945663165, Validation Accuracy: 0.7950065703022339\n",
      "Epoch 19/30, Training Loss: 0.4172320425842847\n",
      "Epoch 19/30, Validation Loss: 0.45043020874885986, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 20/30, Training Loss: 0.4163011310626985\n",
      "Epoch 20/30, Validation Loss: 0.4580818681504714, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 21/30, Training Loss: 0.4156153465467175\n",
      "Epoch 21/30, Validation Loss: 0.4534132229017962, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 22/30, Training Loss: 0.4146919735558233\n",
      "Epoch 22/30, Validation Loss: 0.4619658012820788, Validation Accuracy: 0.7910643889618922\n",
      "Epoch 23/30, Training Loss: 0.41385272113982774\n",
      "Epoch 23/30, Validation Loss: 0.45151459960101165, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 24/30, Training Loss: 0.41140936453902505\n",
      "Epoch 24/30, Validation Loss: 0.4531842044978866, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 25/30, Training Loss: 0.4098527382795266\n",
      "Epoch 25/30, Validation Loss: 0.4529475964098701, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 26/30, Training Loss: 0.4101218578315235\n",
      "Epoch 26/30, Validation Loss: 0.45148962033980805, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 27/30, Training Loss: 0.4117648506297527\n",
      "Epoch 27/30, Validation Loss: 0.4519543516698308, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 28/30, Training Loss: 0.40904209405926895\n",
      "Epoch 28/30, Validation Loss: 0.4507625417403526, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 29/30, Training Loss: 0.40735509254409885\n",
      "Epoch 29/30, Validation Loss: 0.4573363629389184, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 30/30, Training Loss: 0.4060586840500982\n",
      "Epoch 30/30, Validation Loss: 0.4533146493800023, Validation Accuracy: 0.7989487516425755\n",
      "Average Validation Accuracy: 0.7965331409841044\n",
      "Number of Epochs: 30\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.5346828160753713\n",
      "Epoch 1/40, Validation Loss: 0.4975986928527892, Validation Accuracy: 0.7820091923834537\n",
      "Epoch 2/40, Training Loss: 0.4804280880750634\n",
      "Epoch 2/40, Validation Loss: 0.4805145251189227, Validation Accuracy: 0.783322390019698\n",
      "Epoch 3/40, Training Loss: 0.46495760284031784\n",
      "Epoch 3/40, Validation Loss: 0.47776062770975825, Validation Accuracy: 0.7793827971109653\n",
      "Epoch 4/40, Training Loss: 0.4555767711907078\n",
      "Epoch 4/40, Validation Loss: 0.4757722585379141, Validation Accuracy: 0.7800393959290873\n",
      "Epoch 5/40, Training Loss: 0.44703641238566144\n",
      "Epoch 5/40, Validation Loss: 0.47043296027714043, Validation Accuracy: 0.793827971109652\n",
      "Epoch 6/40, Training Loss: 0.44291505237107515\n",
      "Epoch 6/40, Validation Loss: 0.4839433882170947, Validation Accuracy: 0.7642810242941562\n",
      "Epoch 7/40, Training Loss: 0.4405639752491409\n",
      "Epoch 7/40, Validation Loss: 0.46420261618822656, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 8/40, Training Loss: 0.4365666683401492\n",
      "Epoch 8/40, Validation Loss: 0.46786676799751703, Validation Accuracy: 0.7839789888378201\n",
      "Epoch 9/40, Training Loss: 0.4318588870599514\n",
      "Epoch 9/40, Validation Loss: 0.4646062622363655, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 10/40, Training Loss: 0.43289935001199015\n",
      "Epoch 10/40, Validation Loss: 0.4601104440879447, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 11/40, Training Loss: 0.427663079753831\n",
      "Epoch 11/40, Validation Loss: 0.4658771209925881, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 12/40, Training Loss: 0.4257560921466257\n",
      "Epoch 12/40, Validation Loss: 0.45760664437453785, Validation Accuracy: 0.799080761654629\n",
      "Epoch 13/40, Training Loss: 0.42611498504955314\n",
      "Epoch 13/40, Validation Loss: 0.47976771730403, Validation Accuracy: 0.767564018384767\n",
      "Epoch 14/40, Training Loss: 0.4262023235126117\n",
      "Epoch 14/40, Validation Loss: 0.4569140179619115, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 15/40, Training Loss: 0.42507837686365046\n",
      "Epoch 15/40, Validation Loss: 0.4571217257549001, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 16/40, Training Loss: 0.42027168140167326\n",
      "Epoch 16/40, Validation Loss: 0.46704509093655344, Validation Accuracy: 0.778069599474721\n",
      "Epoch 17/40, Training Loss: 0.4175865617617378\n",
      "Epoch 17/40, Validation Loss: 0.4609029391751239, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 18/40, Training Loss: 0.4180524902726252\n",
      "Epoch 18/40, Validation Loss: 0.4707831208111416, Validation Accuracy: 0.778069599474721\n",
      "Epoch 19/40, Training Loss: 0.416302386079756\n",
      "Epoch 19/40, Validation Loss: 0.45956050325672665, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 20/40, Training Loss: 0.4155660810393924\n",
      "Epoch 20/40, Validation Loss: 0.46273849580768517, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 21/40, Training Loss: 0.41334452243458253\n",
      "Epoch 21/40, Validation Loss: 0.45518838661035316, Validation Accuracy: 0.8102429415627052\n",
      "Epoch 22/40, Training Loss: 0.4138201649479196\n",
      "Epoch 22/40, Validation Loss: 0.46112654077288995, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 23/40, Training Loss: 0.41201145609161205\n",
      "Epoch 23/40, Validation Loss: 0.4609287045310929, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 24/40, Training Loss: 0.4101296298479627\n",
      "Epoch 24/40, Validation Loss: 0.45742613081064526, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 25/40, Training Loss: 0.41163822663385724\n",
      "Epoch 25/40, Validation Loss: 0.4690681379776038, Validation Accuracy: 0.7754432042022325\n",
      "Epoch 26/40, Training Loss: 0.4077606488537444\n",
      "Epoch 26/40, Validation Loss: 0.4597172335726428, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 27/40, Training Loss: 0.4097165877483492\n",
      "Epoch 27/40, Validation Loss: 0.45540876189217516, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 28/40, Training Loss: 0.4073263001909328\n",
      "Epoch 28/40, Validation Loss: 0.4580166500978445, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 29/40, Training Loss: 0.40920289266570975\n",
      "Epoch 29/40, Validation Loss: 0.4568865697499345, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 30/40, Training Loss: 0.4054654105334222\n",
      "Epoch 30/40, Validation Loss: 0.4555099908242987, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 31/40, Training Loss: 0.40640613513942464\n",
      "Epoch 31/40, Validation Loss: 0.4597750155557513, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 32/40, Training Loss: 0.4047508085650096\n",
      "Epoch 32/40, Validation Loss: 0.4580103064940862, Validation Accuracy: 0.804333552199606\n",
      "Epoch 33/40, Training Loss: 0.40354109178065\n",
      "Epoch 33/40, Validation Loss: 0.4559022449737132, Validation Accuracy: 0.8082731451083388\n",
      "Epoch 34/40, Training Loss: 0.4016260971997197\n",
      "Epoch 34/40, Validation Loss: 0.4573103174060115, Validation Accuracy: 0.804333552199606\n",
      "Epoch 35/40, Training Loss: 0.4023210167435054\n",
      "Epoch 35/40, Validation Loss: 0.4570466751983653, Validation Accuracy: 0.8076165462902167\n",
      "Epoch 36/40, Training Loss: 0.402618170918755\n",
      "Epoch 36/40, Validation Loss: 0.4595976105223151, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 37/40, Training Loss: 0.40191272513212495\n",
      "Epoch 37/40, Validation Loss: 0.4602632558470621, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 38/40, Training Loss: 0.3995942591085756\n",
      "Epoch 38/40, Validation Loss: 0.45847496604888227, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 39/40, Training Loss: 0.40046756454496557\n",
      "Epoch 39/40, Validation Loss: 0.4688954716109481, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 40/40, Training Loss: 0.40306245247170996\n",
      "Epoch 40/40, Validation Loss: 0.45877798794919905, Validation Accuracy: 0.8069599474720945\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.536456917253692\n",
      "Epoch 1/40, Validation Loss: 0.4988524213199216, Validation Accuracy: 0.7537754432042022\n",
      "Epoch 2/40, Training Loss: 0.48109636289554003\n",
      "Epoch 2/40, Validation Loss: 0.4709084390891784, Validation Accuracy: 0.7846355876559422\n",
      "Epoch 3/40, Training Loss: 0.46817151207740854\n",
      "Epoch 3/40, Validation Loss: 0.46025790379465564, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 4/40, Training Loss: 0.45930526640236846\n",
      "Epoch 4/40, Validation Loss: 0.4576933900216175, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 5/40, Training Loss: 0.45274577805102656\n",
      "Epoch 5/40, Validation Loss: 0.4484420323559127, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 6/40, Training Loss: 0.4474849505472214\n",
      "Epoch 6/40, Validation Loss: 0.44448842849406894, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 7/40, Training Loss: 0.4431699546362002\n",
      "Epoch 7/40, Validation Loss: 0.4756314837963793, Validation Accuracy: 0.7846355876559422\n",
      "Epoch 8/40, Training Loss: 0.4381071328334608\n",
      "Epoch 8/40, Validation Loss: 0.45006708512131455, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 9/40, Training Loss: 0.4364511362738966\n",
      "Epoch 9/40, Validation Loss: 0.4455222134424754, Validation Accuracy: 0.799080761654629\n",
      "Epoch 10/40, Training Loss: 0.4344713323874267\n",
      "Epoch 10/40, Validation Loss: 0.44174184281554524, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 11/40, Training Loss: 0.43230113201332215\n",
      "Epoch 11/40, Validation Loss: 0.439887464436561, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 12/40, Training Loss: 0.43062937130608897\n",
      "Epoch 12/40, Validation Loss: 0.44673993530151734, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 13/40, Training Loss: 0.42660236227621867\n",
      "Epoch 13/40, Validation Loss: 0.43997317254153223, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 14/40, Training Loss: 0.42612563764916006\n",
      "Epoch 14/40, Validation Loss: 0.4418290738425954, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 15/40, Training Loss: 0.42556797943794195\n",
      "Epoch 15/40, Validation Loss: 0.4502999263167069, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 16/40, Training Loss: 0.42254479152206675\n",
      "Epoch 16/40, Validation Loss: 0.45248761968150814, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 17/40, Training Loss: 0.4217465775493249\n",
      "Epoch 17/40, Validation Loss: 0.4387899189407289, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 18/40, Training Loss: 0.42001788872550794\n",
      "Epoch 18/40, Validation Loss: 0.4466735106059082, Validation Accuracy: 0.804333552199606\n",
      "Epoch 19/40, Training Loss: 0.4213924735804086\n",
      "Epoch 19/40, Validation Loss: 0.4401276412551628, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 20/40, Training Loss: 0.41737090039440966\n",
      "Epoch 20/40, Validation Loss: 0.4414436059823523, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 21/40, Training Loss: 0.41761961748476417\n",
      "Epoch 21/40, Validation Loss: 0.444217293947467, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 22/40, Training Loss: 0.41573899990715224\n",
      "Epoch 22/40, Validation Loss: 0.44026309466330793, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 23/40, Training Loss: 0.4154371315725832\n",
      "Epoch 23/40, Validation Loss: 0.44522738762941033, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 24/40, Training Loss: 0.4120687826431486\n",
      "Epoch 24/40, Validation Loss: 0.4505581628160639, Validation Accuracy: 0.799080761654629\n",
      "Epoch 25/40, Training Loss: 0.4126950072569484\n",
      "Epoch 25/40, Validation Loss: 0.43955988388176986, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 26/40, Training Loss: 0.41340506869292476\n",
      "Epoch 26/40, Validation Loss: 0.44224968144952936, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 27/40, Training Loss: 0.4127407403873021\n",
      "Epoch 27/40, Validation Loss: 0.4477565882639735, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 28/40, Training Loss: 0.41124313772506915\n",
      "Epoch 28/40, Validation Loss: 0.4400270638587587, Validation Accuracy: 0.799080761654629\n",
      "Epoch 29/40, Training Loss: 0.40989989111703523\n",
      "Epoch 29/40, Validation Loss: 0.4472219083477689, Validation Accuracy: 0.799080761654629\n",
      "Epoch 30/40, Training Loss: 0.409167982965434\n",
      "Epoch 30/40, Validation Loss: 0.44330735411007366, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 31/40, Training Loss: 0.40842817733528736\n",
      "Epoch 31/40, Validation Loss: 0.4792068536485989, Validation Accuracy: 0.7603414313854235\n",
      "Epoch 32/40, Training Loss: 0.406971436922788\n",
      "Epoch 32/40, Validation Loss: 0.4474322181682624, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 33/40, Training Loss: 0.4065526833811535\n",
      "Epoch 33/40, Validation Loss: 0.4465828557640158, Validation Accuracy: 0.799080761654629\n",
      "Epoch 34/40, Training Loss: 0.4056969243505104\n",
      "Epoch 34/40, Validation Loss: 0.4407296514050811, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 35/40, Training Loss: 0.4055046595026815\n",
      "Epoch 35/40, Validation Loss: 0.44359158993703535, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 36/40, Training Loss: 0.4061833335296923\n",
      "Epoch 36/40, Validation Loss: 0.4442687632018671, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 37/40, Training Loss: 0.4042721761297679\n",
      "Epoch 37/40, Validation Loss: 0.44777914102515937, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 38/40, Training Loss: 0.40177671236335605\n",
      "Epoch 38/40, Validation Loss: 0.4518347940948933, Validation Accuracy: 0.793827971109652\n",
      "Epoch 39/40, Training Loss: 0.4051563742709911\n",
      "Epoch 39/40, Validation Loss: 0.45733345683215487, Validation Accuracy: 0.7846355876559422\n",
      "Epoch 40/40, Training Loss: 0.402721193616628\n",
      "Epoch 40/40, Validation Loss: 0.44162298315716664, Validation Accuracy: 0.7977675640183848\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.5358334948697429\n",
      "Epoch 1/40, Validation Loss: 0.4966761052452457, Validation Accuracy: 0.7747866053841103\n",
      "Epoch 2/40, Training Loss: 0.4812842177672023\n",
      "Epoch 2/40, Validation Loss: 0.4768742962657469, Validation Accuracy: 0.7839789888378201\n",
      "Epoch 3/40, Training Loss: 0.4644454403870844\n",
      "Epoch 3/40, Validation Loss: 0.4704635742447139, Validation Accuracy: 0.7852921864740644\n",
      "Epoch 4/40, Training Loss: 0.45495181772222354\n",
      "Epoch 4/40, Validation Loss: 0.4658850638576203, Validation Accuracy: 0.7879185817465528\n",
      "Epoch 5/40, Training Loss: 0.450204058220302\n",
      "Epoch 5/40, Validation Loss: 0.4623782541505329, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 6/40, Training Loss: 0.4456601215922457\n",
      "Epoch 6/40, Validation Loss: 0.45830566779325144, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 7/40, Training Loss: 0.44023229168077777\n",
      "Epoch 7/40, Validation Loss: 0.46534873669996313, Validation Accuracy: 0.7866053841103086\n",
      "Epoch 8/40, Training Loss: 0.4381708227821535\n",
      "Epoch 8/40, Validation Loss: 0.453891112230211, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 9/40, Training Loss: 0.4338791342232171\n",
      "Epoch 9/40, Validation Loss: 0.4561716718745481, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 10/40, Training Loss: 0.4324928659290623\n",
      "Epoch 10/40, Validation Loss: 0.47216824202247315, Validation Accuracy: 0.7806959947472094\n",
      "Epoch 11/40, Training Loss: 0.42936263747239517\n",
      "Epoch 11/40, Validation Loss: 0.45591637012378083, Validation Accuracy: 0.799080761654629\n",
      "Epoch 12/40, Training Loss: 0.42740606973216605\n",
      "Epoch 12/40, Validation Loss: 0.46756715343104605, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 13/40, Training Loss: 0.42650529351134314\n",
      "Epoch 13/40, Validation Loss: 0.4545578512299747, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 14/40, Training Loss: 0.4236099932763207\n",
      "Epoch 14/40, Validation Loss: 0.4513414914656372, Validation Accuracy: 0.804333552199606\n",
      "Epoch 15/40, Training Loss: 0.4219782603391278\n",
      "Epoch 15/40, Validation Loss: 0.4530033987815155, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 16/40, Training Loss: 0.4194285228574683\n",
      "Epoch 16/40, Validation Loss: 0.450822653512212, Validation Accuracy: 0.804333552199606\n",
      "Epoch 17/40, Training Loss: 0.41899644410399\n",
      "Epoch 17/40, Validation Loss: 0.4493765209786867, Validation Accuracy: 0.799080761654629\n",
      "Epoch 18/40, Training Loss: 0.4204982107998974\n",
      "Epoch 18/40, Validation Loss: 0.4525143077002146, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 19/40, Training Loss: 0.4184437253637107\n",
      "Epoch 19/40, Validation Loss: 0.4670991782703637, Validation Accuracy: 0.7839789888378201\n",
      "Epoch 20/40, Training Loss: 0.4167560229464153\n",
      "Epoch 20/40, Validation Loss: 0.4508512024792077, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 21/40, Training Loss: 0.4149249303215758\n",
      "Epoch 21/40, Validation Loss: 0.4488551776992713, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 22/40, Training Loss: 0.4156359478762848\n",
      "Epoch 22/40, Validation Loss: 0.47775293616529224, Validation Accuracy: 0.7741300065659882\n",
      "Epoch 23/40, Training Loss: 0.41328452762186996\n",
      "Epoch 23/40, Validation Loss: 0.4506922051583597, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 24/40, Training Loss: 0.41085537797783617\n",
      "Epoch 24/40, Validation Loss: 0.4521621330324268, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 25/40, Training Loss: 0.4107428556430371\n",
      "Epoch 25/40, Validation Loss: 0.4616684314858227, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 26/40, Training Loss: 0.4106524789955203\n",
      "Epoch 26/40, Validation Loss: 0.4552192943492485, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 27/40, Training Loss: 0.40833811578279716\n",
      "Epoch 27/40, Validation Loss: 0.45834504356559036, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 28/40, Training Loss: 0.40740553666091966\n",
      "Epoch 28/40, Validation Loss: 0.45297606437618193, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 29/40, Training Loss: 0.4081178176023672\n",
      "Epoch 29/40, Validation Loss: 0.46238281784569407, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 30/40, Training Loss: 0.4067939360604042\n",
      "Epoch 30/40, Validation Loss: 0.46301429414468287, Validation Accuracy: 0.7879185817465528\n",
      "Epoch 31/40, Training Loss: 0.4076303370551174\n",
      "Epoch 31/40, Validation Loss: 0.458400551034674, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 32/40, Training Loss: 0.40603659017466187\n",
      "Epoch 32/40, Validation Loss: 0.4524965563213638, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 33/40, Training Loss: 0.4043992853716133\n",
      "Epoch 33/40, Validation Loss: 0.4534011354270094, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 34/40, Training Loss: 0.40506349783635204\n",
      "Epoch 34/40, Validation Loss: 0.4501617096793589, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 35/40, Training Loss: 0.4056325479950805\n",
      "Epoch 35/40, Validation Loss: 0.45060928511135867, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 36/40, Training Loss: 0.40278947555271816\n",
      "Epoch 36/40, Validation Loss: 0.45387775727903656, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 37/40, Training Loss: 0.403107406439509\n",
      "Epoch 37/40, Validation Loss: 0.4549257973140759, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 38/40, Training Loss: 0.40138476178186927\n",
      "Epoch 38/40, Validation Loss: 0.45881115139037837, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 39/40, Training Loss: 0.40239890193532457\n",
      "Epoch 39/40, Validation Loss: 0.45518836765233134, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 40/40, Training Loss: 0.4027402711509094\n",
      "Epoch 40/40, Validation Loss: 0.4493051058178797, Validation Accuracy: 0.804333552199606\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.5405820645685271\n",
      "Epoch 1/40, Validation Loss: 0.4928404556597091, Validation Accuracy: 0.7746386333771353\n",
      "Epoch 2/40, Training Loss: 0.4848761701677728\n",
      "Epoch 2/40, Validation Loss: 0.47612908139278753, Validation Accuracy: 0.7746386333771353\n",
      "Epoch 3/40, Training Loss: 0.4687792259681569\n",
      "Epoch 3/40, Validation Loss: 0.45794835175675247, Validation Accuracy: 0.790407358738502\n",
      "Epoch 4/40, Training Loss: 0.45739536516348833\n",
      "Epoch 4/40, Validation Loss: 0.4980655197853817, Validation Accuracy: 0.7693823915900131\n",
      "Epoch 5/40, Training Loss: 0.45448938519583915\n",
      "Epoch 5/40, Validation Loss: 0.4496763187865312, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 6/40, Training Loss: 0.4474429903439493\n",
      "Epoch 6/40, Validation Loss: 0.4626777326561394, Validation Accuracy: 0.7884362680683311\n",
      "Epoch 7/40, Training Loss: 0.4430217777043972\n",
      "Epoch 7/40, Validation Loss: 0.4508912120189966, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 8/40, Training Loss: 0.4403837391730212\n",
      "Epoch 8/40, Validation Loss: 0.44412838250242603, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 9/40, Training Loss: 0.438530066009034\n",
      "Epoch 9/40, Validation Loss: 0.44652400721664204, Validation Accuracy: 0.790407358738502\n",
      "Epoch 10/40, Training Loss: 0.4346993355535147\n",
      "Epoch 10/40, Validation Loss: 0.4531968785206061, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 11/40, Training Loss: 0.43253884578901014\n",
      "Epoch 11/40, Validation Loss: 0.44331358700834644, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 12/40, Training Loss: 0.4314382113320777\n",
      "Epoch 12/40, Validation Loss: 0.4402438951802503, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 13/40, Training Loss: 0.42949683271993805\n",
      "Epoch 13/40, Validation Loss: 0.443214979256791, Validation Accuracy: 0.7890932982917214\n",
      "Epoch 14/40, Training Loss: 0.42895066391999326\n",
      "Epoch 14/40, Validation Loss: 0.4390490386654569, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 15/40, Training Loss: 0.42579780221767627\n",
      "Epoch 15/40, Validation Loss: 0.44944597339910985, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 16/40, Training Loss: 0.4269012712783075\n",
      "Epoch 16/40, Validation Loss: 0.4644417548015792, Validation Accuracy: 0.7759526938239159\n",
      "Epoch 17/40, Training Loss: 0.42317863886691925\n",
      "Epoch 17/40, Validation Loss: 0.44025654513486395, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 18/40, Training Loss: 0.42183348277383276\n",
      "Epoch 18/40, Validation Loss: 0.43742997870239286, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 19/40, Training Loss: 0.4223353352270571\n",
      "Epoch 19/40, Validation Loss: 0.43773495048986677, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 20/40, Training Loss: 0.4219603518860077\n",
      "Epoch 20/40, Validation Loss: 0.4476440497405866, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 21/40, Training Loss: 0.4190554324918845\n",
      "Epoch 21/40, Validation Loss: 0.46594647532670286, Validation Accuracy: 0.797634691195795\n",
      "Epoch 22/40, Training Loss: 0.41777099159074427\n",
      "Epoch 22/40, Validation Loss: 0.44037049066723954, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 23/40, Training Loss: 0.4160497039752057\n",
      "Epoch 23/40, Validation Loss: 0.43569393416973934, Validation Accuracy: 0.80946123521682\n",
      "Epoch 24/40, Training Loss: 0.41782872030741275\n",
      "Epoch 24/40, Validation Loss: 0.4357632026076317, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 25/40, Training Loss: 0.4131824104677583\n",
      "Epoch 25/40, Validation Loss: 0.4370626176058934, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 26/40, Training Loss: 0.4138324877780097\n",
      "Epoch 26/40, Validation Loss: 0.4355251992131091, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 27/40, Training Loss: 0.41445977041336496\n",
      "Epoch 27/40, Validation Loss: 0.46890450167562325, Validation Accuracy: 0.7943495400788436\n",
      "Epoch 28/40, Training Loss: 0.4118208223636069\n",
      "Epoch 28/40, Validation Loss: 0.4379214389903071, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 29/40, Training Loss: 0.41095652866355703\n",
      "Epoch 29/40, Validation Loss: 0.43802323564887047, Validation Accuracy: 0.812089356110381\n",
      "Epoch 30/40, Training Loss: 0.4113669670981372\n",
      "Epoch 30/40, Validation Loss: 0.452987484126815, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 31/40, Training Loss: 0.4101812271816837\n",
      "Epoch 31/40, Validation Loss: 0.4388886656592654, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 32/40, Training Loss: 0.4097884405267442\n",
      "Epoch 32/40, Validation Loss: 0.45653391052135, Validation Accuracy: 0.7818659658344284\n",
      "Epoch 33/40, Training Loss: 0.4074960398314193\n",
      "Epoch 33/40, Validation Loss: 0.4677704948327304, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 34/40, Training Loss: 0.40871961784409727\n",
      "Epoch 34/40, Validation Loss: 0.437092733398782, Validation Accuracy: 0.8153745072273325\n",
      "Epoch 35/40, Training Loss: 0.40952565409536434\n",
      "Epoch 35/40, Validation Loss: 0.4448242879896888, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 36/40, Training Loss: 0.40729418961609914\n",
      "Epoch 36/40, Validation Loss: 0.4612647871150396, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 37/40, Training Loss: 0.4068551823066601\n",
      "Epoch 37/40, Validation Loss: 0.4372137308471802, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 38/40, Training Loss: 0.40571290523478676\n",
      "Epoch 38/40, Validation Loss: 0.43641714944811394, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 39/40, Training Loss: 0.4073959028450992\n",
      "Epoch 39/40, Validation Loss: 0.43681892848217674, Validation Accuracy: 0.80946123521682\n",
      "Epoch 40/40, Training Loss: 0.40489266544893343\n",
      "Epoch 40/40, Validation Loss: 0.4476747705518263, Validation Accuracy: 0.8035479632063075\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.5366661598480592\n",
      "Epoch 1/40, Validation Loss: 0.49673662525821105, Validation Accuracy: 0.7726675427069645\n",
      "Epoch 2/40, Training Loss: 0.4822925440673753\n",
      "Epoch 2/40, Validation Loss: 0.4727856427899206, Validation Accuracy: 0.7950065703022339\n",
      "Epoch 3/40, Training Loss: 0.46736425247405144\n",
      "Epoch 3/40, Validation Loss: 0.4650282202122723, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 4/40, Training Loss: 0.45633347550519493\n",
      "Epoch 4/40, Validation Loss: 0.4651651795543925, Validation Accuracy: 0.78580814717477\n",
      "Epoch 5/40, Training Loss: 0.4512163973914513\n",
      "Epoch 5/40, Validation Loss: 0.45765137719234245, Validation Accuracy: 0.7956636005256241\n",
      "Epoch 6/40, Training Loss: 0.44581683124770016\n",
      "Epoch 6/40, Validation Loss: 0.45300613647980215, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 7/40, Training Loss: 0.4398701610214754\n",
      "Epoch 7/40, Validation Loss: 0.45461642168735333, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 8/40, Training Loss: 0.4365353549872171\n",
      "Epoch 8/40, Validation Loss: 0.4624323154073111, Validation Accuracy: 0.7923784494086727\n",
      "Epoch 9/40, Training Loss: 0.4349763914160528\n",
      "Epoch 9/40, Validation Loss: 0.45240546638116785, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 10/40, Training Loss: 0.43408801909193906\n",
      "Epoch 10/40, Validation Loss: 0.4499747852614413, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 11/40, Training Loss: 0.42857398072213637\n",
      "Epoch 11/40, Validation Loss: 0.45070785065596014, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 12/40, Training Loss: 0.4269783701698768\n",
      "Epoch 12/40, Validation Loss: 0.448156017907627, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 13/40, Training Loss: 0.42703260870508636\n",
      "Epoch 13/40, Validation Loss: 0.45326840323615447, Validation Accuracy: 0.797634691195795\n",
      "Epoch 14/40, Training Loss: 0.42529643251709737\n",
      "Epoch 14/40, Validation Loss: 0.450755512488138, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 15/40, Training Loss: 0.422511620931034\n",
      "Epoch 15/40, Validation Loss: 0.4545872975238331, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 16/40, Training Loss: 0.4213030757064738\n",
      "Epoch 16/40, Validation Loss: 0.4523051280859877, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 17/40, Training Loss: 0.42117303969177206\n",
      "Epoch 17/40, Validation Loss: 0.45318544168434843, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 18/40, Training Loss: 0.4192889063983295\n",
      "Epoch 18/40, Validation Loss: 0.44889433919915356, Validation Accuracy: 0.804862023653088\n",
      "Epoch 19/40, Training Loss: 0.4167691063321638\n",
      "Epoch 19/40, Validation Loss: 0.4532041811038062, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 20/40, Training Loss: 0.4175031904688501\n",
      "Epoch 20/40, Validation Loss: 0.4493502232962878, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 21/40, Training Loss: 0.4153233586940083\n",
      "Epoch 21/40, Validation Loss: 0.45271906865204814, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 22/40, Training Loss: 0.41356002776015777\n",
      "Epoch 22/40, Validation Loss: 0.45028767625542837, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 23/40, Training Loss: 0.4107828142067657\n",
      "Epoch 23/40, Validation Loss: 0.4501930321347339, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 24/40, Training Loss: 0.41361893637208486\n",
      "Epoch 24/40, Validation Loss: 0.44744323985894935, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 25/40, Training Loss: 0.4103751379918317\n",
      "Epoch 25/40, Validation Loss: 0.4571540984105689, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 26/40, Training Loss: 0.40974825724294495\n",
      "Epoch 26/40, Validation Loss: 0.45307472718791814, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 27/40, Training Loss: 0.409677776559366\n",
      "Epoch 27/40, Validation Loss: 0.45285431759831796, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 28/40, Training Loss: 0.4074516038647474\n",
      "Epoch 28/40, Validation Loss: 0.457751195390187, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 29/40, Training Loss: 0.4089222945312033\n",
      "Epoch 29/40, Validation Loss: 0.4506526389671246, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 30/40, Training Loss: 0.40629878258845936\n",
      "Epoch 30/40, Validation Loss: 0.44994846910862396, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 31/40, Training Loss: 0.4040767662276042\n",
      "Epoch 31/40, Validation Loss: 0.4514914954285971, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 32/40, Training Loss: 0.4053174719370882\n",
      "Epoch 32/40, Validation Loss: 0.45309359299418817, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 33/40, Training Loss: 0.40585790904057933\n",
      "Epoch 33/40, Validation Loss: 0.45233442072624935, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 34/40, Training Loss: 0.4043556018842487\n",
      "Epoch 34/40, Validation Loss: 0.4511224744324597, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 35/40, Training Loss: 0.4036055986727942\n",
      "Epoch 35/40, Validation Loss: 0.4703612992276696, Validation Accuracy: 0.7910643889618922\n",
      "Epoch 36/40, Training Loss: 0.40265313953435017\n",
      "Epoch 36/40, Validation Loss: 0.45533044911257886, Validation Accuracy: 0.7956636005256241\n",
      "Epoch 37/40, Training Loss: 0.40251523883050194\n",
      "Epoch 37/40, Validation Loss: 0.45370092771518294, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 38/40, Training Loss: 0.40143662996179474\n",
      "Epoch 38/40, Validation Loss: 0.4526511244670883, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 39/40, Training Loss: 0.40161028601170523\n",
      "Epoch 39/40, Validation Loss: 0.45069761078863246, Validation Accuracy: 0.797634691195795\n",
      "Epoch 40/40, Training Loss: 0.400213897286907\n",
      "Epoch 40/40, Validation Loss: 0.463344610466851, Validation Accuracy: 0.7989487516425755\n",
      "Average Validation Accuracy: 0.8023115557077937\n",
      "Number of Epochs: 40\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/50, Training Loss: 0.5391644486213919\n",
      "Epoch 1/50, Validation Loss: 0.5031374373049012, Validation Accuracy: 0.7669074195666448\n",
      "Epoch 2/50, Training Loss: 0.48174430604955654\n",
      "Epoch 2/50, Validation Loss: 0.48380777723502116, Validation Accuracy: 0.7826657912015759\n",
      "Epoch 3/50, Training Loss: 0.46366948260879265\n",
      "Epoch 3/50, Validation Loss: 0.47540736143813705, Validation Accuracy: 0.7826657912015759\n",
      "Epoch 4/50, Training Loss: 0.4550979113563152\n",
      "Epoch 4/50, Validation Loss: 0.46812988053129606, Validation Accuracy: 0.7866053841103086\n",
      "Epoch 5/50, Training Loss: 0.45076895450434973\n",
      "Epoch 5/50, Validation Loss: 0.4676502236989156, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 6/50, Training Loss: 0.44441556071085253\n",
      "Epoch 6/50, Validation Loss: 0.462650243602498, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 7/50, Training Loss: 0.4400900910728247\n",
      "Epoch 7/50, Validation Loss: 0.46197657017963717, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 8/50, Training Loss: 0.43484234773698127\n",
      "Epoch 8/50, Validation Loss: 0.4752173484619999, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 9/50, Training Loss: 0.43279221587450173\n",
      "Epoch 9/50, Validation Loss: 0.4599548431201131, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 10/50, Training Loss: 0.43050773346948185\n",
      "Epoch 10/50, Validation Loss: 0.4665662936515209, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 11/50, Training Loss: 0.42815661467514016\n",
      "Epoch 11/50, Validation Loss: 0.45946001210761944, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 12/50, Training Loss: 0.42601594141149146\n",
      "Epoch 12/50, Validation Loss: 0.46206137463840513, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 13/50, Training Loss: 0.42293681658002646\n",
      "Epoch 13/50, Validation Loss: 0.45654833765398145, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 14/50, Training Loss: 0.42462381656988085\n",
      "Epoch 14/50, Validation Loss: 0.45522697788726596, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 15/50, Training Loss: 0.4218022160212512\n",
      "Epoch 15/50, Validation Loss: 0.45662376715640746, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 16/50, Training Loss: 0.4226510789137813\n",
      "Epoch 16/50, Validation Loss: 0.4594445612028007, Validation Accuracy: 0.793827971109652\n",
      "Epoch 17/50, Training Loss: 0.4185206954052129\n",
      "Epoch 17/50, Validation Loss: 0.45561559428095194, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 18/50, Training Loss: 0.4175184146254238\n",
      "Epoch 18/50, Validation Loss: 0.4574312876461376, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 19/50, Training Loss: 0.4155963248917906\n",
      "Epoch 19/50, Validation Loss: 0.45569110575926863, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 20/50, Training Loss: 0.414296466182536\n",
      "Epoch 20/50, Validation Loss: 0.45777805972629815, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 21/50, Training Loss: 0.41355127518571266\n",
      "Epoch 21/50, Validation Loss: 0.4904413329954235, Validation Accuracy: 0.7531188443860801\n",
      "Epoch 22/50, Training Loss: 0.41511345541305117\n",
      "Epoch 22/50, Validation Loss: 0.4568054671764998, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 23/50, Training Loss: 0.4128458607560537\n",
      "Epoch 23/50, Validation Loss: 0.4568622812862796, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 24/50, Training Loss: 0.41106846795620255\n",
      "Epoch 24/50, Validation Loss: 0.47025960752087115, Validation Accuracy: 0.7734734077478661\n",
      "Epoch 25/50, Training Loss: 0.41061804853770834\n",
      "Epoch 25/50, Validation Loss: 0.49633569867199007, Validation Accuracy: 0.7531188443860801\n",
      "Epoch 26/50, Training Loss: 0.40768493070533585\n",
      "Epoch 26/50, Validation Loss: 0.47484345876499623, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 27/50, Training Loss: 0.40833893112271163\n",
      "Epoch 27/50, Validation Loss: 0.4596924901554722, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 28/50, Training Loss: 0.40641606532604363\n",
      "Epoch 28/50, Validation Loss: 0.4644773154475614, Validation Accuracy: 0.7754432042022325\n",
      "Epoch 29/50, Training Loss: 0.40790921355795673\n",
      "Epoch 29/50, Validation Loss: 0.47217125621141565, Validation Accuracy: 0.7741300065659882\n",
      "Epoch 30/50, Training Loss: 0.40768327447646874\n",
      "Epoch 30/50, Validation Loss: 0.4580044821684897, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 31/50, Training Loss: 0.40486982843185976\n",
      "Epoch 31/50, Validation Loss: 0.4599446645932984, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 32/50, Training Loss: 0.40380508643318347\n",
      "Epoch 32/50, Validation Loss: 0.4667919991996276, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 33/50, Training Loss: 0.40419676983997893\n",
      "Epoch 33/50, Validation Loss: 0.4585474189858474, Validation Accuracy: 0.793827971109652\n",
      "Epoch 34/50, Training Loss: 0.40190812353817185\n",
      "Epoch 34/50, Validation Loss: 0.4602230404996123, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 35/50, Training Loss: 0.4030474717349909\n",
      "Epoch 35/50, Validation Loss: 0.45806146331170466, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 36/50, Training Loss: 0.40053350627031226\n",
      "Epoch 36/50, Validation Loss: 0.45625248385583544, Validation Accuracy: 0.804333552199606\n",
      "Epoch 37/50, Training Loss: 0.4022417851379068\n",
      "Epoch 37/50, Validation Loss: 0.4585516629106711, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 38/50, Training Loss: 0.3997628780380087\n",
      "Epoch 38/50, Validation Loss: 0.46126762477203187, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 39/50, Training Loss: 0.40028893502228685\n",
      "Epoch 39/50, Validation Loss: 0.4644074630557867, Validation Accuracy: 0.7813525935653316\n",
      "Epoch 40/50, Training Loss: 0.39904376702612937\n",
      "Epoch 40/50, Validation Loss: 0.46313230508050995, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 41/50, Training Loss: 0.3988074453601374\n",
      "Epoch 41/50, Validation Loss: 0.47293668852738685, Validation Accuracy: 0.7741300065659882\n",
      "Epoch 42/50, Training Loss: 0.3992097938623954\n",
      "Epoch 42/50, Validation Loss: 0.4615366800410273, Validation Accuracy: 0.7879185817465528\n",
      "Epoch 43/50, Training Loss: 0.3975139695007031\n",
      "Epoch 43/50, Validation Loss: 0.46753867918440184, Validation Accuracy: 0.7852921864740644\n",
      "Epoch 44/50, Training Loss: 0.3968433030536325\n",
      "Epoch 44/50, Validation Loss: 0.46074563475491487, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 45/50, Training Loss: 0.39803916571314724\n",
      "Epoch 45/50, Validation Loss: 0.4598247929432317, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 46/50, Training Loss: 0.39685800431535784\n",
      "Epoch 46/50, Validation Loss: 0.4629240129045479, Validation Accuracy: 0.7839789888378201\n",
      "Epoch 47/50, Training Loss: 0.3969747506258056\n",
      "Epoch 47/50, Validation Loss: 0.45822257451049947, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 48/50, Training Loss: 0.39452309594086304\n",
      "Epoch 48/50, Validation Loss: 0.46658032083230494, Validation Accuracy: 0.7813525935653316\n",
      "Epoch 49/50, Training Loss: 0.3940100536982375\n",
      "Epoch 49/50, Validation Loss: 0.45849657050914167, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 50/50, Training Loss: 0.39304672325337964\n",
      "Epoch 50/50, Validation Loss: 0.4713129873987268, Validation Accuracy: 0.7957977675640184\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/50, Training Loss: 0.5402038769498272\n",
      "Epoch 1/50, Validation Loss: 0.48538718821178556, Validation Accuracy: 0.7813525935653316\n",
      "Epoch 2/50, Training Loss: 0.48153339737043604\n",
      "Epoch 2/50, Validation Loss: 0.4661268080092225, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 3/50, Training Loss: 0.4691218611957833\n",
      "Epoch 3/50, Validation Loss: 0.45976610825011865, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 4/50, Training Loss: 0.4571802259723502\n",
      "Epoch 4/50, Validation Loss: 0.46127340384802895, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 5/50, Training Loss: 0.45177857935663285\n",
      "Epoch 5/50, Validation Loss: 0.4525009296561411, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 6/50, Training Loss: 0.44918971796204726\n",
      "Epoch 6/50, Validation Loss: 0.45996572172844596, Validation Accuracy: 0.7866053841103086\n",
      "Epoch 7/50, Training Loss: 0.44222844371528136\n",
      "Epoch 7/50, Validation Loss: 0.4455732575651863, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 8/50, Training Loss: 0.43984817147372274\n",
      "Epoch 8/50, Validation Loss: 0.4457578093437624, Validation Accuracy: 0.799080761654629\n",
      "Epoch 9/50, Training Loss: 0.4375209573294547\n",
      "Epoch 9/50, Validation Loss: 0.4467921583908391, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 10/50, Training Loss: 0.4346304364854426\n",
      "Epoch 10/50, Validation Loss: 0.44727387497718424, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 11/50, Training Loss: 0.43029676908700487\n",
      "Epoch 11/50, Validation Loss: 0.440202538879754, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 12/50, Training Loss: 0.43078125648572063\n",
      "Epoch 12/50, Validation Loss: 0.4451205883740755, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 13/50, Training Loss: 0.42721282432633123\n",
      "Epoch 13/50, Validation Loss: 0.440485666306075, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 14/50, Training Loss: 0.4251834349388995\n",
      "Epoch 14/50, Validation Loss: 0.4566576392511735, Validation Accuracy: 0.799080761654629\n",
      "Epoch 15/50, Training Loss: 0.4258508352548119\n",
      "Epoch 15/50, Validation Loss: 0.4446627203355597, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 16/50, Training Loss: 0.42310547572499496\n",
      "Epoch 16/50, Validation Loss: 0.44954521257761887, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 17/50, Training Loss: 0.42199498004331365\n",
      "Epoch 17/50, Validation Loss: 0.4503372365716084, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 18/50, Training Loss: 0.4211560857734029\n",
      "Epoch 18/50, Validation Loss: 0.4674760292708406, Validation Accuracy: 0.7734734077478661\n",
      "Epoch 19/50, Training Loss: 0.4187962336959488\n",
      "Epoch 19/50, Validation Loss: 0.43904731820547144, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 20/50, Training Loss: 0.4175360052506598\n",
      "Epoch 20/50, Validation Loss: 0.46017605020464714, Validation Accuracy: 0.7787261982928431\n",
      "Epoch 21/50, Training Loss: 0.4173457651763294\n",
      "Epoch 21/50, Validation Loss: 0.44107088957625534, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 22/50, Training Loss: 0.4161673139076768\n",
      "Epoch 22/50, Validation Loss: 0.447148149101678, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 23/50, Training Loss: 0.41456034206577486\n",
      "Epoch 23/50, Validation Loss: 0.44077134701906073, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 24/50, Training Loss: 0.41466815300344484\n",
      "Epoch 24/50, Validation Loss: 0.445630069822073, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 25/50, Training Loss: 0.4138931055453036\n",
      "Epoch 25/50, Validation Loss: 0.4432252580348734, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 26/50, Training Loss: 0.4116411505369689\n",
      "Epoch 26/50, Validation Loss: 0.45244225155542656, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 27/50, Training Loss: 0.4119198687980807\n",
      "Epoch 27/50, Validation Loss: 0.43941921153695795, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 28/50, Training Loss: 0.40979912342733443\n",
      "Epoch 28/50, Validation Loss: 0.4419610396768722, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 29/50, Training Loss: 0.4101461210236775\n",
      "Epoch 29/50, Validation Loss: 0.44398088072529013, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 30/50, Training Loss: 0.4080410977859744\n",
      "Epoch 30/50, Validation Loss: 0.4551525007036188, Validation Accuracy: 0.7866053841103086\n",
      "Epoch 31/50, Training Loss: 0.40912463706661395\n",
      "Epoch 31/50, Validation Loss: 0.4396838358754575, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 32/50, Training Loss: 0.40601262295242213\n",
      "Epoch 32/50, Validation Loss: 0.4416009121384296, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 33/50, Training Loss: 0.40817066516208994\n",
      "Epoch 33/50, Validation Loss: 0.4509309327610188, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 34/50, Training Loss: 0.4048589488388751\n",
      "Epoch 34/50, Validation Loss: 0.4439606008300294, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 35/50, Training Loss: 0.40763786870233343\n",
      "Epoch 35/50, Validation Loss: 0.4490429936805789, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 36/50, Training Loss: 0.40527916324185576\n",
      "Epoch 36/50, Validation Loss: 0.44061687598443783, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 37/50, Training Loss: 0.4044179608532059\n",
      "Epoch 37/50, Validation Loss: 0.4404062938861822, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 38/50, Training Loss: 0.4032851609345183\n",
      "Epoch 38/50, Validation Loss: 0.4463559717369017, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 39/50, Training Loss: 0.40311100500149366\n",
      "Epoch 39/50, Validation Loss: 0.44471951031872115, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 40/50, Training Loss: 0.40224397370195764\n",
      "Epoch 40/50, Validation Loss: 0.45060290805800424, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 41/50, Training Loss: 0.4019599859394974\n",
      "Epoch 41/50, Validation Loss: 0.4431973466776428, Validation Accuracy: 0.793827971109652\n",
      "Epoch 42/50, Training Loss: 0.4028267145371969\n",
      "Epoch 42/50, Validation Loss: 0.4422773261656936, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 43/50, Training Loss: 0.4013460666684341\n",
      "Epoch 43/50, Validation Loss: 0.44961269710856583, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 44/50, Training Loss: 0.39953683657948114\n",
      "Epoch 44/50, Validation Loss: 0.4414065414893378, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 45/50, Training Loss: 0.39929667357697574\n",
      "Epoch 45/50, Validation Loss: 0.44186041082855293, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 46/50, Training Loss: 0.3986207522999427\n",
      "Epoch 46/50, Validation Loss: 0.4427432863539114, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 47/50, Training Loss: 0.3986973027671807\n",
      "Epoch 47/50, Validation Loss: 0.4451152175586885, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 48/50, Training Loss: 0.4001691334164674\n",
      "Epoch 48/50, Validation Loss: 0.4455660455006892, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 49/50, Training Loss: 0.39760576754691096\n",
      "Epoch 49/50, Validation Loss: 0.44446156351432126, Validation Accuracy: 0.793827971109652\n",
      "Epoch 50/50, Training Loss: 0.40032049920165474\n",
      "Epoch 50/50, Validation Loss: 0.4499271241996769, Validation Accuracy: 0.7957977675640184\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/50, Training Loss: 0.536414876150021\n",
      "Epoch 1/50, Validation Loss: 0.49534806694971956, Validation Accuracy: 0.7688772160210111\n",
      "Epoch 2/50, Training Loss: 0.4792961841375809\n",
      "Epoch 2/50, Validation Loss: 0.4764798297229862, Validation Accuracy: 0.7787261982928431\n",
      "Epoch 3/50, Training Loss: 0.4639779667998236\n",
      "Epoch 3/50, Validation Loss: 0.5205703131386434, Validation Accuracy: 0.7380170715692712\n",
      "Epoch 4/50, Training Loss: 0.45592335714247284\n",
      "Epoch 4/50, Validation Loss: 0.4660734744128132, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 5/50, Training Loss: 0.44958288834633164\n",
      "Epoch 5/50, Validation Loss: 0.46219969739776634, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 6/50, Training Loss: 0.4455511386156708\n",
      "Epoch 6/50, Validation Loss: 0.456569738296002, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 7/50, Training Loss: 0.4397831183132224\n",
      "Epoch 7/50, Validation Loss: 0.4603329592662332, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 8/50, Training Loss: 0.4365315301309577\n",
      "Epoch 8/50, Validation Loss: 0.45792331445123513, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 9/50, Training Loss: 0.4355504103200486\n",
      "Epoch 9/50, Validation Loss: 0.45543109941544957, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 10/50, Training Loss: 0.4307299598054154\n",
      "Epoch 10/50, Validation Loss: 0.45302968874027594, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 11/50, Training Loss: 0.42809479379552245\n",
      "Epoch 11/50, Validation Loss: 0.4525447878303952, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 12/50, Training Loss: 0.4270963894882853\n",
      "Epoch 12/50, Validation Loss: 0.46296732509947575, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 13/50, Training Loss: 0.4240987723854583\n",
      "Epoch 13/50, Validation Loss: 0.4599451499537648, Validation Accuracy: 0.788575180564675\n",
      "Epoch 14/50, Training Loss: 0.425376934906238\n",
      "Epoch 14/50, Validation Loss: 0.4489522604808133, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 15/50, Training Loss: 0.4213009432173307\n",
      "Epoch 15/50, Validation Loss: 0.45857227851114973, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 16/50, Training Loss: 0.422184434609385\n",
      "Epoch 16/50, Validation Loss: 0.4514293731507206, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 17/50, Training Loss: 0.4190723666544818\n",
      "Epoch 17/50, Validation Loss: 0.46484754070717627, Validation Accuracy: 0.788575180564675\n",
      "Epoch 18/50, Training Loss: 0.42023802015764194\n",
      "Epoch 18/50, Validation Loss: 0.44884818324243836, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 19/50, Training Loss: 0.4168150143751635\n",
      "Epoch 19/50, Validation Loss: 0.4565905795593536, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 20/50, Training Loss: 0.41547970477677393\n",
      "Epoch 20/50, Validation Loss: 0.45601275481322673, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 21/50, Training Loss: 0.4138498913222958\n",
      "Epoch 21/50, Validation Loss: 0.45166224494810503, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 22/50, Training Loss: 0.41343829746595206\n",
      "Epoch 22/50, Validation Loss: 0.45641468660369594, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 23/50, Training Loss: 0.411750510031861\n",
      "Epoch 23/50, Validation Loss: 0.45015830601229095, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 24/50, Training Loss: 0.4105265669847333\n",
      "Epoch 24/50, Validation Loss: 0.44898169031317947, Validation Accuracy: 0.8069599474720945\n",
      "Epoch 25/50, Training Loss: 0.4087949346046983\n",
      "Epoch 25/50, Validation Loss: 0.4541344790675565, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 26/50, Training Loss: 0.411560993113621\n",
      "Epoch 26/50, Validation Loss: 0.45503158139854827, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 27/50, Training Loss: 0.4096172054168668\n",
      "Epoch 27/50, Validation Loss: 0.45034287694393027, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 28/50, Training Loss: 0.40870204439821833\n",
      "Epoch 28/50, Validation Loss: 0.45149595594686986, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 29/50, Training Loss: 0.407461580270388\n",
      "Epoch 29/50, Validation Loss: 0.4475822071520446, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 30/50, Training Loss: 0.40662451006296113\n",
      "Epoch 30/50, Validation Loss: 0.4526014909226233, Validation Accuracy: 0.799080761654629\n",
      "Epoch 31/50, Training Loss: 0.40526690455324693\n",
      "Epoch 31/50, Validation Loss: 0.46441639672126134, Validation Accuracy: 0.7826657912015759\n",
      "Epoch 32/50, Training Loss: 0.4043438291553594\n",
      "Epoch 32/50, Validation Loss: 0.4555985062768322, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 33/50, Training Loss: 0.4044733110062406\n",
      "Epoch 33/50, Validation Loss: 0.45839574053415455, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 34/50, Training Loss: 0.4030242242026595\n",
      "Epoch 34/50, Validation Loss: 0.46841712699744714, Validation Accuracy: 0.783322390019698\n",
      "Epoch 35/50, Training Loss: 0.40365564449643837\n",
      "Epoch 35/50, Validation Loss: 0.4548936193877178, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 36/50, Training Loss: 0.40372668806062595\n",
      "Epoch 36/50, Validation Loss: 0.4484299592166671, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 37/50, Training Loss: 0.4021189778534759\n",
      "Epoch 37/50, Validation Loss: 0.44934159653817174, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 38/50, Training Loss: 0.40285762286503013\n",
      "Epoch 38/50, Validation Loss: 0.4509316938514797, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 39/50, Training Loss: 0.4001995976183202\n",
      "Epoch 39/50, Validation Loss: 0.44734690137480565, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 40/50, Training Loss: 0.4004587678928075\n",
      "Epoch 40/50, Validation Loss: 0.4507896737122411, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 41/50, Training Loss: 0.40047776506446164\n",
      "Epoch 41/50, Validation Loss: 0.449171418626427, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 42/50, Training Loss: 0.39875942689618415\n",
      "Epoch 42/50, Validation Loss: 0.4553636564283159, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 43/50, Training Loss: 0.39943227792779606\n",
      "Epoch 43/50, Validation Loss: 0.4553627010181312, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 44/50, Training Loss: 0.3982502484591458\n",
      "Epoch 44/50, Validation Loss: 0.4570714378271115, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 45/50, Training Loss: 0.3966879109922904\n",
      "Epoch 45/50, Validation Loss: 0.4553921424944675, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 46/50, Training Loss: 0.3970927981723325\n",
      "Epoch 46/50, Validation Loss: 0.4586767698028637, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 47/50, Training Loss: 0.39826756782262657\n",
      "Epoch 47/50, Validation Loss: 0.45063212974221295, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 48/50, Training Loss: 0.3951965757496557\n",
      "Epoch 48/50, Validation Loss: 0.4494036767651273, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 49/50, Training Loss: 0.3979484817194031\n",
      "Epoch 49/50, Validation Loss: 0.4569504425436726, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 50/50, Training Loss: 0.3956729456430345\n",
      "Epoch 50/50, Validation Loss: 0.4577901890374603, Validation Accuracy: 0.7971109652002626\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/50, Training Loss: 0.5449090212622653\n",
      "Epoch 1/50, Validation Loss: 0.5007038960594157, Validation Accuracy: 0.7700394218134035\n",
      "Epoch 2/50, Training Loss: 0.4833457392305527\n",
      "Epoch 2/50, Validation Loss: 0.47573267769907157, Validation Accuracy: 0.778580814717477\n",
      "Epoch 3/50, Training Loss: 0.4697092795583207\n",
      "Epoch 3/50, Validation Loss: 0.45954043936979083, Validation Accuracy: 0.7923784494086727\n",
      "Epoch 4/50, Training Loss: 0.46187301898213823\n",
      "Epoch 4/50, Validation Loss: 0.4538821202376126, Validation Accuracy: 0.7917214191852825\n",
      "Epoch 5/50, Training Loss: 0.45262315690400096\n",
      "Epoch 5/50, Validation Loss: 0.4680987499381235, Validation Accuracy: 0.7825229960578186\n",
      "Epoch 6/50, Training Loss: 0.4473946593662729\n",
      "Epoch 6/50, Validation Loss: 0.4522544298886629, Validation Accuracy: 0.7917214191852825\n",
      "Epoch 7/50, Training Loss: 0.4454180614783226\n",
      "Epoch 7/50, Validation Loss: 0.4785869613055783, Validation Accuracy: 0.7766097240473062\n",
      "Epoch 8/50, Training Loss: 0.44010030776457837\n",
      "Epoch 8/50, Validation Loss: 0.44841815913534916, Validation Accuracy: 0.7910643889618922\n",
      "Epoch 9/50, Training Loss: 0.43843447804216323\n",
      "Epoch 9/50, Validation Loss: 0.4456313296138304, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 10/50, Training Loss: 0.43812285393984923\n",
      "Epoch 10/50, Validation Loss: 0.44526651107672, Validation Accuracy: 0.7950065703022339\n",
      "Epoch 11/50, Training Loss: 0.4328251918411161\n",
      "Epoch 11/50, Validation Loss: 0.4481540505642666, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 12/50, Training Loss: 0.4340349308012195\n",
      "Epoch 12/50, Validation Loss: 0.4595150014102771, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 13/50, Training Loss: 0.43097053986443623\n",
      "Epoch 13/50, Validation Loss: 0.4406533281255455, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 14/50, Training Loss: 0.42844582616969984\n",
      "Epoch 14/50, Validation Loss: 0.4416099699379886, Validation Accuracy: 0.7943495400788436\n",
      "Epoch 15/50, Training Loss: 0.4267400221072939\n",
      "Epoch 15/50, Validation Loss: 0.4414266706566224, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 16/50, Training Loss: 0.4250253934286085\n",
      "Epoch 16/50, Validation Loss: 0.4509951560051029, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 17/50, Training Loss: 0.4241035762255195\n",
      "Epoch 17/50, Validation Loss: 0.4389626398019454, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 18/50, Training Loss: 0.4225991962678007\n",
      "Epoch 18/50, Validation Loss: 0.4416144347666758, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 19/50, Training Loss: 0.42249280079377916\n",
      "Epoch 19/50, Validation Loss: 0.4371109583576, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 20/50, Training Loss: 0.42033828851666666\n",
      "Epoch 20/50, Validation Loss: 0.4371927063619591, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 21/50, Training Loss: 0.41828035620918735\n",
      "Epoch 21/50, Validation Loss: 0.45698278291999356, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 22/50, Training Loss: 0.42134085379228037\n",
      "Epoch 22/50, Validation Loss: 0.4580198376200586, Validation Accuracy: 0.797634691195795\n",
      "Epoch 23/50, Training Loss: 0.41802857352758016\n",
      "Epoch 23/50, Validation Loss: 0.44368497110630206, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 24/50, Training Loss: 0.41612817164207383\n",
      "Epoch 24/50, Validation Loss: 0.4372177384598717, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 25/50, Training Loss: 0.4154229871048702\n",
      "Epoch 25/50, Validation Loss: 0.4454207142220118, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 26/50, Training Loss: 0.41513095554599927\n",
      "Epoch 26/50, Validation Loss: 0.44127955151165965, Validation Accuracy: 0.8153745072273325\n",
      "Epoch 27/50, Training Loss: 0.41265954710836483\n",
      "Epoch 27/50, Validation Loss: 0.437352380066798, Validation Accuracy: 0.8147174770039421\n",
      "Epoch 28/50, Training Loss: 0.412946614458805\n",
      "Epoch 28/50, Validation Loss: 0.4382402785317436, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 29/50, Training Loss: 0.41193862008101984\n",
      "Epoch 29/50, Validation Loss: 0.4387736666108925, Validation Accuracy: 0.804862023653088\n",
      "Epoch 30/50, Training Loss: 0.4129283758237215\n",
      "Epoch 30/50, Validation Loss: 0.4503153521587087, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 31/50, Training Loss: 0.4109889461592896\n",
      "Epoch 31/50, Validation Loss: 0.4365659979469489, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 32/50, Training Loss: 0.41010735195687437\n",
      "Epoch 32/50, Validation Loss: 0.4362832999237233, Validation Accuracy: 0.812089356110381\n",
      "Epoch 33/50, Training Loss: 0.4089254684296493\n",
      "Epoch 33/50, Validation Loss: 0.4353728034772486, Validation Accuracy: 0.812089356110381\n",
      "Epoch 34/50, Training Loss: 0.40924431208589573\n",
      "Epoch 34/50, Validation Loss: 0.43795233652853843, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 35/50, Training Loss: 0.40688393752425517\n",
      "Epoch 35/50, Validation Loss: 0.446564904506762, Validation Accuracy: 0.7890932982917214\n",
      "Epoch 36/50, Training Loss: 0.4051239409745522\n",
      "Epoch 36/50, Validation Loss: 0.4470585957754657, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 37/50, Training Loss: 0.4048186091906599\n",
      "Epoch 37/50, Validation Loss: 0.441210103128593, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 38/50, Training Loss: 0.40767954922039207\n",
      "Epoch 38/50, Validation Loss: 0.43690272769768823, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 39/50, Training Loss: 0.40589036967536907\n",
      "Epoch 39/50, Validation Loss: 0.45155534993720614, Validation Accuracy: 0.7871222076215506\n",
      "Epoch 40/50, Training Loss: 0.4059024631654418\n",
      "Epoch 40/50, Validation Loss: 0.4390297638184113, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 41/50, Training Loss: 0.40625134778265254\n",
      "Epoch 41/50, Validation Loss: 0.44049050653090027, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 42/50, Training Loss: 0.4047355579207419\n",
      "Epoch 42/50, Validation Loss: 0.4383303401552882, Validation Accuracy: 0.80946123521682\n",
      "Epoch 43/50, Training Loss: 0.4035653407218575\n",
      "Epoch 43/50, Validation Loss: 0.4516272520090585, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 44/50, Training Loss: 0.40346889018406235\n",
      "Epoch 44/50, Validation Loss: 0.4406891717375573, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 45/50, Training Loss: 0.40301754531937006\n",
      "Epoch 45/50, Validation Loss: 0.447721557935495, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 46/50, Training Loss: 0.40169184349887954\n",
      "Epoch 46/50, Validation Loss: 0.4396251870114454, Validation Accuracy: 0.80946123521682\n",
      "Epoch 47/50, Training Loss: 0.4027837771223247\n",
      "Epoch 47/50, Validation Loss: 0.4387874326117688, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 48/50, Training Loss: 0.4004884310008034\n",
      "Epoch 48/50, Validation Loss: 0.4358576742142283, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 49/50, Training Loss: 0.4005097510131795\n",
      "Epoch 49/50, Validation Loss: 0.4520382387904909, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 50/50, Training Loss: 0.3995177685393123\n",
      "Epoch 50/50, Validation Loss: 0.43746309159859936, Validation Accuracy: 0.812089356110381\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/50, Training Loss: 0.5363167199328189\n",
      "Epoch 1/50, Validation Loss: 0.48670699326467765, Validation Accuracy: 0.7838370565045992\n",
      "Epoch 2/50, Training Loss: 0.4824532375639192\n",
      "Epoch 2/50, Validation Loss: 0.4780983862842565, Validation Accuracy: 0.778580814717477\n",
      "Epoch 3/50, Training Loss: 0.4654112748430157\n",
      "Epoch 3/50, Validation Loss: 0.4655222397356133, Validation Accuracy: 0.7943495400788436\n",
      "Epoch 4/50, Training Loss: 0.45553612492959017\n",
      "Epoch 4/50, Validation Loss: 0.469284505744255, Validation Accuracy: 0.7851511169513797\n",
      "Epoch 5/50, Training Loss: 0.4515172520803967\n",
      "Epoch 5/50, Validation Loss: 0.47380506781695403, Validation Accuracy: 0.7792378449408672\n",
      "Epoch 6/50, Training Loss: 0.44446602191903145\n",
      "Epoch 6/50, Validation Loss: 0.45374930451053597, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 7/50, Training Loss: 0.44083103541470575\n",
      "Epoch 7/50, Validation Loss: 0.4600373485091469, Validation Accuracy: 0.7956636005256241\n",
      "Epoch 8/50, Training Loss: 0.43811309293616474\n",
      "Epoch 8/50, Validation Loss: 0.4578936437037603, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 9/50, Training Loss: 0.43427615510079803\n",
      "Epoch 9/50, Validation Loss: 0.46983964226320774, Validation Accuracy: 0.7844940867279895\n",
      "Epoch 10/50, Training Loss: 0.4309864109210924\n",
      "Epoch 10/50, Validation Loss: 0.4639290113060574, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 11/50, Training Loss: 0.42952686536499834\n",
      "Epoch 11/50, Validation Loss: 0.4575063765673113, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 12/50, Training Loss: 0.4271226634816548\n",
      "Epoch 12/50, Validation Loss: 0.45670723872190994, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 13/50, Training Loss: 0.423657620457683\n",
      "Epoch 13/50, Validation Loss: 0.46470941599282917, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 14/50, Training Loss: 0.42484565283565384\n",
      "Epoch 14/50, Validation Loss: 0.4510904366823391, Validation Accuracy: 0.804862023653088\n",
      "Epoch 15/50, Training Loss: 0.42282879786697897\n",
      "Epoch 15/50, Validation Loss: 0.4501999871346963, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 16/50, Training Loss: 0.42156541313281837\n",
      "Epoch 16/50, Validation Loss: 0.44938539389852455, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 17/50, Training Loss: 0.41830035433994506\n",
      "Epoch 17/50, Validation Loss: 0.4576182473470403, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 18/50, Training Loss: 0.41662413258780173\n",
      "Epoch 18/50, Validation Loss: 0.4795550164517932, Validation Accuracy: 0.7720105124835742\n",
      "Epoch 19/50, Training Loss: 0.41911971351019356\n",
      "Epoch 19/50, Validation Loss: 0.46251644020539306, Validation Accuracy: 0.790407358738502\n",
      "Epoch 20/50, Training Loss: 0.4160784349686361\n",
      "Epoch 20/50, Validation Loss: 0.45740534883987216, Validation Accuracy: 0.7950065703022339\n",
      "Epoch 21/50, Training Loss: 0.41554980992469104\n",
      "Epoch 21/50, Validation Loss: 0.4471497992492471, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 22/50, Training Loss: 0.41285909139343446\n",
      "Epoch 22/50, Validation Loss: 0.45866534638545275, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 23/50, Training Loss: 0.41654213469015955\n",
      "Epoch 23/50, Validation Loss: 0.4563157379783261, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 24/50, Training Loss: 0.41178741627751686\n",
      "Epoch 24/50, Validation Loss: 0.45804572017639095, Validation Accuracy: 0.797634691195795\n",
      "Epoch 25/50, Training Loss: 0.409200864484695\n",
      "Epoch 25/50, Validation Loss: 0.4551703171190167, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 26/50, Training Loss: 0.4107038949633364\n",
      "Epoch 26/50, Validation Loss: 0.4704575871765926, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 27/50, Training Loss: 0.40852221454985027\n",
      "Epoch 27/50, Validation Loss: 0.45182370043393827, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 28/50, Training Loss: 0.40714788946305985\n",
      "Epoch 28/50, Validation Loss: 0.46195467454210626, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 29/50, Training Loss: 0.4074682004192448\n",
      "Epoch 29/50, Validation Loss: 0.45582046948802407, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 30/50, Training Loss: 0.4062655061835379\n",
      "Epoch 30/50, Validation Loss: 0.46150135752106214, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 31/50, Training Loss: 0.4062250993187659\n",
      "Epoch 31/50, Validation Loss: 0.455333022000902, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 32/50, Training Loss: 0.40430544462455853\n",
      "Epoch 32/50, Validation Loss: 0.46718930191706615, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 33/50, Training Loss: 0.4038158634975748\n",
      "Epoch 33/50, Validation Loss: 0.45331270637780585, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 34/50, Training Loss: 0.4048287045318154\n",
      "Epoch 34/50, Validation Loss: 0.4641559470776488, Validation Accuracy: 0.7923784494086727\n",
      "Epoch 35/50, Training Loss: 0.4033374964232676\n",
      "Epoch 35/50, Validation Loss: 0.4499486891152971, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 36/50, Training Loss: 0.4016025745923438\n",
      "Epoch 36/50, Validation Loss: 0.45301232742467473, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 37/50, Training Loss: 0.4024655087374327\n",
      "Epoch 37/50, Validation Loss: 0.4572201241295375, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 38/50, Training Loss: 0.4020535134346154\n",
      "Epoch 38/50, Validation Loss: 0.456983013731959, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 39/50, Training Loss: 0.4015098663726504\n",
      "Epoch 39/50, Validation Loss: 0.45258301137629603, Validation Accuracy: 0.7956636005256241\n",
      "Epoch 40/50, Training Loss: 0.4009436083043341\n",
      "Epoch 40/50, Validation Loss: 0.45449816400468035, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 41/50, Training Loss: 0.3993948800269309\n",
      "Epoch 41/50, Validation Loss: 0.45624087690448883, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 42/50, Training Loss: 0.39938942144998885\n",
      "Epoch 42/50, Validation Loss: 0.4507740768774642, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 43/50, Training Loss: 0.400399717514518\n",
      "Epoch 43/50, Validation Loss: 0.4515039776086183, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 44/50, Training Loss: 0.3991245703962375\n",
      "Epoch 44/50, Validation Loss: 0.45621401098854253, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 45/50, Training Loss: 0.3986097177798588\n",
      "Epoch 45/50, Validation Loss: 0.4595118903442827, Validation Accuracy: 0.7923784494086727\n",
      "Epoch 46/50, Training Loss: 0.39575403613427024\n",
      "Epoch 46/50, Validation Loss: 0.4687367547010876, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 47/50, Training Loss: 0.3973490047388346\n",
      "Epoch 47/50, Validation Loss: 0.4519454804663571, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 48/50, Training Loss: 0.39662432276553367\n",
      "Epoch 48/50, Validation Loss: 0.45176978358579556, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 49/50, Training Loss: 0.39642150539738613\n",
      "Epoch 49/50, Validation Loss: 0.45279666759970927, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 50/50, Training Loss: 0.39505006806568055\n",
      "Epoch 50/50, Validation Loss: 0.4635417108955496, Validation Accuracy: 0.797634691195795\n",
      "Average Validation Accuracy: 0.7996861095268951\n",
      "Number of Epochs: 50\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/60, Training Loss: 0.5399030881721204\n",
      "Epoch 1/60, Validation Loss: 0.5050141692005526, Validation Accuracy: 0.7695338148391333\n",
      "Epoch 2/60, Training Loss: 0.47809022131163303\n",
      "Epoch 2/60, Validation Loss: 0.4859773553322747, Validation Accuracy: 0.7760998030203545\n",
      "Epoch 3/60, Training Loss: 0.4640404968241381\n",
      "Epoch 3/60, Validation Loss: 0.4773687453092081, Validation Accuracy: 0.7879185817465528\n",
      "Epoch 4/60, Training Loss: 0.45512983108090915\n",
      "Epoch 4/60, Validation Loss: 0.46983176516612785, Validation Accuracy: 0.793827971109652\n",
      "Epoch 5/60, Training Loss: 0.4506337134524437\n",
      "Epoch 5/60, Validation Loss: 0.46480881450063893, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 6/60, Training Loss: 0.44411378456499634\n",
      "Epoch 6/60, Validation Loss: 0.46530724375347815, Validation Accuracy: 0.7879185817465528\n",
      "Epoch 7/60, Training Loss: 0.43776893952074325\n",
      "Epoch 7/60, Validation Loss: 0.4631289747685038, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 8/60, Training Loss: 0.43754789747512873\n",
      "Epoch 8/60, Validation Loss: 0.4611241134439463, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 9/60, Training Loss: 0.43293084444727487\n",
      "Epoch 9/60, Validation Loss: 0.47784825301295175, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 10/60, Training Loss: 0.4297274881167205\n",
      "Epoch 10/60, Validation Loss: 0.4601027903912579, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 11/60, Training Loss: 0.4263862150273924\n",
      "Epoch 11/60, Validation Loss: 0.47579409260088235, Validation Accuracy: 0.7708470124753776\n",
      "Epoch 12/60, Training Loss: 0.42597934485381356\n",
      "Epoch 12/60, Validation Loss: 0.45896214488601184, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 13/60, Training Loss: 0.4235788286905589\n",
      "Epoch 13/60, Validation Loss: 0.4566656397899408, Validation Accuracy: 0.793827971109652\n",
      "Epoch 14/60, Training Loss: 0.4223875944500207\n",
      "Epoch 14/60, Validation Loss: 0.46138079226485096, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 15/60, Training Loss: 0.42084096245995656\n",
      "Epoch 15/60, Validation Loss: 0.4558446113780843, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 16/60, Training Loss: 0.418626769213617\n",
      "Epoch 16/60, Validation Loss: 0.4551467636492864, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 17/60, Training Loss: 0.41908988363434635\n",
      "Epoch 17/60, Validation Loss: 0.45707836466309915, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 18/60, Training Loss: 0.4183016868841069\n",
      "Epoch 18/60, Validation Loss: 0.45893805134670895, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 19/60, Training Loss: 0.4160070335516936\n",
      "Epoch 19/60, Validation Loss: 0.4640827456693999, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 20/60, Training Loss: 0.41430664268319845\n",
      "Epoch 20/60, Validation Loss: 0.4601198854168672, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 21/60, Training Loss: 0.4110935878722374\n",
      "Epoch 21/60, Validation Loss: 0.4676161456794639, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 22/60, Training Loss: 0.41612113541935686\n",
      "Epoch 22/60, Validation Loss: 0.4636155145330579, Validation Accuracy: 0.7852921864740644\n",
      "Epoch 23/60, Training Loss: 0.41235281375488586\n",
      "Epoch 23/60, Validation Loss: 0.4554904175639465, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 24/60, Training Loss: 0.4092902365895941\n",
      "Epoch 24/60, Validation Loss: 0.46234995583121064, Validation Accuracy: 0.783322390019698\n",
      "Epoch 25/60, Training Loss: 0.41141963297418094\n",
      "Epoch 25/60, Validation Loss: 0.45567720042083276, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 26/60, Training Loss: 0.40911893122230614\n",
      "Epoch 26/60, Validation Loss: 0.46197657105732337, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 27/60, Training Loss: 0.4089443052133785\n",
      "Epoch 27/60, Validation Loss: 0.45925691536583824, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 28/60, Training Loss: 0.4070720126035958\n",
      "Epoch 28/60, Validation Loss: 0.45669906777549163, Validation Accuracy: 0.804333552199606\n",
      "Epoch 29/60, Training Loss: 0.40932738959906606\n",
      "Epoch 29/60, Validation Loss: 0.45606685562439614, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 30/60, Training Loss: 0.40462441161138024\n",
      "Epoch 30/60, Validation Loss: 0.46052186551908547, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 31/60, Training Loss: 0.40582345252040175\n",
      "Epoch 31/60, Validation Loss: 0.4677214709290971, Validation Accuracy: 0.7787261982928431\n",
      "Epoch 32/60, Training Loss: 0.403155273305658\n",
      "Epoch 32/60, Validation Loss: 0.45913727920873004, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 33/60, Training Loss: 0.40598136432508003\n",
      "Epoch 33/60, Validation Loss: 0.46475159759140766, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 34/60, Training Loss: 0.40245724017206297\n",
      "Epoch 34/60, Validation Loss: 0.45615945926121393, Validation Accuracy: 0.804333552199606\n",
      "Epoch 35/60, Training Loss: 0.4039635899576928\n",
      "Epoch 35/60, Validation Loss: 0.4577952533063152, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 36/60, Training Loss: 0.40249154099759465\n",
      "Epoch 36/60, Validation Loss: 0.4704306636844318, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 37/60, Training Loss: 0.4009831236318497\n",
      "Epoch 37/60, Validation Loss: 0.4653608982319607, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 38/60, Training Loss: 0.40052883784602006\n",
      "Epoch 38/60, Validation Loss: 0.4863644109268463, Validation Accuracy: 0.7609980302035456\n",
      "Epoch 39/60, Training Loss: 0.39964744101554706\n",
      "Epoch 39/60, Validation Loss: 0.45742812499169905, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 40/60, Training Loss: 0.3984710784467656\n",
      "Epoch 40/60, Validation Loss: 0.4689057910941658, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 41/60, Training Loss: 0.399780160397917\n",
      "Epoch 41/60, Validation Loss: 0.45863424276650266, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 42/60, Training Loss: 0.39721719023045593\n",
      "Epoch 42/60, Validation Loss: 0.4655847261557404, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 43/60, Training Loss: 0.3984327745621442\n",
      "Epoch 43/60, Validation Loss: 0.45847040888760726, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 44/60, Training Loss: 0.39614059267629165\n",
      "Epoch 44/60, Validation Loss: 0.4664687220572801, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 45/60, Training Loss: 0.3975767829110773\n",
      "Epoch 45/60, Validation Loss: 0.46218610172652447, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 46/60, Training Loss: 0.3955212837559345\n",
      "Epoch 46/60, Validation Loss: 0.46150255367081827, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 47/60, Training Loss: 0.3942685431979225\n",
      "Epoch 47/60, Validation Loss: 0.4616926974417027, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 48/60, Training Loss: 0.394315160473618\n",
      "Epoch 48/60, Validation Loss: 0.4597651690868807, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 49/60, Training Loss: 0.39355183396674204\n",
      "Epoch 49/60, Validation Loss: 0.45957957311528513, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 50/60, Training Loss: 0.3954895575019944\n",
      "Epoch 50/60, Validation Loss: 0.4593255704376086, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 51/60, Training Loss: 0.3935260845353128\n",
      "Epoch 51/60, Validation Loss: 0.4694030353341115, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 52/60, Training Loss: 0.39352296285937466\n",
      "Epoch 52/60, Validation Loss: 0.4609877250269446, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 53/60, Training Loss: 0.3934637652196753\n",
      "Epoch 53/60, Validation Loss: 0.4659083632664531, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 54/60, Training Loss: 0.3920041767494103\n",
      "Epoch 54/60, Validation Loss: 0.46158432964411084, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 55/60, Training Loss: 0.3909885903571065\n",
      "Epoch 55/60, Validation Loss: 0.4604791407107683, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 56/60, Training Loss: 0.3907898483294358\n",
      "Epoch 56/60, Validation Loss: 0.4622059106553724, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 57/60, Training Loss: 0.3925934688743018\n",
      "Epoch 57/60, Validation Loss: 0.46866266363110215, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 58/60, Training Loss: 0.3935896367167081\n",
      "Epoch 58/60, Validation Loss: 0.46203003484385174, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 59/60, Training Loss: 0.39024687202505554\n",
      "Epoch 59/60, Validation Loss: 0.46939715239858126, Validation Accuracy: 0.7800393959290873\n",
      "Epoch 60/60, Training Loss: 0.38913904649652836\n",
      "Epoch 60/60, Validation Loss: 0.4661347971380693, Validation Accuracy: 0.804333552199606\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/60, Training Loss: 0.5414236403043502\n",
      "Epoch 1/60, Validation Loss: 0.482915387259728, Validation Accuracy: 0.7800393959290873\n",
      "Epoch 2/60, Training Loss: 0.48315179244348694\n",
      "Epoch 2/60, Validation Loss: 0.46304111900441935, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 3/60, Training Loss: 0.46727303087007344\n",
      "Epoch 3/60, Validation Loss: 0.45496236376893456, Validation Accuracy: 0.799080761654629\n",
      "Epoch 4/60, Training Loss: 0.46095072007750276\n",
      "Epoch 4/60, Validation Loss: 0.45355071763249594, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 5/60, Training Loss: 0.4507534054946399\n",
      "Epoch 5/60, Validation Loss: 0.45060632104805004, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 6/60, Training Loss: 0.4465561170042969\n",
      "Epoch 6/60, Validation Loss: 0.4705287025392992, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 7/60, Training Loss: 0.44292164239983545\n",
      "Epoch 7/60, Validation Loss: 0.45262965714042097, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 8/60, Training Loss: 0.44072904664622203\n",
      "Epoch 8/60, Validation Loss: 0.4475730245845168, Validation Accuracy: 0.799080761654629\n",
      "Epoch 9/60, Training Loss: 0.43857268849265546\n",
      "Epoch 9/60, Validation Loss: 0.4432856878802102, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 10/60, Training Loss: 0.4344125303422685\n",
      "Epoch 10/60, Validation Loss: 0.44674594462385975, Validation Accuracy: 0.804333552199606\n",
      "Epoch 11/60, Training Loss: 0.43470539142844555\n",
      "Epoch 11/60, Validation Loss: 0.4412485753132411, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 12/60, Training Loss: 0.42883639671690665\n",
      "Epoch 12/60, Validation Loss: 0.4640250362806919, Validation Accuracy: 0.7800393959290873\n",
      "Epoch 13/60, Training Loss: 0.428001818420693\n",
      "Epoch 13/60, Validation Loss: 0.4405839325596837, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 14/60, Training Loss: 0.4264551410329311\n",
      "Epoch 14/60, Validation Loss: 0.4691361028564538, Validation Accuracy: 0.7734734077478661\n",
      "Epoch 15/60, Training Loss: 0.4236335751754562\n",
      "Epoch 15/60, Validation Loss: 0.4401269145895049, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 16/60, Training Loss: 0.4220226960369139\n",
      "Epoch 16/60, Validation Loss: 0.4498865259079877, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 17/60, Training Loss: 0.421648319106637\n",
      "Epoch 17/60, Validation Loss: 0.43997006744380396, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 18/60, Training Loss: 0.41977153432963715\n",
      "Epoch 18/60, Validation Loss: 0.438778770336618, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 19/60, Training Loss: 0.4187024774816953\n",
      "Epoch 19/60, Validation Loss: 0.4394646802653817, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 20/60, Training Loss: 0.41822648719148686\n",
      "Epoch 20/60, Validation Loss: 0.47499976116988357, Validation Accuracy: 0.7655942219304005\n",
      "Epoch 21/60, Training Loss: 0.41650868785076256\n",
      "Epoch 21/60, Validation Loss: 0.4422538466556534, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 22/60, Training Loss: 0.4168480893210789\n",
      "Epoch 22/60, Validation Loss: 0.43946818147264227, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 23/60, Training Loss: 0.4145148585787595\n",
      "Epoch 23/60, Validation Loss: 0.4434867112931469, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 24/60, Training Loss: 0.41286472221372006\n",
      "Epoch 24/60, Validation Loss: 0.4384586178156406, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 25/60, Training Loss: 0.4103292938703158\n",
      "Epoch 25/60, Validation Loss: 0.44708994716522893, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 26/60, Training Loss: 0.41318423280448424\n",
      "Epoch 26/60, Validation Loss: 0.4405335794295628, Validation Accuracy: 0.793827971109652\n",
      "Epoch 27/60, Training Loss: 0.4105690101019823\n",
      "Epoch 27/60, Validation Loss: 0.44563931796251166, Validation Accuracy: 0.793827971109652\n",
      "Epoch 28/60, Training Loss: 0.41064262088984643\n",
      "Epoch 28/60, Validation Loss: 0.44266944870118696, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 29/60, Training Loss: 0.41155245898687465\n",
      "Epoch 29/60, Validation Loss: 0.4430181271352693, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 30/60, Training Loss: 0.4080566347202682\n",
      "Epoch 30/60, Validation Loss: 0.4627485962009243, Validation Accuracy: 0.7767564018384767\n",
      "Epoch 31/60, Training Loss: 0.4091395033802104\n",
      "Epoch 31/60, Validation Loss: 0.4396275134454847, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 32/60, Training Loss: 0.4073428976449754\n",
      "Epoch 32/60, Validation Loss: 0.44660090623881804, Validation Accuracy: 0.793827971109652\n",
      "Epoch 33/60, Training Loss: 0.406600393667778\n",
      "Epoch 33/60, Validation Loss: 0.4426835310201682, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 34/60, Training Loss: 0.40739768173477153\n",
      "Epoch 34/60, Validation Loss: 0.4410584489400474, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 35/60, Training Loss: 0.405969702206024\n",
      "Epoch 35/60, Validation Loss: 0.4418266609662178, Validation Accuracy: 0.793827971109652\n",
      "Epoch 36/60, Training Loss: 0.40555906841370065\n",
      "Epoch 36/60, Validation Loss: 0.44062883007042697, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 37/60, Training Loss: 0.40426971501331005\n",
      "Epoch 37/60, Validation Loss: 0.44069703992124626, Validation Accuracy: 0.799080761654629\n",
      "Epoch 38/60, Training Loss: 0.4043041026400612\n",
      "Epoch 38/60, Validation Loss: 0.47508231077479757, Validation Accuracy: 0.7669074195666448\n",
      "Epoch 39/60, Training Loss: 0.40471766526343944\n",
      "Epoch 39/60, Validation Loss: 0.45260517285522367, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 40/60, Training Loss: 0.4032806196100912\n",
      "Epoch 40/60, Validation Loss: 0.44056235889645773, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 41/60, Training Loss: 0.40262828888542695\n",
      "Epoch 41/60, Validation Loss: 0.44118248688846984, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 42/60, Training Loss: 0.4018256698986833\n",
      "Epoch 42/60, Validation Loss: 0.44020672214670953, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 43/60, Training Loss: 0.40169714222077935\n",
      "Epoch 43/60, Validation Loss: 0.4434962943976462, Validation Accuracy: 0.793827971109652\n",
      "Epoch 44/60, Training Loss: 0.40072915656614333\n",
      "Epoch 44/60, Validation Loss: 0.44029401389014033, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 45/60, Training Loss: 0.40019874825213214\n",
      "Epoch 45/60, Validation Loss: 0.44546666130891643, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 46/60, Training Loss: 0.39859171020566164\n",
      "Epoch 46/60, Validation Loss: 0.44318992234961524, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 47/60, Training Loss: 0.3969167084078698\n",
      "Epoch 47/60, Validation Loss: 0.45515936355628267, Validation Accuracy: 0.799080761654629\n",
      "Epoch 48/60, Training Loss: 0.39863010852785874\n",
      "Epoch 48/60, Validation Loss: 0.47083574771413006, Validation Accuracy: 0.7708470124753776\n",
      "Epoch 49/60, Training Loss: 0.39916957665498803\n",
      "Epoch 49/60, Validation Loss: 0.4428455653497998, Validation Accuracy: 0.799080761654629\n",
      "Epoch 50/60, Training Loss: 0.3995919100392678\n",
      "Epoch 50/60, Validation Loss: 0.44426499868874775, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 51/60, Training Loss: 0.39703406039576516\n",
      "Epoch 51/60, Validation Loss: 0.46956798206059097, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 52/60, Training Loss: 0.3967372692456552\n",
      "Epoch 52/60, Validation Loss: 0.4467669818647869, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 53/60, Training Loss: 0.3975908901992198\n",
      "Epoch 53/60, Validation Loss: 0.44228574713565294, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 54/60, Training Loss: 0.39585804009414094\n",
      "Epoch 54/60, Validation Loss: 0.45802074267055976, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 55/60, Training Loss: 0.3974205868665784\n",
      "Epoch 55/60, Validation Loss: 0.4420430583986624, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 56/60, Training Loss: 0.3970601621751241\n",
      "Epoch 56/60, Validation Loss: 0.4434659834073476, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 57/60, Training Loss: 0.3939425491109451\n",
      "Epoch 57/60, Validation Loss: 0.44654890364377287, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 58/60, Training Loss: 0.39404966020736637\n",
      "Epoch 58/60, Validation Loss: 0.4429246459682887, Validation Accuracy: 0.799080761654629\n",
      "Epoch 59/60, Training Loss: 0.39616480865454656\n",
      "Epoch 59/60, Validation Loss: 0.4426595548372618, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 60/60, Training Loss: 0.3946311219773815\n",
      "Epoch 60/60, Validation Loss: 0.446647917334946, Validation Accuracy: 0.793827971109652\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/60, Training Loss: 0.5383788679684867\n",
      "Epoch 1/60, Validation Loss: 0.4994135459992274, Validation Accuracy: 0.7774130006565988\n",
      "Epoch 2/60, Training Loss: 0.48189875570534096\n",
      "Epoch 2/60, Validation Loss: 0.47827288075423363, Validation Accuracy: 0.778069599474721\n",
      "Epoch 3/60, Training Loss: 0.46481215544142745\n",
      "Epoch 3/60, Validation Loss: 0.4757739635116143, Validation Accuracy: 0.7820091923834537\n",
      "Epoch 4/60, Training Loss: 0.454596008958779\n",
      "Epoch 4/60, Validation Loss: 0.47376730690919916, Validation Accuracy: 0.7813525935653316\n",
      "Epoch 5/60, Training Loss: 0.44807621393734076\n",
      "Epoch 5/60, Validation Loss: 0.46477035413549833, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 6/60, Training Loss: 0.4492491373200742\n",
      "Epoch 6/60, Validation Loss: 0.4650322824950618, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 7/60, Training Loss: 0.4415906298798057\n",
      "Epoch 7/60, Validation Loss: 0.4622955133465572, Validation Accuracy: 0.793827971109652\n",
      "Epoch 8/60, Training Loss: 0.4368303369613379\n",
      "Epoch 8/60, Validation Loss: 0.45629199660573333, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 9/60, Training Loss: 0.43261205725704277\n",
      "Epoch 9/60, Validation Loss: 0.45687991224658425, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 10/60, Training Loss: 0.4333283642008705\n",
      "Epoch 10/60, Validation Loss: 0.45742707206082595, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 11/60, Training Loss: 0.4303035595285611\n",
      "Epoch 11/60, Validation Loss: 0.4651709517259248, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 12/60, Training Loss: 0.4278228472615164\n",
      "Epoch 12/60, Validation Loss: 0.4514983718073805, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 13/60, Training Loss: 0.4266074546600577\n",
      "Epoch 13/60, Validation Loss: 0.4533787377334702, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 14/60, Training Loss: 0.4252473306194378\n",
      "Epoch 14/60, Validation Loss: 0.4501714445845619, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 15/60, Training Loss: 0.42278680062591245\n",
      "Epoch 15/60, Validation Loss: 0.4624026995054714, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 16/60, Training Loss: 0.4220508665550412\n",
      "Epoch 16/60, Validation Loss: 0.45547577428646113, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 17/60, Training Loss: 0.42064327858095096\n",
      "Epoch 17/60, Validation Loss: 0.45099618629167215, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 18/60, Training Loss: 0.4190540308147434\n",
      "Epoch 18/60, Validation Loss: 0.45080231009197486, Validation Accuracy: 0.799080761654629\n",
      "Epoch 19/60, Training Loss: 0.41792268624768797\n",
      "Epoch 19/60, Validation Loss: 0.4635582555534016, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 20/60, Training Loss: 0.4157643645434711\n",
      "Epoch 20/60, Validation Loss: 0.4661051349529109, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 21/60, Training Loss: 0.4151549927909856\n",
      "Epoch 21/60, Validation Loss: 0.44982464931398164, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 22/60, Training Loss: 0.4126688427294255\n",
      "Epoch 22/60, Validation Loss: 0.4468013246529077, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 23/60, Training Loss: 0.41373252072750427\n",
      "Epoch 23/60, Validation Loss: 0.47204051203830705, Validation Accuracy: 0.778069599474721\n",
      "Epoch 24/60, Training Loss: 0.41084989020478696\n",
      "Epoch 24/60, Validation Loss: 0.45294274108884225, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 25/60, Training Loss: 0.4106114347687778\n",
      "Epoch 25/60, Validation Loss: 0.45452585674003154, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 26/60, Training Loss: 0.41014422822420993\n",
      "Epoch 26/60, Validation Loss: 0.45825558364469343, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 27/60, Training Loss: 0.40898900811518896\n",
      "Epoch 27/60, Validation Loss: 0.45670321780739653, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 28/60, Training Loss: 0.4087527764770459\n",
      "Epoch 28/60, Validation Loss: 0.4569257105754308, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 29/60, Training Loss: 0.4093358694451062\n",
      "Epoch 29/60, Validation Loss: 0.4487502393727215, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 30/60, Training Loss: 0.4085473192958381\n",
      "Epoch 30/60, Validation Loss: 0.4506649121798146, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 31/60, Training Loss: 0.40691489090756794\n",
      "Epoch 31/60, Validation Loss: 0.44759561142918325, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 32/60, Training Loss: 0.4067097995381343\n",
      "Epoch 32/60, Validation Loss: 0.4508316695924205, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 33/60, Training Loss: 0.4045456070012934\n",
      "Epoch 33/60, Validation Loss: 0.45208142557381337, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 34/60, Training Loss: 0.4038315213278053\n",
      "Epoch 34/60, Validation Loss: 0.46724744156705145, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 35/60, Training Loss: 0.4051693887926462\n",
      "Epoch 35/60, Validation Loss: 0.45315605195248937, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 36/60, Training Loss: 0.4032854931600138\n",
      "Epoch 36/60, Validation Loss: 0.45731536431618386, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 37/60, Training Loss: 0.4020250327787374\n",
      "Epoch 37/60, Validation Loss: 0.44891962939532015, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 38/60, Training Loss: 0.4009099041901314\n",
      "Epoch 38/60, Validation Loss: 0.4480062471556414, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 39/60, Training Loss: 0.4016504373152073\n",
      "Epoch 39/60, Validation Loss: 0.4532702123034375, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 40/60, Training Loss: 0.4027480205076104\n",
      "Epoch 40/60, Validation Loss: 0.4624861212379021, Validation Accuracy: 0.793827971109652\n",
      "Epoch 41/60, Training Loss: 0.39837780098120373\n",
      "Epoch 41/60, Validation Loss: 0.46237501209474985, Validation Accuracy: 0.7879185817465528\n",
      "Epoch 42/60, Training Loss: 0.40104818435537376\n",
      "Epoch 42/60, Validation Loss: 0.4641454049742035, Validation Accuracy: 0.783322390019698\n",
      "Epoch 43/60, Training Loss: 0.3995881851547425\n",
      "Epoch 43/60, Validation Loss: 0.4581654899953548, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 44/60, Training Loss: 0.3996145995602677\n",
      "Epoch 44/60, Validation Loss: 0.4560007341206074, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 45/60, Training Loss: 0.3980034383752058\n",
      "Epoch 45/60, Validation Loss: 0.4494395991738554, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 46/60, Training Loss: 0.398316275553284\n",
      "Epoch 46/60, Validation Loss: 0.45588446862956616, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 47/60, Training Loss: 0.3984485140309872\n",
      "Epoch 47/60, Validation Loss: 0.45205539761413455, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 48/60, Training Loss: 0.3962566069574181\n",
      "Epoch 48/60, Validation Loss: 0.45040271255670417, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 49/60, Training Loss: 0.39483175654541164\n",
      "Epoch 49/60, Validation Loss: 0.45145221536306185, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 50/60, Training Loss: 0.39574214338943403\n",
      "Epoch 50/60, Validation Loss: 0.44917138972129494, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 51/60, Training Loss: 0.397426561274006\n",
      "Epoch 51/60, Validation Loss: 0.4548768174312814, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 52/60, Training Loss: 0.3959490329496504\n",
      "Epoch 52/60, Validation Loss: 0.44959731723781654, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 53/60, Training Loss: 0.39598208112920835\n",
      "Epoch 53/60, Validation Loss: 0.4478539913424647, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 54/60, Training Loss: 0.3944004047515355\n",
      "Epoch 54/60, Validation Loss: 0.45038234167464114, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 55/60, Training Loss: 0.3952960310371842\n",
      "Epoch 55/60, Validation Loss: 0.45524073111293206, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 56/60, Training Loss: 0.3951801890580673\n",
      "Epoch 56/60, Validation Loss: 0.4730103625696523, Validation Accuracy: 0.7767564018384767\n",
      "Epoch 57/60, Training Loss: 0.3917907254814398\n",
      "Epoch 57/60, Validation Loss: 0.45106506852813416, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 58/60, Training Loss: 0.39472159707620547\n",
      "Epoch 58/60, Validation Loss: 0.4504908085532525, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 59/60, Training Loss: 0.39060702173924194\n",
      "Epoch 59/60, Validation Loss: 0.4576439297519117, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 60/60, Training Loss: 0.3924815020477521\n",
      "Epoch 60/60, Validation Loss: 0.4501357292902719, Validation Accuracy: 0.8010505581089954\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/60, Training Loss: 0.5383831894421202\n",
      "Epoch 1/60, Validation Loss: 0.4865400561799554, Validation Accuracy: 0.7674113009198423\n",
      "Epoch 2/60, Training Loss: 0.48071788020647105\n",
      "Epoch 2/60, Validation Loss: 0.4694353839801868, Validation Accuracy: 0.7779237844940867\n",
      "Epoch 3/60, Training Loss: 0.4691134772881905\n",
      "Epoch 3/60, Validation Loss: 0.45871473310505534, Validation Accuracy: 0.7884362680683311\n",
      "Epoch 4/60, Training Loss: 0.4583598521692077\n",
      "Epoch 4/60, Validation Loss: 0.454041616805873, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 5/60, Training Loss: 0.4536732320534432\n",
      "Epoch 5/60, Validation Loss: 0.4549864550457575, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 6/60, Training Loss: 0.44739954519694247\n",
      "Epoch 6/60, Validation Loss: 0.4466953755439264, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 7/60, Training Loss: 0.4441047087213968\n",
      "Epoch 7/60, Validation Loss: 0.4461643583097383, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 8/60, Training Loss: 0.4421206506609604\n",
      "Epoch 8/60, Validation Loss: 0.44473905826270266, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 9/60, Training Loss: 0.43954268781336275\n",
      "Epoch 9/60, Validation Loss: 0.4432405517558465, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 10/60, Training Loss: 0.4340922410387223\n",
      "Epoch 10/60, Validation Loss: 0.44876509661059727, Validation Accuracy: 0.7864651773981604\n",
      "Epoch 11/60, Training Loss: 0.43324011195636797\n",
      "Epoch 11/60, Validation Loss: 0.4444738955319864, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 12/60, Training Loss: 0.43073325239493465\n",
      "Epoch 12/60, Validation Loss: 0.4451680726015755, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 13/60, Training Loss: 0.42994925918502447\n",
      "Epoch 13/60, Validation Loss: 0.4449128798009213, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 14/60, Training Loss: 0.42747423518204625\n",
      "Epoch 14/60, Validation Loss: 0.4455045123062833, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 15/60, Training Loss: 0.42722543451221284\n",
      "Epoch 15/60, Validation Loss: 0.44196821205044917, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 16/60, Training Loss: 0.4255334120097123\n",
      "Epoch 16/60, Validation Loss: 0.4535081768067095, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 17/60, Training Loss: 0.4229760814624352\n",
      "Epoch 17/60, Validation Loss: 0.44926770298658864, Validation Accuracy: 0.7923784494086727\n",
      "Epoch 18/60, Training Loss: 0.4238948206419707\n",
      "Epoch 18/60, Validation Loss: 0.4418370094910966, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 19/60, Training Loss: 0.42076437172340597\n",
      "Epoch 19/60, Validation Loss: 0.4527502426614312, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 20/60, Training Loss: 0.42247160291421443\n",
      "Epoch 20/60, Validation Loss: 0.4437114770538832, Validation Accuracy: 0.7943495400788436\n",
      "Epoch 21/60, Training Loss: 0.41996013252871245\n",
      "Epoch 21/60, Validation Loss: 0.43730048456897286, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 22/60, Training Loss: 0.42082682912900377\n",
      "Epoch 22/60, Validation Loss: 0.4382689201433933, Validation Accuracy: 0.804862023653088\n",
      "Epoch 23/60, Training Loss: 0.4173660751461513\n",
      "Epoch 23/60, Validation Loss: 0.45681693397111295, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 24/60, Training Loss: 0.415277040717522\n",
      "Epoch 24/60, Validation Loss: 0.4387897040246357, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 25/60, Training Loss: 0.41304082393137803\n",
      "Epoch 25/60, Validation Loss: 0.4387564978206345, Validation Accuracy: 0.804862023653088\n",
      "Epoch 26/60, Training Loss: 0.4116882198341093\n",
      "Epoch 26/60, Validation Loss: 0.4489797810921494, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 27/60, Training Loss: 0.41507473054618194\n",
      "Epoch 27/60, Validation Loss: 0.4374399041825252, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 28/60, Training Loss: 0.41321381322276873\n",
      "Epoch 28/60, Validation Loss: 0.43744674683865453, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 29/60, Training Loss: 0.41073405167718574\n",
      "Epoch 29/60, Validation Loss: 0.43726427256280836, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 30/60, Training Loss: 0.41515377811168436\n",
      "Epoch 30/60, Validation Loss: 0.4655757424328964, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 31/60, Training Loss: 0.4088584257587986\n",
      "Epoch 31/60, Validation Loss: 0.43600133431987614, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 32/60, Training Loss: 0.4105761905354778\n",
      "Epoch 32/60, Validation Loss: 0.4366029288366203, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 33/60, Training Loss: 0.40958223755415185\n",
      "Epoch 33/60, Validation Loss: 0.4385945505184653, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 34/60, Training Loss: 0.40891825647785124\n",
      "Epoch 34/60, Validation Loss: 0.4345609173763797, Validation Accuracy: 0.812089356110381\n",
      "Epoch 35/60, Training Loss: 0.40635772295824185\n",
      "Epoch 35/60, Validation Loss: 0.4570919340037551, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 36/60, Training Loss: 0.40750981096833394\n",
      "Epoch 36/60, Validation Loss: 0.43683735324138123, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 37/60, Training Loss: 0.40590369380678093\n",
      "Epoch 37/60, Validation Loss: 0.43751462833731586, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 38/60, Training Loss: 0.4048583027063392\n",
      "Epoch 38/60, Validation Loss: 0.4348790360448872, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 39/60, Training Loss: 0.4059707293399363\n",
      "Epoch 39/60, Validation Loss: 0.43758151990346883, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 40/60, Training Loss: 0.40462787951931867\n",
      "Epoch 40/60, Validation Loss: 0.4356715708034825, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 41/60, Training Loss: 0.4061484983547779\n",
      "Epoch 41/60, Validation Loss: 0.43644256969787065, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 42/60, Training Loss: 0.40548412363946906\n",
      "Epoch 42/60, Validation Loss: 0.43770597393366056, Validation Accuracy: 0.80946123521682\n",
      "Epoch 43/60, Training Loss: 0.4024811325805003\n",
      "Epoch 43/60, Validation Loss: 0.4501696483705056, Validation Accuracy: 0.7871222076215506\n",
      "Epoch 44/60, Training Loss: 0.4033892570635465\n",
      "Epoch 44/60, Validation Loss: 0.45424057395046297, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 45/60, Training Loss: 0.4030975197537208\n",
      "Epoch 45/60, Validation Loss: 0.4373435773618558, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 46/60, Training Loss: 0.4016826393038738\n",
      "Epoch 46/60, Validation Loss: 0.4436603909777721, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 47/60, Training Loss: 0.40229056372730126\n",
      "Epoch 47/60, Validation Loss: 0.44610876796757365, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 48/60, Training Loss: 0.401331263968325\n",
      "Epoch 48/60, Validation Loss: 0.43629071389505375, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 49/60, Training Loss: 0.40114079926681173\n",
      "Epoch 49/60, Validation Loss: 0.443745181257032, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 50/60, Training Loss: 0.3988583464654568\n",
      "Epoch 50/60, Validation Loss: 0.43819948956760435, Validation Accuracy: 0.80946123521682\n",
      "Epoch 51/60, Training Loss: 0.4021843600910636\n",
      "Epoch 51/60, Validation Loss: 0.4433797764060385, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 52/60, Training Loss: 0.4005306039465068\n",
      "Epoch 52/60, Validation Loss: 0.4402478656863199, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 53/60, Training Loss: 0.3985791219950817\n",
      "Epoch 53/60, Validation Loss: 0.4377540154528867, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 54/60, Training Loss: 0.3990563365222588\n",
      "Epoch 54/60, Validation Loss: 0.43766147585790505, Validation Accuracy: 0.80946123521682\n",
      "Epoch 55/60, Training Loss: 0.39806604824393127\n",
      "Epoch 55/60, Validation Loss: 0.43956800832057186, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 56/60, Training Loss: 0.3978011228554831\n",
      "Epoch 56/60, Validation Loss: 0.4447013542095092, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 57/60, Training Loss: 0.39819338861510667\n",
      "Epoch 57/60, Validation Loss: 0.4390459317440918, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 58/60, Training Loss: 0.39669280333488477\n",
      "Epoch 58/60, Validation Loss: 0.4354081096527464, Validation Accuracy: 0.8153745072273325\n",
      "Epoch 59/60, Training Loss: 0.3970625182843506\n",
      "Epoch 59/60, Validation Loss: 0.4376818646935268, Validation Accuracy: 0.812089356110381\n",
      "Epoch 60/60, Training Loss: 0.3979397247156759\n",
      "Epoch 60/60, Validation Loss: 0.43669417685785217, Validation Accuracy: 0.8074901445466491\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/60, Training Loss: 0.5410396796198967\n",
      "Epoch 1/60, Validation Loss: 0.48935723304748535, Validation Accuracy: 0.7818659658344284\n",
      "Epoch 2/60, Training Loss: 0.48131052540551644\n",
      "Epoch 2/60, Validation Loss: 0.46919401820885576, Validation Accuracy: 0.7943495400788436\n",
      "Epoch 3/60, Training Loss: 0.4645982867502791\n",
      "Epoch 3/60, Validation Loss: 0.46964064548621004, Validation Accuracy: 0.7871222076215506\n",
      "Epoch 4/60, Training Loss: 0.4531863355261134\n",
      "Epoch 4/60, Validation Loss: 0.4636552809342664, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 5/60, Training Loss: 0.4516067261810065\n",
      "Epoch 5/60, Validation Loss: 0.46351637149044356, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 6/60, Training Loss: 0.4464831377949145\n",
      "Epoch 6/60, Validation Loss: 0.4609199130020217, Validation Accuracy: 0.797634691195795\n",
      "Epoch 7/60, Training Loss: 0.44074753999436306\n",
      "Epoch 7/60, Validation Loss: 0.4626143102324446, Validation Accuracy: 0.7923784494086727\n",
      "Epoch 8/60, Training Loss: 0.4372956162206144\n",
      "Epoch 8/60, Validation Loss: 0.4699140216433565, Validation Accuracy: 0.7877792378449409\n",
      "Epoch 9/60, Training Loss: 0.4341853495266807\n",
      "Epoch 9/60, Validation Loss: 0.4652829342643628, Validation Accuracy: 0.7884362680683311\n",
      "Epoch 10/60, Training Loss: 0.4332572598293854\n",
      "Epoch 10/60, Validation Loss: 0.45293862895347686, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 11/60, Training Loss: 0.4287091008145509\n",
      "Epoch 11/60, Validation Loss: 0.45008476963998134, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 12/60, Training Loss: 0.4272524861428212\n",
      "Epoch 12/60, Validation Loss: 0.45403258459574264, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 13/60, Training Loss: 0.42577519274641834\n",
      "Epoch 13/60, Validation Loss: 0.45350435820861634, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 14/60, Training Loss: 0.42479384674878884\n",
      "Epoch 14/60, Validation Loss: 0.4517647000663568, Validation Accuracy: 0.804862023653088\n",
      "Epoch 15/60, Training Loss: 0.42250083313565556\n",
      "Epoch 15/60, Validation Loss: 0.45043026644209916, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 16/60, Training Loss: 0.4219282050849259\n",
      "Epoch 16/60, Validation Loss: 0.46014455760492706, Validation Accuracy: 0.7950065703022339\n",
      "Epoch 17/60, Training Loss: 0.4204796761802332\n",
      "Epoch 17/60, Validation Loss: 0.451461558761709, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 18/60, Training Loss: 0.41728621542336436\n",
      "Epoch 18/60, Validation Loss: 0.45153602146353394, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 19/60, Training Loss: 0.4168794729558658\n",
      "Epoch 19/60, Validation Loss: 0.44855689292490797, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 20/60, Training Loss: 0.4162352400736546\n",
      "Epoch 20/60, Validation Loss: 0.4506328669596093, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 21/60, Training Loss: 0.4150408265569548\n",
      "Epoch 21/60, Validation Loss: 0.4497271785561327, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 22/60, Training Loss: 0.4127127089466792\n",
      "Epoch 22/60, Validation Loss: 0.45165870186546087, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 23/60, Training Loss: 0.4122737704671118\n",
      "Epoch 23/60, Validation Loss: 0.4605021736735761, Validation Accuracy: 0.7943495400788436\n",
      "Epoch 24/60, Training Loss: 0.4107467947317546\n",
      "Epoch 24/60, Validation Loss: 0.4592276497388073, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 25/60, Training Loss: 0.41045742996252116\n",
      "Epoch 25/60, Validation Loss: 0.4500428092573326, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 26/60, Training Loss: 0.4091436884651973\n",
      "Epoch 26/60, Validation Loss: 0.45951810163197093, Validation Accuracy: 0.7950065703022339\n",
      "Epoch 27/60, Training Loss: 0.40828418320049764\n",
      "Epoch 27/60, Validation Loss: 0.4520960151369035, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 28/60, Training Loss: 0.4087584558581039\n",
      "Epoch 28/60, Validation Loss: 0.45236658882252206, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 29/60, Training Loss: 0.40702876096635354\n",
      "Epoch 29/60, Validation Loss: 0.45709258052691115, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 30/60, Training Loss: 0.4065000162389022\n",
      "Epoch 30/60, Validation Loss: 0.4527270653485004, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 31/60, Training Loss: 0.40505759662452334\n",
      "Epoch 31/60, Validation Loss: 0.453436861156013, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 32/60, Training Loss: 0.405476561451717\n",
      "Epoch 32/60, Validation Loss: 0.45021215830173794, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 33/60, Training Loss: 0.403260458016333\n",
      "Epoch 33/60, Validation Loss: 0.4598087477668418, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 34/60, Training Loss: 0.40338068313192665\n",
      "Epoch 34/60, Validation Loss: 0.47442910480873746, Validation Accuracy: 0.7884362680683311\n",
      "Epoch 35/60, Training Loss: 0.40342375334948694\n",
      "Epoch 35/60, Validation Loss: 0.4545776489439435, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 36/60, Training Loss: 0.4026895335379235\n",
      "Epoch 36/60, Validation Loss: 0.46468283805547583, Validation Accuracy: 0.7838370565045992\n",
      "Epoch 37/60, Training Loss: 0.40486901182084883\n",
      "Epoch 37/60, Validation Loss: 0.4565988875223392, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 38/60, Training Loss: 0.40094938889888954\n",
      "Epoch 38/60, Validation Loss: 0.4517778991794711, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 39/60, Training Loss: 0.4009047197837999\n",
      "Epoch 39/60, Validation Loss: 0.45364585120952566, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 40/60, Training Loss: 0.39924085756221156\n",
      "Epoch 40/60, Validation Loss: 0.45689574313101344, Validation Accuracy: 0.7917214191852825\n",
      "Epoch 41/60, Training Loss: 0.3994723750654794\n",
      "Epoch 41/60, Validation Loss: 0.44968413011565883, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 42/60, Training Loss: 0.39895098934590506\n",
      "Epoch 42/60, Validation Loss: 0.4612535730940509, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 43/60, Training Loss: 0.39781512109821865\n",
      "Epoch 43/60, Validation Loss: 0.4684147841994363, Validation Accuracy: 0.7838370565045992\n",
      "Epoch 44/60, Training Loss: 0.39708584320201024\n",
      "Epoch 44/60, Validation Loss: 0.4552709357081596, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 45/60, Training Loss: 0.39774400110691394\n",
      "Epoch 45/60, Validation Loss: 0.45253854198137505, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 46/60, Training Loss: 0.3997324391945297\n",
      "Epoch 46/60, Validation Loss: 0.4548766954524043, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 47/60, Training Loss: 0.3946349411479288\n",
      "Epoch 47/60, Validation Loss: 0.4663295343479249, Validation Accuracy: 0.7864651773981604\n",
      "Epoch 48/60, Training Loss: 0.39669854395345755\n",
      "Epoch 48/60, Validation Loss: 0.4594173540424614, Validation Accuracy: 0.7910643889618922\n",
      "Epoch 49/60, Training Loss: 0.3947909327316785\n",
      "Epoch 49/60, Validation Loss: 0.45705113370771183, Validation Accuracy: 0.7956636005256241\n",
      "Epoch 50/60, Training Loss: 0.39585263634056556\n",
      "Epoch 50/60, Validation Loss: 0.45183148769496, Validation Accuracy: 0.7956636005256241\n",
      "Epoch 51/60, Training Loss: 0.3949607515859166\n",
      "Epoch 51/60, Validation Loss: 0.4577154221100957, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 52/60, Training Loss: 0.39434752690549596\n",
      "Epoch 52/60, Validation Loss: 0.4637413564581834, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 53/60, Training Loss: 0.3939809462158229\n",
      "Epoch 53/60, Validation Loss: 0.452690390002041, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 54/60, Training Loss: 0.3934287286346431\n",
      "Epoch 54/60, Validation Loss: 0.4589369259774685, Validation Accuracy: 0.7917214191852825\n",
      "Epoch 55/60, Training Loss: 0.3929425612180017\n",
      "Epoch 55/60, Validation Loss: 0.45790145296544926, Validation Accuracy: 0.7950065703022339\n",
      "Epoch 56/60, Training Loss: 0.3919824711841548\n",
      "Epoch 56/60, Validation Loss: 0.4556986228489751, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 57/60, Training Loss: 0.39125073977851177\n",
      "Epoch 57/60, Validation Loss: 0.4545577056315869, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 58/60, Training Loss: 0.39192875452202763\n",
      "Epoch 58/60, Validation Loss: 0.46059686179560516, Validation Accuracy: 0.7917214191852825\n",
      "Epoch 59/60, Training Loss: 0.3936705062522741\n",
      "Epoch 59/60, Validation Loss: 0.46344645422790687, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 60/60, Training Loss: 0.3900236056584699\n",
      "Epoch 60/60, Validation Loss: 0.4618310682592592, Validation Accuracy: 0.7930354796320631\n",
      "Average Validation Accuracy: 0.7999475411193931\n",
      "Number of Epochs: 60\n"
     ]
    }
   ],
   "source": [
    "epochs = [10, 20, 30, 40, 50, 60]\n",
    "average_val_accuracy_dict = {}\n",
    "for num_epoch in epochs:\n",
    "    val_accuracies = []\n",
    "    for train_idx, val_idx in skf.split(combined_features, labels):\n",
    "        # Create TensorDatasets for the current fold\n",
    "        train_dataset = TensorDataset(torch.tensor(combined_features[train_idx]), torch.tensor(labels_numpy[train_idx].reshape(-1,1), dtype=torch.float32))\n",
    "        val_dataset = TensorDataset(torch.tensor(combined_features[val_idx]), torch.tensor(labels_numpy[val_idx].reshape(-1,1), dtype=torch.float32))\n",
    "\n",
    "        # Create DataLoaders for the current fold\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "        # Train and validate your model for the current fold\n",
    "        # Train and validate your model for the current fold and store the validation accuracy\n",
    "        val_accuracy = train_and_validate(train_dataloader, val_dataloader, len(val_dataset), num_epoch)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Calculate the average validation accuracy across all folds\n",
    "    average_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "    average_val_accuracy_dict[num_epoch] = average_val_accuracy\n",
    "    print(f'Average Validation Accuracy: {average_val_accuracy}')\n",
    "    print(f'Number of Epochs: {num_epoch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the average_val_accuracy_dict dictionary, plot a graph with number of epochs on x-axis and average validation accuracy on y-axis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the keys and values as separate lists\n",
    "keys = list(average_val_accuracy_dict.keys())\n",
    "values = list(average_val_accuracy_dict.values())\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(keys, values)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.title('Scatter plot of  validation accuracy vs epochs')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this graph, we can see that `epoch = 40` is the optimal parameter as it will give us a higher validation accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performed with CombinedModelMoreHLs 2 layers\n",
    "- With the optimal epoch size, we can also explore if having more hidden layers will help with the final average validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.5560178285625976\n",
      "Epoch 1/40, Validation Loss: 0.4858637933487667, Validation Accuracy: 0.7728168089297439\n",
      "Epoch 2/40, Training Loss: 0.503550732386081\n",
      "Epoch 2/40, Validation Loss: 0.4899200462389991, Validation Accuracy: 0.7649376231122784\n",
      "Epoch 3/40, Training Loss: 0.48799195924768923\n",
      "Epoch 3/40, Validation Loss: 0.46860000268795104, Validation Accuracy: 0.7793827971109653\n",
      "Epoch 4/40, Training Loss: 0.47601003148971893\n",
      "Epoch 4/40, Validation Loss: 0.4595032822711305, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 5/40, Training Loss: 0.4778352170263532\n",
      "Epoch 5/40, Validation Loss: 0.4828306177133665, Validation Accuracy: 0.7754432042022325\n",
      "Epoch 6/40, Training Loss: 0.4717351252169121\n",
      "Epoch 6/40, Validation Loss: 0.4849641940590599, Validation Accuracy: 0.7708470124753776\n",
      "Epoch 7/40, Training Loss: 0.4613897866249241\n",
      "Epoch 7/40, Validation Loss: 0.45244472325628343, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 8/40, Training Loss: 0.45980148675443305\n",
      "Epoch 8/40, Validation Loss: 0.45301035891106617, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 9/40, Training Loss: 0.45864765458493406\n",
      "Epoch 9/40, Validation Loss: 0.4543173479706205, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 10/40, Training Loss: 0.45222607150849864\n",
      "Epoch 10/40, Validation Loss: 0.4670581071398645, Validation Accuracy: 0.7879185817465528\n",
      "Epoch 11/40, Training Loss: 0.44627026065675607\n",
      "Epoch 11/40, Validation Loss: 0.45215550576048996, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 12/40, Training Loss: 0.4453453949048841\n",
      "Epoch 12/40, Validation Loss: 0.45043837573593826, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 13/40, Training Loss: 0.44367857818587086\n",
      "Epoch 13/40, Validation Loss: 0.46833780437161787, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 14/40, Training Loss: 0.4448172899544865\n",
      "Epoch 14/40, Validation Loss: 0.473605782729793, Validation Accuracy: 0.7839789888378201\n",
      "Epoch 15/40, Training Loss: 0.4391048971632021\n",
      "Epoch 15/40, Validation Loss: 0.45130342424539993, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 16/40, Training Loss: 0.44261897267319084\n",
      "Epoch 16/40, Validation Loss: 0.46062485210558507, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 17/40, Training Loss: 0.43044964651872947\n",
      "Epoch 17/40, Validation Loss: 0.4543209795240332, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 18/40, Training Loss: 0.4305867085091555\n",
      "Epoch 18/40, Validation Loss: 0.4676107739473825, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 19/40, Training Loss: 0.4265689340534955\n",
      "Epoch 19/40, Validation Loss: 0.4473615182436886, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 20/40, Training Loss: 0.4257189660697315\n",
      "Epoch 20/40, Validation Loss: 0.4550934167900635, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 21/40, Training Loss: 0.421999723696959\n",
      "Epoch 21/40, Validation Loss: 0.45150318636476056, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 22/40, Training Loss: 0.4240306287495483\n",
      "Epoch 22/40, Validation Loss: 0.45585135027220114, Validation Accuracy: 0.793827971109652\n",
      "Epoch 23/40, Training Loss: 0.4165920746559155\n",
      "Epoch 23/40, Validation Loss: 0.46854462400468855, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 24/40, Training Loss: 0.4216733871032716\n",
      "Epoch 24/40, Validation Loss: 0.44866051973472715, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 25/40, Training Loss: 0.41402993348287787\n",
      "Epoch 25/40, Validation Loss: 0.4698828537582727, Validation Accuracy: 0.788575180564675\n",
      "Epoch 26/40, Training Loss: 0.4257005134553421\n",
      "Epoch 26/40, Validation Loss: 0.457390746384547, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 27/40, Training Loss: 0.41683337001467313\n",
      "Epoch 27/40, Validation Loss: 0.45175360069068937, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 28/40, Training Loss: 0.41118022541850413\n",
      "Epoch 28/40, Validation Loss: 0.45959344594032353, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 29/40, Training Loss: 0.40669203829264705\n",
      "Epoch 29/40, Validation Loss: 0.46444467242553594, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 30/40, Training Loss: 0.40666972841881704\n",
      "Epoch 30/40, Validation Loss: 0.45838549875542134, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 31/40, Training Loss: 0.40856052577749796\n",
      "Epoch 31/40, Validation Loss: 0.4638082950488123, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 32/40, Training Loss: 0.4099980043809558\n",
      "Epoch 32/40, Validation Loss: 0.454970942839434, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 33/40, Training Loss: 0.4030205205992216\n",
      "Epoch 33/40, Validation Loss: 0.4651476152787346, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 34/40, Training Loss: 0.40009555789664036\n",
      "Epoch 34/40, Validation Loss: 0.45522425202799094, Validation Accuracy: 0.799080761654629\n",
      "Epoch 35/40, Training Loss: 0.40012047893986147\n",
      "Epoch 35/40, Validation Loss: 0.4579225018893549, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 36/40, Training Loss: 0.40089288102633996\n",
      "Epoch 36/40, Validation Loss: 0.4712977395319814, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 37/40, Training Loss: 0.39547209078421586\n",
      "Epoch 37/40, Validation Loss: 0.46442412015499246, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 38/40, Training Loss: 0.39430947736726973\n",
      "Epoch 38/40, Validation Loss: 0.466413146518756, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 39/40, Training Loss: 0.3906840442770266\n",
      "Epoch 39/40, Validation Loss: 0.4915830583082444, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 40/40, Training Loss: 0.3931954934058853\n",
      "Epoch 40/40, Validation Loss: 0.4723634709706481, Validation Accuracy: 0.8023637557452397\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.5678772024927646\n",
      "Epoch 1/40, Validation Loss: 0.4845444286212871, Validation Accuracy: 0.7800393959290873\n",
      "Epoch 2/40, Training Loss: 0.510519584743526\n",
      "Epoch 2/40, Validation Loss: 0.5312841424611227, Validation Accuracy: 0.726854891661195\n",
      "Epoch 3/40, Training Loss: 0.4967017731582868\n",
      "Epoch 3/40, Validation Loss: 0.4538369110117408, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 4/40, Training Loss: 0.4766648812341721\n",
      "Epoch 4/40, Validation Loss: 0.4425053484542832, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 5/40, Training Loss: 0.4798148794544572\n",
      "Epoch 5/40, Validation Loss: 0.44434565645081836, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 6/40, Training Loss: 0.47059355608708275\n",
      "Epoch 6/40, Validation Loss: 0.4460039918959453, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 7/40, Training Loss: 0.4676639427213375\n",
      "Epoch 7/40, Validation Loss: 0.4442271409234451, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 8/40, Training Loss: 0.45604720379267466\n",
      "Epoch 8/40, Validation Loss: 0.45585101008103157, Validation Accuracy: 0.7806959947472094\n",
      "Epoch 9/40, Training Loss: 0.46102664053557424\n",
      "Epoch 9/40, Validation Loss: 0.4523233806358465, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 10/40, Training Loss: 0.45939900090531727\n",
      "Epoch 10/40, Validation Loss: 0.444446278979797, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 11/40, Training Loss: 0.45213470319554877\n",
      "Epoch 11/40, Validation Loss: 0.43808764648375087, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 12/40, Training Loss: 0.44835172225464515\n",
      "Epoch 12/40, Validation Loss: 0.4470993272974814, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 13/40, Training Loss: 0.4493511629796873\n",
      "Epoch 13/40, Validation Loss: 0.4446309215501341, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 14/40, Training Loss: 0.4405703050209077\n",
      "Epoch 14/40, Validation Loss: 0.44637076488418104, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 15/40, Training Loss: 0.44085117702291704\n",
      "Epoch 15/40, Validation Loss: 0.4377505427753036, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 16/40, Training Loss: 0.4365174787955021\n",
      "Epoch 16/40, Validation Loss: 0.4405777591392788, Validation Accuracy: 0.793827971109652\n",
      "Epoch 17/40, Training Loss: 0.44188978845678917\n",
      "Epoch 17/40, Validation Loss: 0.4626849301705498, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 18/40, Training Loss: 0.43942605557404163\n",
      "Epoch 18/40, Validation Loss: 0.4406767284000263, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 19/40, Training Loss: 0.43725669068184114\n",
      "Epoch 19/40, Validation Loss: 0.4421963474337811, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 20/40, Training Loss: 0.43395916026408277\n",
      "Epoch 20/40, Validation Loss: 0.43983792799832155, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 21/40, Training Loss: 0.4264696855146897\n",
      "Epoch 21/40, Validation Loss: 0.44232009735485023, Validation Accuracy: 0.804333552199606\n",
      "Epoch 22/40, Training Loss: 0.4303687047359981\n",
      "Epoch 22/40, Validation Loss: 0.4377408771439216, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 23/40, Training Loss: 0.4254880073355643\n",
      "Epoch 23/40, Validation Loss: 0.44081741119905604, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 24/40, Training Loss: 0.430307341749313\n",
      "Epoch 24/40, Validation Loss: 0.43903304923189246, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 25/40, Training Loss: 0.41970752285954754\n",
      "Epoch 25/40, Validation Loss: 0.4403818842335677, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 26/40, Training Loss: 0.4229199156126012\n",
      "Epoch 26/40, Validation Loss: 0.4414803279241966, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 27/40, Training Loss: 0.41802565244043594\n",
      "Epoch 27/40, Validation Loss: 0.43385425184643706, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 28/40, Training Loss: 0.41784929349869393\n",
      "Epoch 28/40, Validation Loss: 0.4845563068654369, Validation Accuracy: 0.7747866053841103\n",
      "Epoch 29/40, Training Loss: 0.4127047249015782\n",
      "Epoch 29/40, Validation Loss: 0.4436149959652368, Validation Accuracy: 0.799080761654629\n",
      "Epoch 30/40, Training Loss: 0.4179726548717795\n",
      "Epoch 30/40, Validation Loss: 0.4400653553424471, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 31/40, Training Loss: 0.40995332247668054\n",
      "Epoch 31/40, Validation Loss: 0.4357034399890931, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 32/40, Training Loss: 0.41029187916653365\n",
      "Epoch 32/40, Validation Loss: 0.438565919312273, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 33/40, Training Loss: 0.41062331266134117\n",
      "Epoch 33/40, Validation Loss: 0.4390964902722867, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 34/40, Training Loss: 0.40670771331690114\n",
      "Epoch 34/40, Validation Loss: 0.45022163573281926, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 35/40, Training Loss: 0.40922305667944\n",
      "Epoch 35/40, Validation Loss: 0.44213525039090223, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 36/40, Training Loss: 0.40489349738643393\n",
      "Epoch 36/40, Validation Loss: 0.4429479445579476, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 37/40, Training Loss: 0.4019403520218656\n",
      "Epoch 37/40, Validation Loss: 0.44293419541352236, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 38/40, Training Loss: 0.4015493046326118\n",
      "Epoch 38/40, Validation Loss: 0.44299601069627165, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 39/40, Training Loss: 0.40126525595041085\n",
      "Epoch 39/40, Validation Loss: 0.4466666702512671, Validation Accuracy: 0.793827971109652\n",
      "Epoch 40/40, Training Loss: 0.3942657574434371\n",
      "Epoch 40/40, Validation Loss: 0.4498500654386132, Validation Accuracy: 0.8030203545633617\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.5668197323878607\n",
      "Epoch 1/40, Validation Loss: 0.4972385068994542, Validation Accuracy: 0.7557452396585687\n",
      "Epoch 2/40, Training Loss: 0.5042730287460517\n",
      "Epoch 2/40, Validation Loss: 0.510504093957353, Validation Accuracy: 0.7623112278397899\n",
      "Epoch 3/40, Training Loss: 0.4969552207122168\n",
      "Epoch 3/40, Validation Loss: 0.47418671598687223, Validation Accuracy: 0.7820091923834537\n",
      "Epoch 4/40, Training Loss: 0.48269537650537614\n",
      "Epoch 4/40, Validation Loss: 0.4730600563721507, Validation Accuracy: 0.788575180564675\n",
      "Epoch 5/40, Training Loss: 0.47125915398826124\n",
      "Epoch 5/40, Validation Loss: 0.4637596455271019, Validation Accuracy: 0.7820091923834537\n",
      "Epoch 6/40, Training Loss: 0.46425459789126877\n",
      "Epoch 6/40, Validation Loss: 0.47460922249714743, Validation Accuracy: 0.778069599474721\n",
      "Epoch 7/40, Training Loss: 0.46701555200449124\n",
      "Epoch 7/40, Validation Loss: 0.45561035973122294, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 8/40, Training Loss: 0.4537940961980992\n",
      "Epoch 8/40, Validation Loss: 0.4672371764808737, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 9/40, Training Loss: 0.45413350815496106\n",
      "Epoch 9/40, Validation Loss: 0.4537494384064412, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 10/40, Training Loss: 0.45300109907398073\n",
      "Epoch 10/40, Validation Loss: 0.46436190218494044, Validation Accuracy: 0.793827971109652\n",
      "Epoch 11/40, Training Loss: 0.45198277715505575\n",
      "Epoch 11/40, Validation Loss: 0.4662914018083305, Validation Accuracy: 0.793827971109652\n",
      "Epoch 12/40, Training Loss: 0.4543143740006945\n",
      "Epoch 12/40, Validation Loss: 0.47340925922373517, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 13/40, Training Loss: 0.4494477113870185\n",
      "Epoch 13/40, Validation Loss: 0.46480851558022473, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 14/40, Training Loss: 0.4419345526498916\n",
      "Epoch 14/40, Validation Loss: 0.4730628378182182, Validation Accuracy: 0.7846355876559422\n",
      "Epoch 15/40, Training Loss: 0.4406854461418988\n",
      "Epoch 15/40, Validation Loss: 0.4554357055369862, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 16/40, Training Loss: 0.4423381350494511\n",
      "Epoch 16/40, Validation Loss: 0.4579627359120165, Validation Accuracy: 0.788575180564675\n",
      "Epoch 17/40, Training Loss: 0.4352743018643437\n",
      "Epoch 17/40, Validation Loss: 0.5020895960206819, Validation Accuracy: 0.7734734077478661\n",
      "Epoch 18/40, Training Loss: 0.4352972259613003\n",
      "Epoch 18/40, Validation Loss: 0.4636119307672205, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 19/40, Training Loss: 0.4356717308127661\n",
      "Epoch 19/40, Validation Loss: 0.4564638118118204, Validation Accuracy: 0.793827971109652\n",
      "Epoch 20/40, Training Loss: 0.43009180222146626\n",
      "Epoch 20/40, Validation Loss: 0.44889537830159304, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 21/40, Training Loss: 0.4275197491851535\n",
      "Epoch 21/40, Validation Loss: 0.46097906044786746, Validation Accuracy: 0.799080761654629\n",
      "Epoch 22/40, Training Loss: 0.43022838015881737\n",
      "Epoch 22/40, Validation Loss: 0.4587761330569446, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 23/40, Training Loss: 0.4300555283511717\n",
      "Epoch 23/40, Validation Loss: 0.4568222408714407, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 24/40, Training Loss: 0.4235290985779343\n",
      "Epoch 24/40, Validation Loss: 0.4491695202984579, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 25/40, Training Loss: 0.42291434591249843\n",
      "Epoch 25/40, Validation Loss: 0.45963349383134217, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 26/40, Training Loss: 0.41899062781118035\n",
      "Epoch 26/40, Validation Loss: 0.45283533660548675, Validation Accuracy: 0.799080761654629\n",
      "Epoch 27/40, Training Loss: 0.4188319325368861\n",
      "Epoch 27/40, Validation Loss: 0.4704222433971173, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 28/40, Training Loss: 0.417699483308814\n",
      "Epoch 28/40, Validation Loss: 0.45755677666827177, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 29/40, Training Loss: 0.4140466712726881\n",
      "Epoch 29/40, Validation Loss: 0.46243655094535563, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 30/40, Training Loss: 0.40843293105503864\n",
      "Epoch 30/40, Validation Loss: 0.466953329699899, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 31/40, Training Loss: 0.4097167544526456\n",
      "Epoch 31/40, Validation Loss: 0.469032436718979, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 32/40, Training Loss: 0.40958216480832554\n",
      "Epoch 32/40, Validation Loss: 0.4653777079973662, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 33/40, Training Loss: 0.4107766611271799\n",
      "Epoch 33/40, Validation Loss: 0.4907806141567733, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 34/40, Training Loss: 0.40588048590332504\n",
      "Epoch 34/40, Validation Loss: 0.4679388600085857, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 35/40, Training Loss: 0.4054593748004809\n",
      "Epoch 35/40, Validation Loss: 0.4776176621537675, Validation Accuracy: 0.7774130006565988\n",
      "Epoch 36/40, Training Loss: 0.4040950713508085\n",
      "Epoch 36/40, Validation Loss: 0.45209536089986097, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 37/40, Training Loss: 0.40433849610721023\n",
      "Epoch 37/40, Validation Loss: 0.48103207592603736, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 38/40, Training Loss: 0.40463975468880237\n",
      "Epoch 38/40, Validation Loss: 0.4883274468812721, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 39/40, Training Loss: 0.39600857659646377\n",
      "Epoch 39/40, Validation Loss: 0.4598037664100762, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 40/40, Training Loss: 0.3936964177069428\n",
      "Epoch 40/40, Validation Loss: 0.46940277807941144, Validation Accuracy: 0.799080761654629\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.565994415921098\n",
      "Epoch 1/40, Validation Loss: 0.4881651671457041, Validation Accuracy: 0.7608409986859396\n",
      "Epoch 2/40, Training Loss: 0.5112404944692931\n",
      "Epoch 2/40, Validation Loss: 0.4661048876989574, Validation Accuracy: 0.7798948751642576\n",
      "Epoch 3/40, Training Loss: 0.5000957430895232\n",
      "Epoch 3/40, Validation Loss: 0.4659701665346535, Validation Accuracy: 0.7818659658344284\n",
      "Epoch 4/40, Training Loss: 0.48639233958885425\n",
      "Epoch 4/40, Validation Loss: 0.45946929794955627, Validation Accuracy: 0.7871222076215506\n",
      "Epoch 5/40, Training Loss: 0.4863213664336311\n",
      "Epoch 5/40, Validation Loss: 0.44590654454306156, Validation Accuracy: 0.797634691195795\n",
      "Epoch 6/40, Training Loss: 0.47453383209667804\n",
      "Epoch 6/40, Validation Loss: 0.44872342931662557, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 7/40, Training Loss: 0.4766683681547798\n",
      "Epoch 7/40, Validation Loss: 0.4408940296249552, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 8/40, Training Loss: 0.4654124386589045\n",
      "Epoch 8/40, Validation Loss: 0.44091194021608193, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 9/40, Training Loss: 0.4576723261948998\n",
      "Epoch 9/40, Validation Loss: 0.442619105050077, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 10/40, Training Loss: 0.4586866046656461\n",
      "Epoch 10/40, Validation Loss: 0.44782125284768526, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 11/40, Training Loss: 0.45354222404597\n",
      "Epoch 11/40, Validation Loss: 0.4403412485817028, Validation Accuracy: 0.7910643889618922\n",
      "Epoch 12/40, Training Loss: 0.4505463147540809\n",
      "Epoch 12/40, Validation Loss: 0.4364437950843292, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 13/40, Training Loss: 0.45433099838731483\n",
      "Epoch 13/40, Validation Loss: 0.4347663542050966, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 14/40, Training Loss: 0.4427052895560509\n",
      "Epoch 14/40, Validation Loss: 0.4301803237831717, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 15/40, Training Loss: 0.44377351252073693\n",
      "Epoch 15/40, Validation Loss: 0.43121301324267663, Validation Accuracy: 0.80946123521682\n",
      "Epoch 16/40, Training Loss: 0.44065711604250385\n",
      "Epoch 16/40, Validation Loss: 0.4560206995896644, Validation Accuracy: 0.790407358738502\n",
      "Epoch 17/40, Training Loss: 0.4423526355854952\n",
      "Epoch 17/40, Validation Loss: 0.43156268927439345, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 18/40, Training Loss: 0.43679306230793785\n",
      "Epoch 18/40, Validation Loss: 0.4206930329213748, Validation Accuracy: 0.8134034165571616\n",
      "Epoch 19/40, Training Loss: 0.43966363996189095\n",
      "Epoch 19/40, Validation Loss: 0.4352659378152009, Validation Accuracy: 0.812089356110381\n",
      "Epoch 20/40, Training Loss: 0.43231517998037217\n",
      "Epoch 20/40, Validation Loss: 0.43753527740689474, Validation Accuracy: 0.7923784494086727\n",
      "Epoch 21/40, Training Loss: 0.43233891116000533\n",
      "Epoch 21/40, Validation Loss: 0.4301342644499547, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 22/40, Training Loss: 0.4286817304320692\n",
      "Epoch 22/40, Validation Loss: 0.4211590782744098, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 23/40, Training Loss: 0.42707597740542075\n",
      "Epoch 23/40, Validation Loss: 0.4344928918981739, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 24/40, Training Loss: 0.42640840019199633\n",
      "Epoch 24/40, Validation Loss: 0.43191925404076487, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 25/40, Training Loss: 0.4298020601174806\n",
      "Epoch 25/40, Validation Loss: 0.4424494918026225, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 26/40, Training Loss: 0.4153041668490475\n",
      "Epoch 26/40, Validation Loss: 0.4349374787111557, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 27/40, Training Loss: 0.42295717166888275\n",
      "Epoch 27/40, Validation Loss: 0.42207418673754676, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 28/40, Training Loss: 0.4223139286090148\n",
      "Epoch 28/40, Validation Loss: 0.4364057037618538, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 29/40, Training Loss: 0.41614594954381307\n",
      "Epoch 29/40, Validation Loss: 0.4340634454109984, Validation Accuracy: 0.80946123521682\n",
      "Epoch 30/40, Training Loss: 0.4209660198832825\n",
      "Epoch 30/40, Validation Loss: 0.4269416179381194, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 31/40, Training Loss: 0.4186655782417362\n",
      "Epoch 31/40, Validation Loss: 0.4317383696056941, Validation Accuracy: 0.804862023653088\n",
      "Epoch 32/40, Training Loss: 0.40985410461040933\n",
      "Epoch 32/40, Validation Loss: 0.45958872275982854, Validation Accuracy: 0.7818659658344284\n",
      "Epoch 33/40, Training Loss: 0.4088430174350191\n",
      "Epoch 33/40, Validation Loss: 0.4273877665205464, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 34/40, Training Loss: 0.4131454301514025\n",
      "Epoch 34/40, Validation Loss: 0.449037266475836, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 35/40, Training Loss: 0.4012431529230802\n",
      "Epoch 35/40, Validation Loss: 0.42251018781936606, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 36/40, Training Loss: 0.40445609981795466\n",
      "Epoch 36/40, Validation Loss: 0.42816292456502375, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 37/40, Training Loss: 0.40288790239123845\n",
      "Epoch 37/40, Validation Loss: 0.4356641079352788, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 38/40, Training Loss: 0.40062451551318795\n",
      "Epoch 38/40, Validation Loss: 0.42483386053113725, Validation Accuracy: 0.812089356110381\n",
      "Epoch 39/40, Training Loss: 0.4043691040571593\n",
      "Epoch 39/40, Validation Loss: 0.42533170929207853, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 40/40, Training Loss: 0.40400883236171536\n",
      "Epoch 40/40, Validation Loss: 0.42485749532336964, Validation Accuracy: 0.8042049934296978\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.5690711546601273\n",
      "Epoch 1/40, Validation Loss: 0.49234972441695746, Validation Accuracy: 0.7812089356110381\n",
      "Epoch 2/40, Training Loss: 0.5074521766247087\n",
      "Epoch 2/40, Validation Loss: 0.50765388712521, Validation Accuracy: 0.7555847568988173\n",
      "Epoch 3/40, Training Loss: 0.49240101637255174\n",
      "Epoch 3/40, Validation Loss: 0.4634338272881757, Validation Accuracy: 0.7897503285151117\n",
      "Epoch 4/40, Training Loss: 0.4756826877574439\n",
      "Epoch 4/40, Validation Loss: 0.47873613445078517, Validation Accuracy: 0.7634691195795007\n",
      "Epoch 5/40, Training Loss: 0.4767814666189234\n",
      "Epoch 5/40, Validation Loss: 0.454823442037505, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 6/40, Training Loss: 0.4672310896159157\n",
      "Epoch 6/40, Validation Loss: 0.4588969162426382, Validation Accuracy: 0.7897503285151117\n",
      "Epoch 7/40, Training Loss: 0.46158487651389574\n",
      "Epoch 7/40, Validation Loss: 0.45576675251828436, Validation Accuracy: 0.790407358738502\n",
      "Epoch 8/40, Training Loss: 0.4606849088521767\n",
      "Epoch 8/40, Validation Loss: 0.45651131784494636, Validation Accuracy: 0.804862023653088\n",
      "Epoch 9/40, Training Loss: 0.45853615581519963\n",
      "Epoch 9/40, Validation Loss: 0.45041101393704325, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 10/40, Training Loss: 0.45222016961712225\n",
      "Epoch 10/40, Validation Loss: 0.4519930264244529, Validation Accuracy: 0.7943495400788436\n",
      "Epoch 11/40, Training Loss: 0.4494290270908611\n",
      "Epoch 11/40, Validation Loss: 0.45192641415755164, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 12/40, Training Loss: 0.45052932663344025\n",
      "Epoch 12/40, Validation Loss: 0.46425180870513016, Validation Accuracy: 0.7910643889618922\n",
      "Epoch 13/40, Training Loss: 0.44307038502332574\n",
      "Epoch 13/40, Validation Loss: 0.4668515469313292, Validation Accuracy: 0.778580814717477\n",
      "Epoch 14/40, Training Loss: 0.4400344040352372\n",
      "Epoch 14/40, Validation Loss: 0.4633019962079862, Validation Accuracy: 0.7798948751642576\n",
      "Epoch 15/40, Training Loss: 0.43262101497667355\n",
      "Epoch 15/40, Validation Loss: 0.4534601198597104, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 16/40, Training Loss: 0.4385188839488768\n",
      "Epoch 16/40, Validation Loss: 0.4673345333101784, Validation Accuracy: 0.804862023653088\n",
      "Epoch 17/40, Training Loss: 0.4351513379123893\n",
      "Epoch 17/40, Validation Loss: 0.4649625048821509, Validation Accuracy: 0.7798948751642576\n",
      "Epoch 18/40, Training Loss: 0.4294495032440255\n",
      "Epoch 18/40, Validation Loss: 0.4639544223693653, Validation Accuracy: 0.7798948751642576\n",
      "Epoch 19/40, Training Loss: 0.43961019900057885\n",
      "Epoch 19/40, Validation Loss: 0.4503621759370984, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 20/40, Training Loss: 0.42419149834672454\n",
      "Epoch 20/40, Validation Loss: 0.4486502193363081, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 21/40, Training Loss: 0.42572887649568986\n",
      "Epoch 21/40, Validation Loss: 0.46792068500169287, Validation Accuracy: 0.7792378449408672\n",
      "Epoch 22/40, Training Loss: 0.4259443815377128\n",
      "Epoch 22/40, Validation Loss: 0.45266736873196367, Validation Accuracy: 0.797634691195795\n",
      "Epoch 23/40, Training Loss: 0.4185304630870425\n",
      "Epoch 23/40, Validation Loss: 0.4620959079136867, Validation Accuracy: 0.7884362680683311\n",
      "Epoch 24/40, Training Loss: 0.42238159698197064\n",
      "Epoch 24/40, Validation Loss: 0.4560181743889579, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 25/40, Training Loss: 0.4194223393155677\n",
      "Epoch 25/40, Validation Loss: 0.45303287872976344, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 26/40, Training Loss: 0.4162268664326098\n",
      "Epoch 26/40, Validation Loss: 0.4598102209484936, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 27/40, Training Loss: 0.4176237656883993\n",
      "Epoch 27/40, Validation Loss: 0.4568599895013408, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 28/40, Training Loss: 0.41485385685728915\n",
      "Epoch 28/40, Validation Loss: 0.4509935345968807, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 29/40, Training Loss: 0.4165258468214295\n",
      "Epoch 29/40, Validation Loss: 0.4684285071449286, Validation Accuracy: 0.7838370565045992\n",
      "Epoch 30/40, Training Loss: 0.4101415275671859\n",
      "Epoch 30/40, Validation Loss: 0.4670884113866075, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 31/40, Training Loss: 0.4061589385248388\n",
      "Epoch 31/40, Validation Loss: 0.45931533729920837, Validation Accuracy: 0.7923784494086727\n",
      "Epoch 32/40, Training Loss: 0.4070895313189959\n",
      "Epoch 32/40, Validation Loss: 0.45236375418867114, Validation Accuracy: 0.7910643889618922\n",
      "Epoch 33/40, Training Loss: 0.40344171076426355\n",
      "Epoch 33/40, Validation Loss: 0.46796326761997026, Validation Accuracy: 0.80946123521682\n",
      "Epoch 34/40, Training Loss: 0.40502374996663393\n",
      "Epoch 34/40, Validation Loss: 0.4594058331433703, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 35/40, Training Loss: 0.4045680631441003\n",
      "Epoch 35/40, Validation Loss: 0.4656430582871846, Validation Accuracy: 0.7963206307490145\n",
      "Epoch 36/40, Training Loss: 0.40131474770312237\n",
      "Epoch 36/40, Validation Loss: 0.45487049026951115, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 37/40, Training Loss: 0.39756706874240727\n",
      "Epoch 37/40, Validation Loss: 0.46957804673200193, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 38/40, Training Loss: 0.39458795071987735\n",
      "Epoch 38/40, Validation Loss: 0.45493005071791054, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 39/40, Training Loss: 0.39793769017184577\n",
      "Epoch 39/40, Validation Loss: 0.4554287709334758, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 40/40, Training Loss: 0.3870170106402454\n",
      "Epoch 40/40, Validation Loss: 0.45815680142862636, Validation Accuracy: 0.7917214191852825\n",
      "Average Validation Accuracy: 0.8000782569156423\n"
     ]
    }
   ],
   "source": [
    "val_accuracies = []\n",
    "for train_idx, val_idx in skf.split(combined_features, labels):\n",
    "    # Create TensorDatasets for the current fold\n",
    "    train_dataset = TensorDataset(torch.tensor(combined_features[train_idx]), torch.tensor(labels_numpy[train_idx].reshape(-1,1), dtype=torch.float32))\n",
    "    val_dataset = TensorDataset(torch.tensor(combined_features[val_idx]), torch.tensor(labels_numpy[val_idx].reshape(-1,1), dtype=torch.float32))\n",
    "\n",
    "    # Create DataLoaders for the current fold\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    # Train and validate your model for the current fold\n",
    "    # Train and validate your model for the current fold and store the validation accuracy\n",
    "    val_accuracy = train_and_validate(train_dataloader, val_dataloader, len(val_dataset), num_epochs=40)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Calculate the average validation accuracy across all folds\n",
    "average_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "print(f'Average Validation Accuracy: {average_val_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Validation Accuracy: 0.8000782569156423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_val_accuracy_dict = {}\n",
    "average_val_accuracy_dict[2] = 0.8000782569156423"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performed with CombinedModelMoreHLs 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.6747242410977682\n",
      "Epoch 1/40, Validation Loss: 0.6398675739765167, Validation Accuracy: 0.6270518713066316\n",
      "Epoch 2/40, Training Loss: 0.6265063484509786\n",
      "Epoch 2/40, Validation Loss: 0.591761976480484, Validation Accuracy: 0.7261982928430729\n",
      "Epoch 3/40, Training Loss: 0.5925513009230295\n",
      "Epoch 3/40, Validation Loss: 0.5596535801887512, Validation Accuracy: 0.737360472751149\n",
      "Epoch 4/40, Training Loss: 0.5590356687704722\n",
      "Epoch 4/40, Validation Loss: 0.5219336152076721, Validation Accuracy: 0.7649376231122784\n",
      "Epoch 5/40, Training Loss: 0.5308896203835806\n",
      "Epoch 5/40, Validation Loss: 0.49757087230682373, Validation Accuracy: 0.7767564018384767\n",
      "Epoch 6/40, Training Loss: 0.5075901250044504\n",
      "Epoch 6/40, Validation Loss: 0.48568572103977203, Validation Accuracy: 0.778069599474721\n",
      "Epoch 7/40, Training Loss: 0.4919910728931427\n",
      "Epoch 7/40, Validation Loss: 0.47702476382255554, Validation Accuracy: 0.7800393959290873\n",
      "Epoch 8/40, Training Loss: 0.47958092391490936\n",
      "Epoch 8/40, Validation Loss: 0.47062957286834717, Validation Accuracy: 0.783322390019698\n",
      "Epoch 9/40, Training Loss: 0.47719821830590564\n",
      "Epoch 9/40, Validation Loss: 0.4698268175125122, Validation Accuracy: 0.7852921864740644\n",
      "Epoch 10/40, Training Loss: 0.46792880197366077\n",
      "Epoch 10/40, Validation Loss: 0.4600521922111511, Validation Accuracy: 0.7852921864740644\n",
      "Epoch 11/40, Training Loss: 0.458977406223615\n",
      "Epoch 11/40, Validation Loss: 0.45553572475910187, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 12/40, Training Loss: 0.4574556102355321\n",
      "Epoch 12/40, Validation Loss: 0.4549786150455475, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 13/40, Training Loss: 0.4527413795391719\n",
      "Epoch 13/40, Validation Loss: 0.45138978958129883, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 14/40, Training Loss: 0.4500981718301773\n",
      "Epoch 14/40, Validation Loss: 0.4531061351299286, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 15/40, Training Loss: 0.44641005992889404\n",
      "Epoch 15/40, Validation Loss: 0.44955289363861084, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 16/40, Training Loss: 0.4461490611235301\n",
      "Epoch 16/40, Validation Loss: 0.44850800931453705, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 17/40, Training Loss: 0.44164161880811054\n",
      "Epoch 17/40, Validation Loss: 0.4456361383199692, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 18/40, Training Loss: 0.43913312753041583\n",
      "Epoch 18/40, Validation Loss: 0.4438086599111557, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 19/40, Training Loss: 0.43116716543833417\n",
      "Epoch 19/40, Validation Loss: 0.44144466519355774, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 20/40, Training Loss: 0.43424594899018604\n",
      "Epoch 20/40, Validation Loss: 0.43935757875442505, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 21/40, Training Loss: 0.43181145191192627\n",
      "Epoch 21/40, Validation Loss: 0.4373313933610916, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 22/40, Training Loss: 0.42795949180920917\n",
      "Epoch 22/40, Validation Loss: 0.4389922171831131, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 23/40, Training Loss: 0.42523860434691113\n",
      "Epoch 23/40, Validation Loss: 0.4405052959918976, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 24/40, Training Loss: 0.4216527193784714\n",
      "Epoch 24/40, Validation Loss: 0.4371222257614136, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 25/40, Training Loss: 0.4143034716447194\n",
      "Epoch 25/40, Validation Loss: 0.4418851435184479, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 26/40, Training Loss: 0.4166974872350693\n",
      "Epoch 26/40, Validation Loss: 0.4335401803255081, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 27/40, Training Loss: 0.411099116007487\n",
      "Epoch 27/40, Validation Loss: 0.4363659620285034, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 28/40, Training Loss: 0.40910493830839795\n",
      "Epoch 28/40, Validation Loss: 0.43399661779403687, Validation Accuracy: 0.799080761654629\n",
      "Epoch 29/40, Training Loss: 0.4103570878505707\n",
      "Epoch 29/40, Validation Loss: 0.440273642539978, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 30/40, Training Loss: 0.4047774573167165\n",
      "Epoch 30/40, Validation Loss: 0.4360324591398239, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 31/40, Training Loss: 0.4054579387108485\n",
      "Epoch 31/40, Validation Loss: 0.43285422027111053, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 32/40, Training Loss: 0.4008223315080007\n",
      "Epoch 32/40, Validation Loss: 0.43925735354423523, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 33/40, Training Loss: 0.40679628153642017\n",
      "Epoch 33/40, Validation Loss: 0.43358340859413147, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 34/40, Training Loss: 0.4006497859954834\n",
      "Epoch 34/40, Validation Loss: 0.4367903769016266, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 35/40, Training Loss: 0.40231460829575855\n",
      "Epoch 35/40, Validation Loss: 0.4369128942489624, Validation Accuracy: 0.804333552199606\n",
      "Epoch 36/40, Training Loss: 0.39434942603111267\n",
      "Epoch 36/40, Validation Loss: 0.43612198531627655, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 37/40, Training Loss: 0.39712925752003986\n",
      "Epoch 37/40, Validation Loss: 0.43912993371486664, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 38/40, Training Loss: 0.39359832803408307\n",
      "Epoch 38/40, Validation Loss: 0.4371776580810547, Validation Accuracy: 0.8089297439264609\n",
      "Epoch 39/40, Training Loss: 0.3869793315728505\n",
      "Epoch 39/40, Validation Loss: 0.44052931666374207, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 40/40, Training Loss: 0.3830070147911708\n",
      "Epoch 40/40, Validation Loss: 0.4403284192085266, Validation Accuracy: 0.8036769533814839\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.6765145659446716\n",
      "Epoch 1/40, Validation Loss: 0.6514802575111389, Validation Accuracy: 0.5942219304005253\n",
      "Epoch 2/40, Training Loss: 0.6398093402385712\n",
      "Epoch 2/40, Validation Loss: 0.6054668426513672, Validation Accuracy: 0.6992777413000657\n",
      "Epoch 3/40, Training Loss: 0.6062188744544983\n",
      "Epoch 3/40, Validation Loss: 0.573616623878479, Validation Accuracy: 0.6946815495732108\n",
      "Epoch 4/40, Training Loss: 0.5732598106066386\n",
      "Epoch 4/40, Validation Loss: 0.5365390479564667, Validation Accuracy: 0.7367038739330269\n",
      "Epoch 5/40, Training Loss: 0.545059472322464\n",
      "Epoch 5/40, Validation Loss: 0.5030604600906372, Validation Accuracy: 0.7669074195666448\n",
      "Epoch 6/40, Training Loss: 0.5223684807618459\n",
      "Epoch 6/40, Validation Loss: 0.49487680196762085, Validation Accuracy: 0.7642810242941562\n",
      "Epoch 7/40, Training Loss: 0.5065023601055145\n",
      "Epoch 7/40, Validation Loss: 0.484169140458107, Validation Accuracy: 0.7701904136572554\n",
      "Epoch 8/40, Training Loss: 0.4988652815421422\n",
      "Epoch 8/40, Validation Loss: 0.47387102246284485, Validation Accuracy: 0.7826657912015759\n",
      "Epoch 9/40, Training Loss: 0.4917059689760208\n",
      "Epoch 9/40, Validation Loss: 0.46928703784942627, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 10/40, Training Loss: 0.48465431729952496\n",
      "Epoch 10/40, Validation Loss: 0.46303604543209076, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 11/40, Training Loss: 0.47387180229028064\n",
      "Epoch 11/40, Validation Loss: 0.4585171788930893, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 12/40, Training Loss: 0.46970626215140027\n",
      "Epoch 12/40, Validation Loss: 0.45469705760478973, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 13/40, Training Loss: 0.46329691012700397\n",
      "Epoch 13/40, Validation Loss: 0.45185941457748413, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 14/40, Training Loss: 0.4611238092184067\n",
      "Epoch 14/40, Validation Loss: 0.4536653906106949, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 15/40, Training Loss: 0.45667413870493573\n",
      "Epoch 15/40, Validation Loss: 0.44722993671894073, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 16/40, Training Loss: 0.4489264190196991\n",
      "Epoch 16/40, Validation Loss: 0.4472814202308655, Validation Accuracy: 0.799080761654629\n",
      "Epoch 17/40, Training Loss: 0.45199454327424365\n",
      "Epoch 17/40, Validation Loss: 0.46763110160827637, Validation Accuracy: 0.7800393959290873\n",
      "Epoch 18/40, Training Loss: 0.4563530534505844\n",
      "Epoch 18/40, Validation Loss: 0.44380638003349304, Validation Accuracy: 0.799080761654629\n",
      "Epoch 19/40, Training Loss: 0.4454416086276372\n",
      "Epoch 19/40, Validation Loss: 0.44559700787067413, Validation Accuracy: 0.793827971109652\n",
      "Epoch 20/40, Training Loss: 0.43679342170556384\n",
      "Epoch 20/40, Validation Loss: 0.44539812207221985, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 21/40, Training Loss: 0.4365668793519338\n",
      "Epoch 21/40, Validation Loss: 0.43861018121242523, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 22/40, Training Loss: 0.4349258840084076\n",
      "Epoch 22/40, Validation Loss: 0.43752458691596985, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 23/40, Training Loss: 0.4330064157644908\n",
      "Epoch 23/40, Validation Loss: 0.43877990543842316, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 24/40, Training Loss: 0.43759319682916004\n",
      "Epoch 24/40, Validation Loss: 0.43794775009155273, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 25/40, Training Loss: 0.4300020436445872\n",
      "Epoch 25/40, Validation Loss: 0.4373905062675476, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 26/40, Training Loss: 0.4224497725566228\n",
      "Epoch 26/40, Validation Loss: 0.4387975186109543, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 27/40, Training Loss: 0.42289671798547107\n",
      "Epoch 27/40, Validation Loss: 0.43759675323963165, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 28/40, Training Loss: 0.42305561900138855\n",
      "Epoch 28/40, Validation Loss: 0.4355998933315277, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 29/40, Training Loss: 0.42035311957200366\n",
      "Epoch 29/40, Validation Loss: 0.44391243159770966, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 30/40, Training Loss: 0.42042864362398785\n",
      "Epoch 30/40, Validation Loss: 0.4381474107503891, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 31/40, Training Loss: 0.4153480529785156\n",
      "Epoch 31/40, Validation Loss: 0.4347772002220154, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 32/40, Training Loss: 0.4099961320559184\n",
      "Epoch 32/40, Validation Loss: 0.4338233023881912, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 33/40, Training Loss: 0.41327109932899475\n",
      "Epoch 33/40, Validation Loss: 0.4351184666156769, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 34/40, Training Loss: 0.4111219644546509\n",
      "Epoch 34/40, Validation Loss: 0.43482254445552826, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 35/40, Training Loss: 0.40939123431841534\n",
      "Epoch 35/40, Validation Loss: 0.4345972090959549, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 36/40, Training Loss: 0.40216051042079926\n",
      "Epoch 36/40, Validation Loss: 0.4359516054391861, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 37/40, Training Loss: 0.40544559558232623\n",
      "Epoch 37/40, Validation Loss: 0.43807199597358704, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 38/40, Training Loss: 0.40808965265750885\n",
      "Epoch 38/40, Validation Loss: 0.4346128851175308, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 39/40, Training Loss: 0.3991301904122035\n",
      "Epoch 39/40, Validation Loss: 0.4378177225589752, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 40/40, Training Loss: 0.39778150618076324\n",
      "Epoch 40/40, Validation Loss: 0.434024840593338, Validation Accuracy: 0.8030203545633617\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.6724302470684052\n",
      "Epoch 1/40, Validation Loss: 0.6430698931217194, Validation Accuracy: 0.6736703873933026\n",
      "Epoch 2/40, Training Loss: 0.6263102889060974\n",
      "Epoch 2/40, Validation Loss: 0.6056590676307678, Validation Accuracy: 0.6808929743926461\n",
      "Epoch 3/40, Training Loss: 0.5939741333325704\n",
      "Epoch 3/40, Validation Loss: 0.5707839727401733, Validation Accuracy: 0.7045305318450427\n",
      "Epoch 4/40, Training Loss: 0.5606507758299509\n",
      "Epoch 4/40, Validation Loss: 0.5304206609725952, Validation Accuracy: 0.7399868680236376\n",
      "Epoch 5/40, Training Loss: 0.5283654431502024\n",
      "Epoch 5/40, Validation Loss: 0.49916988611221313, Validation Accuracy: 0.7669074195666448\n",
      "Epoch 6/40, Training Loss: 0.5104944954315821\n",
      "Epoch 6/40, Validation Loss: 0.48569464683532715, Validation Accuracy: 0.7708470124753776\n",
      "Epoch 7/40, Training Loss: 0.492283230026563\n",
      "Epoch 7/40, Validation Loss: 0.4817565530538559, Validation Accuracy: 0.7688772160210111\n",
      "Epoch 8/40, Training Loss: 0.483147790034612\n",
      "Epoch 8/40, Validation Loss: 0.47594884037971497, Validation Accuracy: 0.7708470124753776\n",
      "Epoch 9/40, Training Loss: 0.47163482507069904\n",
      "Epoch 9/40, Validation Loss: 0.4704405218362808, Validation Accuracy: 0.7774130006565988\n",
      "Epoch 10/40, Training Loss: 0.4697459538777669\n",
      "Epoch 10/40, Validation Loss: 0.4680272191762924, Validation Accuracy: 0.7774130006565988\n",
      "Epoch 11/40, Training Loss: 0.46129963795344037\n",
      "Epoch 11/40, Validation Loss: 0.46648310124874115, Validation Accuracy: 0.7826657912015759\n",
      "Epoch 12/40, Training Loss: 0.45881707469622296\n",
      "Epoch 12/40, Validation Loss: 0.46346744894981384, Validation Accuracy: 0.7820091923834537\n",
      "Epoch 13/40, Training Loss: 0.4543566405773163\n",
      "Epoch 13/40, Validation Loss: 0.457832008600235, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 14/40, Training Loss: 0.4504154523213704\n",
      "Epoch 14/40, Validation Loss: 0.46017172932624817, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 15/40, Training Loss: 0.4479959160089493\n",
      "Epoch 15/40, Validation Loss: 0.45527224242687225, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 16/40, Training Loss: 0.4440704435110092\n",
      "Epoch 16/40, Validation Loss: 0.45456190407276154, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 17/40, Training Loss: 0.44072916110356647\n",
      "Epoch 17/40, Validation Loss: 0.45292581617832184, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 18/40, Training Loss: 0.436128964026769\n",
      "Epoch 18/40, Validation Loss: 0.45209361612796783, Validation Accuracy: 0.793827971109652\n",
      "Epoch 19/40, Training Loss: 0.4351031581560771\n",
      "Epoch 19/40, Validation Loss: 0.45245224237442017, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 20/40, Training Loss: 0.4372909863789876\n",
      "Epoch 20/40, Validation Loss: 0.44888900220394135, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 21/40, Training Loss: 0.4358817934989929\n",
      "Epoch 21/40, Validation Loss: 0.457130491733551, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 22/40, Training Loss: 0.43677003184954327\n",
      "Epoch 22/40, Validation Loss: 0.4483310580253601, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 23/40, Training Loss: 0.42581010858217877\n",
      "Epoch 23/40, Validation Loss: 0.4519662857055664, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 24/40, Training Loss: 0.42462968329588574\n",
      "Epoch 24/40, Validation Loss: 0.4580451399087906, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 25/40, Training Loss: 0.42299074431260425\n",
      "Epoch 25/40, Validation Loss: 0.457415834069252, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 26/40, Training Loss: 0.42239754398663837\n",
      "Epoch 26/40, Validation Loss: 0.45485836267471313, Validation Accuracy: 0.8036769533814839\n",
      "Epoch 27/40, Training Loss: 0.4166177213191986\n",
      "Epoch 27/40, Validation Loss: 0.44920821487903595, Validation Accuracy: 0.8063033486539725\n",
      "Epoch 28/40, Training Loss: 0.4190786729256312\n",
      "Epoch 28/40, Validation Loss: 0.443798691034317, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 29/40, Training Loss: 0.41392680009206134\n",
      "Epoch 29/40, Validation Loss: 0.44684459269046783, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 30/40, Training Loss: 0.4113141944011052\n",
      "Epoch 30/40, Validation Loss: 0.44500263035297394, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 31/40, Training Loss: 0.4065043181180954\n",
      "Epoch 31/40, Validation Loss: 0.44793714582920074, Validation Accuracy: 0.804333552199606\n",
      "Epoch 32/40, Training Loss: 0.40373818576335907\n",
      "Epoch 32/40, Validation Loss: 0.4484276622533798, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 33/40, Training Loss: 0.4056781182686488\n",
      "Epoch 33/40, Validation Loss: 0.4472281038761139, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 34/40, Training Loss: 0.40459680557250977\n",
      "Epoch 34/40, Validation Loss: 0.4470457583665848, Validation Accuracy: 0.8056467498358503\n",
      "Epoch 35/40, Training Loss: 0.40299153327941895\n",
      "Epoch 35/40, Validation Loss: 0.44514913856983185, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 36/40, Training Loss: 0.4011433372894923\n",
      "Epoch 36/40, Validation Loss: 0.44900496304035187, Validation Accuracy: 0.799080761654629\n",
      "Epoch 37/40, Training Loss: 0.3958507825930913\n",
      "Epoch 37/40, Validation Loss: 0.4504694640636444, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 38/40, Training Loss: 0.39594756563504535\n",
      "Epoch 38/40, Validation Loss: 0.44685252010822296, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 39/40, Training Loss: 0.39408128956953686\n",
      "Epoch 39/40, Validation Loss: 0.44462111592292786, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 40/40, Training Loss: 0.39481158554553986\n",
      "Epoch 40/40, Validation Loss: 0.4500894844532013, Validation Accuracy: 0.804333552199606\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.674191822608312\n",
      "Epoch 1/40, Validation Loss: 0.6379123032093048, Validation Accuracy: 0.676084099868594\n",
      "Epoch 2/40, Training Loss: 0.6281306445598602\n",
      "Epoch 2/40, Validation Loss: 0.5821033418178558, Validation Accuracy: 0.7063074901445466\n",
      "Epoch 3/40, Training Loss: 0.5898501376310984\n",
      "Epoch 3/40, Validation Loss: 0.5416658520698547, Validation Accuracy: 0.7233902759526938\n",
      "Epoch 4/40, Training Loss: 0.5596642891565958\n",
      "Epoch 4/40, Validation Loss: 0.5133471935987473, Validation Accuracy: 0.7496714848883048\n",
      "Epoch 5/40, Training Loss: 0.5302292307217916\n",
      "Epoch 5/40, Validation Loss: 0.5026227086782455, Validation Accuracy: 0.7588699080157687\n",
      "Epoch 6/40, Training Loss: 0.5138930032650629\n",
      "Epoch 6/40, Validation Loss: 0.4763227552175522, Validation Accuracy: 0.7601839684625493\n",
      "Epoch 7/40, Training Loss: 0.499339093764623\n",
      "Epoch 7/40, Validation Loss: 0.46904292702674866, Validation Accuracy: 0.7766097240473062\n",
      "Epoch 8/40, Training Loss: 0.4859292656183243\n",
      "Epoch 8/40, Validation Loss: 0.46063680946826935, Validation Accuracy: 0.7779237844940867\n",
      "Epoch 9/40, Training Loss: 0.47958587606747943\n",
      "Epoch 9/40, Validation Loss: 0.4561909884214401, Validation Accuracy: 0.7798948751642576\n",
      "Epoch 10/40, Training Loss: 0.475191464026769\n",
      "Epoch 10/40, Validation Loss: 0.45323340594768524, Validation Accuracy: 0.7818659658344284\n",
      "Epoch 11/40, Training Loss: 0.4688614308834076\n",
      "Epoch 11/40, Validation Loss: 0.45260627567768097, Validation Accuracy: 0.7864651773981604\n",
      "Epoch 12/40, Training Loss: 0.4652890811363856\n",
      "Epoch 12/40, Validation Loss: 0.4416673481464386, Validation Accuracy: 0.7890932982917214\n",
      "Epoch 13/40, Training Loss: 0.4602551410595576\n",
      "Epoch 13/40, Validation Loss: 0.43776851892471313, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 14/40, Training Loss: 0.4551311582326889\n",
      "Epoch 14/40, Validation Loss: 0.43379224836826324, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 15/40, Training Loss: 0.45109232266743976\n",
      "Epoch 15/40, Validation Loss: 0.4344450980424881, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 16/40, Training Loss: 0.45193501313527423\n",
      "Epoch 16/40, Validation Loss: 0.43397705256938934, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 17/40, Training Loss: 0.44528215130170185\n",
      "Epoch 17/40, Validation Loss: 0.4318140596151352, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 18/40, Training Loss: 0.44296740492184955\n",
      "Epoch 18/40, Validation Loss: 0.4260774552822113, Validation Accuracy: 0.80946123521682\n",
      "Epoch 19/40, Training Loss: 0.4423224826653798\n",
      "Epoch 19/40, Validation Loss: 0.4260439872741699, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 20/40, Training Loss: 0.4369141608476639\n",
      "Epoch 20/40, Validation Loss: 0.4225691854953766, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 21/40, Training Loss: 0.4369204094012578\n",
      "Epoch 21/40, Validation Loss: 0.42107199132442474, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 22/40, Training Loss: 0.42919783294200897\n",
      "Epoch 22/40, Validation Loss: 0.4192795753479004, Validation Accuracy: 0.80946123521682\n",
      "Epoch 23/40, Training Loss: 0.4279563178618749\n",
      "Epoch 23/40, Validation Loss: 0.4202379286289215, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 24/40, Training Loss: 0.4296650489171346\n",
      "Epoch 24/40, Validation Loss: 0.4167334735393524, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 25/40, Training Loss: 0.42744473616282147\n",
      "Epoch 25/40, Validation Loss: 0.4193856418132782, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 26/40, Training Loss: 0.41984322667121887\n",
      "Epoch 26/40, Validation Loss: 0.41761958599090576, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 27/40, Training Loss: 0.42177718381086987\n",
      "Epoch 27/40, Validation Loss: 0.4163237363100052, Validation Accuracy: 0.812089356110381\n",
      "Epoch 28/40, Training Loss: 0.4205014109611511\n",
      "Epoch 28/40, Validation Loss: 0.4198862761259079, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 29/40, Training Loss: 0.42003656427065533\n",
      "Epoch 29/40, Validation Loss: 0.4178131967782974, Validation Accuracy: 0.80946123521682\n",
      "Epoch 30/40, Training Loss: 0.4153289496898651\n",
      "Epoch 30/40, Validation Loss: 0.4138578027486801, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 31/40, Training Loss: 0.4156970630089442\n",
      "Epoch 31/40, Validation Loss: 0.41174885630607605, Validation Accuracy: 0.812089356110381\n",
      "Epoch 32/40, Training Loss: 0.40950285891691846\n",
      "Epoch 32/40, Validation Loss: 0.4151824712753296, Validation Accuracy: 0.8134034165571616\n",
      "Epoch 33/40, Training Loss: 0.41270377735296887\n",
      "Epoch 33/40, Validation Loss: 0.41447871923446655, Validation Accuracy: 0.80946123521682\n",
      "Epoch 34/40, Training Loss: 0.4105003972848256\n",
      "Epoch 34/40, Validation Loss: 0.4140216261148453, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 35/40, Training Loss: 0.4057791233062744\n",
      "Epoch 35/40, Validation Loss: 0.41162411868572235, Validation Accuracy: 0.8134034165571616\n",
      "Epoch 36/40, Training Loss: 0.40947577357292175\n",
      "Epoch 36/40, Validation Loss: 0.4132730960845947, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 37/40, Training Loss: 0.4049870123465856\n",
      "Epoch 37/40, Validation Loss: 0.41436056792736053, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 38/40, Training Loss: 0.4060571839412053\n",
      "Epoch 38/40, Validation Loss: 0.4130092114210129, Validation Accuracy: 0.8147174770039421\n",
      "Epoch 39/40, Training Loss: 0.4021245688199997\n",
      "Epoch 39/40, Validation Loss: 0.4168829172849655, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 40/40, Training Loss: 0.4025084724028905\n",
      "Epoch 40/40, Validation Loss: 0.420452281832695, Validation Accuracy: 0.8042049934296978\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.670785387357076\n",
      "Epoch 1/40, Validation Loss: 0.630929708480835, Validation Accuracy: 0.7030223390275953\n",
      "Epoch 2/40, Training Loss: 0.6245126724243164\n",
      "Epoch 2/40, Validation Loss: 0.5749379992485046, Validation Accuracy: 0.7227332457293035\n",
      "Epoch 3/40, Training Loss: 0.5839511156082153\n",
      "Epoch 3/40, Validation Loss: 0.5381385087966919, Validation Accuracy: 0.7477003942181341\n",
      "Epoch 4/40, Training Loss: 0.5524753828843435\n",
      "Epoch 4/40, Validation Loss: 0.5093974024057388, Validation Accuracy: 0.7562417871222076\n",
      "Epoch 5/40, Training Loss: 0.5195432156324387\n",
      "Epoch 5/40, Validation Loss: 0.4901457726955414, Validation Accuracy: 0.7739816031537451\n",
      "Epoch 6/40, Training Loss: 0.5028498023748398\n",
      "Epoch 6/40, Validation Loss: 0.47578804194927216, Validation Accuracy: 0.783180026281209\n",
      "Epoch 7/40, Training Loss: 0.4924205889304479\n",
      "Epoch 7/40, Validation Loss: 0.46656541526317596, Validation Accuracy: 0.7825229960578186\n",
      "Epoch 8/40, Training Loss: 0.4843018849690755\n",
      "Epoch 8/40, Validation Loss: 0.4640266001224518, Validation Accuracy: 0.7871222076215506\n",
      "Epoch 9/40, Training Loss: 0.4734409401814143\n",
      "Epoch 9/40, Validation Loss: 0.4551636427640915, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 10/40, Training Loss: 0.4696928709745407\n",
      "Epoch 10/40, Validation Loss: 0.452077716588974, Validation Accuracy: 0.790407358738502\n",
      "Epoch 11/40, Training Loss: 0.46487384537855786\n",
      "Epoch 11/40, Validation Loss: 0.4554704427719116, Validation Accuracy: 0.7851511169513797\n",
      "Epoch 12/40, Training Loss: 0.45916488766670227\n",
      "Epoch 12/40, Validation Loss: 0.46485209465026855, Validation Accuracy: 0.7739816031537451\n",
      "Epoch 13/40, Training Loss: 0.46170173088709515\n",
      "Epoch 13/40, Validation Loss: 0.4556150585412979, Validation Accuracy: 0.7864651773981604\n",
      "Epoch 14/40, Training Loss: 0.45440853635470074\n",
      "Epoch 14/40, Validation Loss: 0.44612278044223785, Validation Accuracy: 0.7897503285151117\n",
      "Epoch 15/40, Training Loss: 0.44575291872024536\n",
      "Epoch 15/40, Validation Loss: 0.4452327787876129, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 16/40, Training Loss: 0.44450899958610535\n",
      "Epoch 16/40, Validation Loss: 0.44354479014873505, Validation Accuracy: 0.7950065703022339\n",
      "Epoch 17/40, Training Loss: 0.4373372594515483\n",
      "Epoch 17/40, Validation Loss: 0.4429188668727875, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 18/40, Training Loss: 0.4344390084346135\n",
      "Epoch 18/40, Validation Loss: 0.44114941358566284, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 19/40, Training Loss: 0.43030894299348194\n",
      "Epoch 19/40, Validation Loss: 0.4401664435863495, Validation Accuracy: 0.7989487516425755\n",
      "Epoch 20/40, Training Loss: 0.4298669199148814\n",
      "Epoch 20/40, Validation Loss: 0.4424495995044708, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 21/40, Training Loss: 0.4277869164943695\n",
      "Epoch 21/40, Validation Loss: 0.43888843059539795, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 22/40, Training Loss: 0.4286429633696874\n",
      "Epoch 22/40, Validation Loss: 0.4443657696247101, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 23/40, Training Loss: 0.4249904503424962\n",
      "Epoch 23/40, Validation Loss: 0.43811893463134766, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 24/40, Training Loss: 0.4272385835647583\n",
      "Epoch 24/40, Validation Loss: 0.4388609975576401, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 25/40, Training Loss: 0.4219624996185303\n",
      "Epoch 25/40, Validation Loss: 0.44077806174755096, Validation Accuracy: 0.80946123521682\n",
      "Epoch 26/40, Training Loss: 0.423764705657959\n",
      "Epoch 26/40, Validation Loss: 0.4361458569765091, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 27/40, Training Loss: 0.4129244287808736\n",
      "Epoch 27/40, Validation Loss: 0.4446583241224289, Validation Accuracy: 0.7917214191852825\n",
      "Epoch 28/40, Training Loss: 0.41265204548835754\n",
      "Epoch 28/40, Validation Loss: 0.452892541885376, Validation Accuracy: 0.7871222076215506\n",
      "Epoch 29/40, Training Loss: 0.4156324118375778\n",
      "Epoch 29/40, Validation Loss: 0.43803805112838745, Validation Accuracy: 0.7969776609724047\n",
      "Epoch 30/40, Training Loss: 0.4090498487154643\n",
      "Epoch 30/40, Validation Loss: 0.43524621427059174, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 31/40, Training Loss: 0.41002675890922546\n",
      "Epoch 31/40, Validation Loss: 0.4356456696987152, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 32/40, Training Loss: 0.41232701142628986\n",
      "Epoch 32/40, Validation Loss: 0.4341728240251541, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 33/40, Training Loss: 0.4066537668307622\n",
      "Epoch 33/40, Validation Loss: 0.43665117025375366, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 34/40, Training Loss: 0.40413904190063477\n",
      "Epoch 34/40, Validation Loss: 0.43693557381629944, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 35/40, Training Loss: 0.4028488099575043\n",
      "Epoch 35/40, Validation Loss: 0.43488214910030365, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 36/40, Training Loss: 0.39961518347263336\n",
      "Epoch 36/40, Validation Loss: 0.4373646080493927, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 37/40, Training Loss: 0.3982288638750712\n",
      "Epoch 37/40, Validation Loss: 0.4374857097864151, Validation Accuracy: 0.804862023653088\n",
      "Epoch 38/40, Training Loss: 0.3923715303341548\n",
      "Epoch 38/40, Validation Loss: 0.43889227509498596, Validation Accuracy: 0.8015768725361366\n",
      "Epoch 39/40, Training Loss: 0.39362021287282306\n",
      "Epoch 39/40, Validation Loss: 0.4414699077606201, Validation Accuracy: 0.8061760840998686\n",
      "Epoch 40/40, Training Loss: 0.392824908097585\n",
      "Epoch 40/40, Validation Loss: 0.4480482488870621, Validation Accuracy: 0.7923784494086727\n",
      "Average Validation Accuracy: 0.8015228605965646\n"
     ]
    }
   ],
   "source": [
    "val_accuracies = []\n",
    "for train_idx, val_idx in skf.split(combined_features, labels):\n",
    "    # Create TensorDatasets for the current fold\n",
    "    train_dataset = TensorDataset(torch.tensor(combined_features[train_idx]), torch.tensor(labels_numpy[train_idx].reshape(-1,1), dtype=torch.float32))\n",
    "    val_dataset = TensorDataset(torch.tensor(combined_features[val_idx]), torch.tensor(labels_numpy[val_idx].reshape(-1,1), dtype=torch.float32))\n",
    "\n",
    "    # Create DataLoaders for the current fold\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "    # Train and validate your model for the current fold\n",
    "    # Train and validate your model for the current fold and store the validation accuracy\n",
    "    val_accuracy = train_and_validate(train_dataloader, val_dataloader, len(val_dataset), num_epochs=40)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Calculate the average validation accuracy across all folds\n",
    "average_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "print(f'Average Validation Accuracy: {average_val_accuracy}')\n",
    "average_val_accuracy_dict[3] = average_val_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performed with CombinedModelMoreHLs 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.6704482734203339\n",
      "Epoch 1/40, Validation Loss: 0.6340758204460144, Validation Accuracy: 0.711096520026264\n",
      "Epoch 2/40, Training Loss: 0.6225814819335938\n",
      "Epoch 2/40, Validation Loss: 0.5856404304504395, Validation Accuracy: 0.7104399212081418\n",
      "Epoch 3/40, Training Loss: 0.5904293358325958\n",
      "Epoch 3/40, Validation Loss: 0.5507956147193909, Validation Accuracy: 0.7301378857518056\n",
      "Epoch 4/40, Training Loss: 0.5495012303193411\n",
      "Epoch 4/40, Validation Loss: 0.5164992213249207, Validation Accuracy: 0.7701904136572554\n",
      "Epoch 5/40, Training Loss: 0.5278213024139404\n",
      "Epoch 5/40, Validation Loss: 0.4998415857553482, Validation Accuracy: 0.7728168089297439\n",
      "Epoch 6/40, Training Loss: 0.5025688608487447\n",
      "Epoch 6/40, Validation Loss: 0.49279969930648804, Validation Accuracy: 0.7728168089297439\n",
      "Epoch 7/40, Training Loss: 0.49094679951667786\n",
      "Epoch 7/40, Validation Loss: 0.4806216359138489, Validation Accuracy: 0.7813525935653316\n",
      "Epoch 8/40, Training Loss: 0.48325762152671814\n",
      "Epoch 8/40, Validation Loss: 0.4751393646001816, Validation Accuracy: 0.7806959947472094\n",
      "Epoch 9/40, Training Loss: 0.47773101925849915\n",
      "Epoch 9/40, Validation Loss: 0.47261251509189606, Validation Accuracy: 0.778069599474721\n",
      "Epoch 10/40, Training Loss: 0.47203059991200763\n",
      "Epoch 10/40, Validation Loss: 0.46370546519756317, Validation Accuracy: 0.7820091923834537\n",
      "Epoch 11/40, Training Loss: 0.467538982629776\n",
      "Epoch 11/40, Validation Loss: 0.4641284644603729, Validation Accuracy: 0.7859487852921865\n",
      "Epoch 12/40, Training Loss: 0.463963121175766\n",
      "Epoch 12/40, Validation Loss: 0.46049487590789795, Validation Accuracy: 0.7839789888378201\n",
      "Epoch 13/40, Training Loss: 0.46043023963769275\n",
      "Epoch 13/40, Validation Loss: 0.45379072427749634, Validation Accuracy: 0.7879185817465528\n",
      "Epoch 14/40, Training Loss: 0.44738568365573883\n",
      "Epoch 14/40, Validation Loss: 0.45087793469429016, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 15/40, Training Loss: 0.44889219601949054\n",
      "Epoch 15/40, Validation Loss: 0.44984398782253265, Validation Accuracy: 0.793827971109652\n",
      "Epoch 16/40, Training Loss: 0.44524293144543964\n",
      "Epoch 16/40, Validation Loss: 0.446586012840271, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 17/40, Training Loss: 0.4429513067007065\n",
      "Epoch 17/40, Validation Loss: 0.445881649851799, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 18/40, Training Loss: 0.4388458927472432\n",
      "Epoch 18/40, Validation Loss: 0.4554870277643204, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 19/40, Training Loss: 0.4427044788996379\n",
      "Epoch 19/40, Validation Loss: 0.45572127401828766, Validation Accuracy: 0.7879185817465528\n",
      "Epoch 20/40, Training Loss: 0.4428727775812149\n",
      "Epoch 20/40, Validation Loss: 0.44578249752521515, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 21/40, Training Loss: 0.4396158258120219\n",
      "Epoch 21/40, Validation Loss: 0.44366104900836945, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 22/40, Training Loss: 0.4257614662249883\n",
      "Epoch 22/40, Validation Loss: 0.44257740676403046, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 23/40, Training Loss: 0.42614760001500446\n",
      "Epoch 23/40, Validation Loss: 0.4402316063642502, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 24/40, Training Loss: 0.42604102691014606\n",
      "Epoch 24/40, Validation Loss: 0.4412621855735779, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 25/40, Training Loss: 0.4245956242084503\n",
      "Epoch 25/40, Validation Loss: 0.44238224625587463, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 26/40, Training Loss: 0.42252478500207263\n",
      "Epoch 26/40, Validation Loss: 0.4394535720348358, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 27/40, Training Loss: 0.41947217285633087\n",
      "Epoch 27/40, Validation Loss: 0.4356071650981903, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 28/40, Training Loss: 0.4172484775384267\n",
      "Epoch 28/40, Validation Loss: 0.44173234701156616, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 29/40, Training Loss: 0.41478659709294635\n",
      "Epoch 29/40, Validation Loss: 0.43693363666534424, Validation Accuracy: 0.7918581746552856\n",
      "Epoch 30/40, Training Loss: 0.4106135865052541\n",
      "Epoch 30/40, Validation Loss: 0.4373548775911331, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 31/40, Training Loss: 0.4095079153776169\n",
      "Epoch 31/40, Validation Loss: 0.43495234847068787, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 32/40, Training Loss: 0.4084289222955704\n",
      "Epoch 32/40, Validation Loss: 0.43810854852199554, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 33/40, Training Loss: 0.4066321055094401\n",
      "Epoch 33/40, Validation Loss: 0.4375608563423157, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 34/40, Training Loss: 0.40619654456774396\n",
      "Epoch 34/40, Validation Loss: 0.43498969078063965, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 35/40, Training Loss: 0.4010998209317525\n",
      "Epoch 35/40, Validation Loss: 0.44501541554927826, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 36/40, Training Loss: 0.40361814697583515\n",
      "Epoch 36/40, Validation Loss: 0.43997788429260254, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 37/40, Training Loss: 0.3968595216671626\n",
      "Epoch 37/40, Validation Loss: 0.4452880769968033, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 38/40, Training Loss: 0.39904775222142536\n",
      "Epoch 38/40, Validation Loss: 0.4368942975997925, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 39/40, Training Loss: 0.39370513955752057\n",
      "Epoch 39/40, Validation Loss: 0.44010724127292633, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 40/40, Training Loss: 0.39525288343429565\n",
      "Epoch 40/40, Validation Loss: 0.439235657453537, Validation Accuracy: 0.8030203545633617\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.6810242931048075\n",
      "Epoch 1/40, Validation Loss: 0.6548350155353546, Validation Accuracy: 0.5705843729481287\n",
      "Epoch 2/40, Training Loss: 0.6434618333975474\n",
      "Epoch 2/40, Validation Loss: 0.6071596443653107, Validation Accuracy: 0.6933683519369666\n",
      "Epoch 3/40, Training Loss: 0.607761283715566\n",
      "Epoch 3/40, Validation Loss: 0.5751174092292786, Validation Accuracy: 0.6953381483913329\n",
      "Epoch 4/40, Training Loss: 0.5807359417279562\n",
      "Epoch 4/40, Validation Loss: 0.5402322113513947, Validation Accuracy: 0.7550886408404465\n",
      "Epoch 5/40, Training Loss: 0.5470014214515686\n",
      "Epoch 5/40, Validation Loss: 0.511823445558548, Validation Accuracy: 0.7590282337491793\n",
      "Epoch 6/40, Training Loss: 0.5230180025100708\n",
      "Epoch 6/40, Validation Loss: 0.4883222132921219, Validation Accuracy: 0.7728168089297439\n",
      "Epoch 7/40, Training Loss: 0.506568655371666\n",
      "Epoch 7/40, Validation Loss: 0.48554661870002747, Validation Accuracy: 0.7655942219304005\n",
      "Epoch 8/40, Training Loss: 0.4947821299235026\n",
      "Epoch 8/40, Validation Loss: 0.4716985374689102, Validation Accuracy: 0.778069599474721\n",
      "Epoch 9/40, Training Loss: 0.4857345372438431\n",
      "Epoch 9/40, Validation Loss: 0.46585777401924133, Validation Accuracy: 0.7905449770190414\n",
      "Epoch 10/40, Training Loss: 0.48097332815329236\n",
      "Epoch 10/40, Validation Loss: 0.45955972373485565, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 11/40, Training Loss: 0.4752546151479085\n",
      "Epoch 11/40, Validation Loss: 0.4566064029932022, Validation Accuracy: 0.7892317793827971\n",
      "Epoch 12/40, Training Loss: 0.4691154211759567\n",
      "Epoch 12/40, Validation Loss: 0.45315469801425934, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 13/40, Training Loss: 0.4651804914077123\n",
      "Epoch 13/40, Validation Loss: 0.45037294924259186, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 14/40, Training Loss: 0.4559065153201421\n",
      "Epoch 14/40, Validation Loss: 0.4465086758136749, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 15/40, Training Loss: 0.456804816921552\n",
      "Epoch 15/40, Validation Loss: 0.446414053440094, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 16/40, Training Loss: 0.45107772946357727\n",
      "Epoch 16/40, Validation Loss: 0.4432007670402527, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 17/40, Training Loss: 0.4502855936686198\n",
      "Epoch 17/40, Validation Loss: 0.44119323790073395, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 18/40, Training Loss: 0.439041535059611\n",
      "Epoch 18/40, Validation Loss: 0.4498559534549713, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 19/40, Training Loss: 0.4445968170960744\n",
      "Epoch 19/40, Validation Loss: 0.4476306885480881, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 20/40, Training Loss: 0.44196650882562\n",
      "Epoch 20/40, Validation Loss: 0.44016288220882416, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 21/40, Training Loss: 0.436244656642278\n",
      "Epoch 21/40, Validation Loss: 0.4377756267786026, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 22/40, Training Loss: 0.43400528530279797\n",
      "Epoch 22/40, Validation Loss: 0.4381903260946274, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 23/40, Training Loss: 0.43037499984105426\n",
      "Epoch 23/40, Validation Loss: 0.44021183252334595, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 24/40, Training Loss: 0.4300604611635208\n",
      "Epoch 24/40, Validation Loss: 0.4451260417699814, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 25/40, Training Loss: 0.4264204154411952\n",
      "Epoch 25/40, Validation Loss: 0.4350907504558563, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 26/40, Training Loss: 0.42219794789950055\n",
      "Epoch 26/40, Validation Loss: 0.43962277472019196, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 27/40, Training Loss: 0.42543130616346997\n",
      "Epoch 27/40, Validation Loss: 0.4455915838479996, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 28/40, Training Loss: 0.4249299218257268\n",
      "Epoch 28/40, Validation Loss: 0.4363914132118225, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 29/40, Training Loss: 0.41929498811562854\n",
      "Epoch 29/40, Validation Loss: 0.432850182056427, Validation Accuracy: 0.7997373604727511\n",
      "Epoch 30/40, Training Loss: 0.42047471304734546\n",
      "Epoch 30/40, Validation Loss: 0.43386808037757874, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 31/40, Training Loss: 0.416358083486557\n",
      "Epoch 31/40, Validation Loss: 0.43185532093048096, Validation Accuracy: 0.799080761654629\n",
      "Epoch 32/40, Training Loss: 0.41061102350552875\n",
      "Epoch 32/40, Validation Loss: 0.4326276481151581, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 33/40, Training Loss: 0.4107501010100047\n",
      "Epoch 33/40, Validation Loss: 0.43594834208488464, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 34/40, Training Loss: 0.4089997510115306\n",
      "Epoch 34/40, Validation Loss: 0.43325068056583405, Validation Accuracy: 0.799080761654629\n",
      "Epoch 35/40, Training Loss: 0.4088449776172638\n",
      "Epoch 35/40, Validation Loss: 0.4348897188901901, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 36/40, Training Loss: 0.4057907313108444\n",
      "Epoch 36/40, Validation Loss: 0.4324679672718048, Validation Accuracy: 0.8049901510177282\n",
      "Epoch 37/40, Training Loss: 0.4039744585752487\n",
      "Epoch 37/40, Validation Loss: 0.4341217875480652, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 38/40, Training Loss: 0.40149061381816864\n",
      "Epoch 38/40, Validation Loss: 0.43405821919441223, Validation Accuracy: 0.7984241628365069\n",
      "Epoch 39/40, Training Loss: 0.39832914372285205\n",
      "Epoch 39/40, Validation Loss: 0.43360818922519684, Validation Accuracy: 0.804333552199606\n",
      "Epoch 40/40, Training Loss: 0.39913494884967804\n",
      "Epoch 40/40, Validation Loss: 0.43445006012916565, Validation Accuracy: 0.8023637557452397\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.6767198840777079\n",
      "Epoch 1/40, Validation Loss: 0.6508154571056366, Validation Accuracy: 0.5738673670387393\n",
      "Epoch 2/40, Training Loss: 0.628423422574997\n",
      "Epoch 2/40, Validation Loss: 0.6057887971401215, Validation Accuracy: 0.690741956664478\n",
      "Epoch 3/40, Training Loss: 0.5896850426991781\n",
      "Epoch 3/40, Validation Loss: 0.5711118280887604, Validation Accuracy: 0.7051871306631649\n",
      "Epoch 4/40, Training Loss: 0.5621077020963033\n",
      "Epoch 4/40, Validation Loss: 0.5314104855060577, Validation Accuracy: 0.7485226526592252\n",
      "Epoch 5/40, Training Loss: 0.527917871872584\n",
      "Epoch 5/40, Validation Loss: 0.5021324455738068, Validation Accuracy: 0.762967826657912\n",
      "Epoch 6/40, Training Loss: 0.5041571805874506\n",
      "Epoch 6/40, Validation Loss: 0.485948845744133, Validation Accuracy: 0.7708470124753776\n",
      "Epoch 7/40, Training Loss: 0.4975029726823171\n",
      "Epoch 7/40, Validation Loss: 0.4820343255996704, Validation Accuracy: 0.7813525935653316\n",
      "Epoch 8/40, Training Loss: 0.48699874182542163\n",
      "Epoch 8/40, Validation Loss: 0.4973736107349396, Validation Accuracy: 0.7655942219304005\n",
      "Epoch 9/40, Training Loss: 0.4831269234418869\n",
      "Epoch 9/40, Validation Loss: 0.48065634071826935, Validation Accuracy: 0.768220617202889\n",
      "Epoch 10/40, Training Loss: 0.479689081509908\n",
      "Epoch 10/40, Validation Loss: 0.47605906426906586, Validation Accuracy: 0.7721602101116218\n",
      "Epoch 11/40, Training Loss: 0.4711063951253891\n",
      "Epoch 11/40, Validation Loss: 0.48189547657966614, Validation Accuracy: 0.7846355876559422\n",
      "Epoch 12/40, Training Loss: 0.46788093944390613\n",
      "Epoch 12/40, Validation Loss: 0.4649718403816223, Validation Accuracy: 0.7852921864740644\n",
      "Epoch 13/40, Training Loss: 0.4592198332150777\n",
      "Epoch 13/40, Validation Loss: 0.46477600932121277, Validation Accuracy: 0.7826657912015759\n",
      "Epoch 14/40, Training Loss: 0.4507148861885071\n",
      "Epoch 14/40, Validation Loss: 0.4639969766139984, Validation Accuracy: 0.7866053841103086\n",
      "Epoch 15/40, Training Loss: 0.45160654683907825\n",
      "Epoch 15/40, Validation Loss: 0.4623973220586777, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 16/40, Training Loss: 0.4462080995241801\n",
      "Epoch 16/40, Validation Loss: 0.45573481917381287, Validation Accuracy: 0.7925147734734077\n",
      "Epoch 17/40, Training Loss: 0.44249068200588226\n",
      "Epoch 17/40, Validation Loss: 0.45600205659866333, Validation Accuracy: 0.7957977675640184\n",
      "Epoch 18/40, Training Loss: 0.43814724187056225\n",
      "Epoch 18/40, Validation Loss: 0.45315515995025635, Validation Accuracy: 0.7898883782009193\n",
      "Epoch 19/40, Training Loss: 0.4394497374693553\n",
      "Epoch 19/40, Validation Loss: 0.451665922999382, Validation Accuracy: 0.7912015758371634\n",
      "Epoch 20/40, Training Loss: 0.4404652069012324\n",
      "Epoch 20/40, Validation Loss: 0.4532151520252228, Validation Accuracy: 0.7872619829284307\n",
      "Epoch 21/40, Training Loss: 0.4344005882740021\n",
      "Epoch 21/40, Validation Loss: 0.4498896598815918, Validation Accuracy: 0.7964543663821405\n",
      "Epoch 22/40, Training Loss: 0.4313393185536067\n",
      "Epoch 22/40, Validation Loss: 0.4486120045185089, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 23/40, Training Loss: 0.4303286373615265\n",
      "Epoch 23/40, Validation Loss: 0.4536913186311722, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 24/40, Training Loss: 0.42530528207619983\n",
      "Epoch 24/40, Validation Loss: 0.45730364322662354, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 25/40, Training Loss: 0.42323821286360425\n",
      "Epoch 25/40, Validation Loss: 0.4514673501253128, Validation Accuracy: 0.8023637557452397\n",
      "Epoch 26/40, Training Loss: 0.41946491102377575\n",
      "Epoch 26/40, Validation Loss: 0.45393428206443787, Validation Accuracy: 0.8069599474720945\n",
      "Epoch 27/40, Training Loss: 0.41737006107966107\n",
      "Epoch 27/40, Validation Loss: 0.44522565603256226, Validation Accuracy: 0.8017071569271176\n",
      "Epoch 28/40, Training Loss: 0.41399747133255005\n",
      "Epoch 28/40, Validation Loss: 0.449296772480011, Validation Accuracy: 0.7971109652002626\n",
      "Epoch 29/40, Training Loss: 0.41867263118426007\n",
      "Epoch 29/40, Validation Loss: 0.44803737103939056, Validation Accuracy: 0.7931713722915299\n",
      "Epoch 30/40, Training Loss: 0.4100639969110489\n",
      "Epoch 30/40, Validation Loss: 0.4533485174179077, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 31/40, Training Loss: 0.40961939096450806\n",
      "Epoch 31/40, Validation Loss: 0.4492403268814087, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 32/40, Training Loss: 0.40645890434583026\n",
      "Epoch 32/40, Validation Loss: 0.44907014071941376, Validation Accuracy: 0.804333552199606\n",
      "Epoch 33/40, Training Loss: 0.4020148515701294\n",
      "Epoch 33/40, Validation Loss: 0.4448980987071991, Validation Accuracy: 0.8010505581089954\n",
      "Epoch 34/40, Training Loss: 0.4053384065628052\n",
      "Epoch 34/40, Validation Loss: 0.45465874671936035, Validation Accuracy: 0.7944845699277742\n",
      "Epoch 35/40, Training Loss: 0.4037306209405263\n",
      "Epoch 35/40, Validation Loss: 0.4455995112657547, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 36/40, Training Loss: 0.3999952922264735\n",
      "Epoch 36/40, Validation Loss: 0.4522355645895004, Validation Accuracy: 0.7951411687458962\n",
      "Epoch 37/40, Training Loss: 0.3979991177717845\n",
      "Epoch 37/40, Validation Loss: 0.44852103292942047, Validation Accuracy: 0.7977675640183848\n",
      "Epoch 38/40, Training Loss: 0.3907824158668518\n",
      "Epoch 38/40, Validation Loss: 0.45407629013061523, Validation Accuracy: 0.8030203545633617\n",
      "Epoch 39/40, Training Loss: 0.3920716196298599\n",
      "Epoch 39/40, Validation Loss: 0.4446369856595993, Validation Accuracy: 0.8003939592908733\n",
      "Epoch 40/40, Training Loss: 0.39470070600509644\n",
      "Epoch 40/40, Validation Loss: 0.4544580280780792, Validation Accuracy: 0.7951411687458962\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.6647999485333761\n",
      "Epoch 1/40, Validation Loss: 0.6290605664253235, Validation Accuracy: 0.6176084099868594\n",
      "Epoch 2/40, Training Loss: 0.6225150525569916\n",
      "Epoch 2/40, Validation Loss: 0.5814737677574158, Validation Accuracy: 0.6971090670170828\n",
      "Epoch 3/40, Training Loss: 0.5879400869210561\n",
      "Epoch 3/40, Validation Loss: 0.5384901165962219, Validation Accuracy: 0.7371879106438897\n",
      "Epoch 4/40, Training Loss: 0.5524213115374247\n",
      "Epoch 4/40, Validation Loss: 0.5025286972522736, Validation Accuracy: 0.7575558475689882\n",
      "Epoch 5/40, Training Loss: 0.5286436676979065\n",
      "Epoch 5/40, Validation Loss: 0.484304815530777, Validation Accuracy: 0.7588699080157687\n",
      "Epoch 6/40, Training Loss: 0.5007018397251765\n",
      "Epoch 6/40, Validation Loss: 0.47082898020744324, Validation Accuracy: 0.7614980289093298\n",
      "Epoch 7/40, Training Loss: 0.48892677823702496\n",
      "Epoch 7/40, Validation Loss: 0.46444064378738403, Validation Accuracy: 0.7746386333771353\n",
      "Epoch 8/40, Training Loss: 0.4831264714399974\n",
      "Epoch 8/40, Validation Loss: 0.46015481650829315, Validation Accuracy: 0.7772667542706965\n",
      "Epoch 9/40, Training Loss: 0.4744107077519099\n",
      "Epoch 9/40, Validation Loss: 0.4516416937112808, Validation Accuracy: 0.7812089356110381\n",
      "Epoch 10/40, Training Loss: 0.46729175249735516\n",
      "Epoch 10/40, Validation Loss: 0.4511062800884247, Validation Accuracy: 0.7864651773981604\n",
      "Epoch 11/40, Training Loss: 0.46538284917672473\n",
      "Epoch 11/40, Validation Loss: 0.4478820860385895, Validation Accuracy: 0.7864651773981604\n",
      "Epoch 12/40, Training Loss: 0.46157461901505786\n",
      "Epoch 12/40, Validation Loss: 0.4378465563058853, Validation Accuracy: 0.7910643889618922\n",
      "Epoch 13/40, Training Loss: 0.45918374756971997\n",
      "Epoch 13/40, Validation Loss: 0.4426199495792389, Validation Accuracy: 0.7910643889618922\n",
      "Epoch 14/40, Training Loss: 0.4540840685367584\n",
      "Epoch 14/40, Validation Loss: 0.4327985793352127, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 15/40, Training Loss: 0.4493444909652074\n",
      "Epoch 15/40, Validation Loss: 0.429680660367012, Validation Accuracy: 0.797634691195795\n",
      "Epoch 16/40, Training Loss: 0.4467705935239792\n",
      "Epoch 16/40, Validation Loss: 0.42653888463974, Validation Accuracy: 0.804862023653088\n",
      "Epoch 17/40, Training Loss: 0.44226787984371185\n",
      "Epoch 17/40, Validation Loss: 0.43038924038410187, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 18/40, Training Loss: 0.44572324057420093\n",
      "Epoch 18/40, Validation Loss: 0.4248853474855423, Validation Accuracy: 0.8042049934296978\n",
      "Epoch 19/40, Training Loss: 0.44318097829818726\n",
      "Epoch 19/40, Validation Loss: 0.42390911281108856, Validation Accuracy: 0.804862023653088\n",
      "Epoch 20/40, Training Loss: 0.4392618437608083\n",
      "Epoch 20/40, Validation Loss: 0.42174623906612396, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 21/40, Training Loss: 0.43409721553325653\n",
      "Epoch 21/40, Validation Loss: 0.42332829535007477, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 22/40, Training Loss: 0.4283018559217453\n",
      "Epoch 22/40, Validation Loss: 0.42094050347805023, Validation Accuracy: 0.804862023653088\n",
      "Epoch 23/40, Training Loss: 0.4336161861817042\n",
      "Epoch 23/40, Validation Loss: 0.42014674842357635, Validation Accuracy: 0.80946123521682\n",
      "Epoch 24/40, Training Loss: 0.4297710905472438\n",
      "Epoch 24/40, Validation Loss: 0.4177337884902954, Validation Accuracy: 0.8068331143232589\n",
      "Epoch 25/40, Training Loss: 0.42225613196690875\n",
      "Epoch 25/40, Validation Loss: 0.41861462593078613, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 26/40, Training Loss: 0.4201380213101705\n",
      "Epoch 26/40, Validation Loss: 0.4176557660102844, Validation Accuracy: 0.80946123521682\n",
      "Epoch 27/40, Training Loss: 0.4189470161994298\n",
      "Epoch 27/40, Validation Loss: 0.4163384586572647, Validation Accuracy: 0.8101182654402103\n",
      "Epoch 28/40, Training Loss: 0.41730986535549164\n",
      "Epoch 28/40, Validation Loss: 0.41682544350624084, Validation Accuracy: 0.8088042049934296\n",
      "Epoch 29/40, Training Loss: 0.4198801517486572\n",
      "Epoch 29/40, Validation Loss: 0.41658182442188263, Validation Accuracy: 0.8140604467805519\n",
      "Epoch 30/40, Training Loss: 0.40909722447395325\n",
      "Epoch 30/40, Validation Loss: 0.4178698807954788, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 31/40, Training Loss: 0.4161701748768489\n",
      "Epoch 31/40, Validation Loss: 0.41403843462467194, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 32/40, Training Loss: 0.4071660687526067\n",
      "Epoch 32/40, Validation Loss: 0.4142540395259857, Validation Accuracy: 0.8114323258869908\n",
      "Epoch 33/40, Training Loss: 0.40832240879535675\n",
      "Epoch 33/40, Validation Loss: 0.41345836222171783, Validation Accuracy: 0.8107752956636005\n",
      "Epoch 34/40, Training Loss: 0.4079059610764186\n",
      "Epoch 34/40, Validation Loss: 0.4148639142513275, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 35/40, Training Loss: 0.4059077352285385\n",
      "Epoch 35/40, Validation Loss: 0.41159583628177643, Validation Accuracy: 0.80946123521682\n",
      "Epoch 36/40, Training Loss: 0.40569832921028137\n",
      "Epoch 36/40, Validation Loss: 0.4126351475715637, Validation Accuracy: 0.8074901445466491\n",
      "Epoch 37/40, Training Loss: 0.4060262193282445\n",
      "Epoch 37/40, Validation Loss: 0.40921740233898163, Validation Accuracy: 0.8127463863337714\n",
      "Epoch 38/40, Training Loss: 0.4003969530264537\n",
      "Epoch 38/40, Validation Loss: 0.4135875850915909, Validation Accuracy: 0.8081471747700394\n",
      "Epoch 39/40, Training Loss: 0.39868617057800293\n",
      "Epoch 39/40, Validation Loss: 0.4099220931529999, Validation Accuracy: 0.80946123521682\n",
      "Epoch 40/40, Training Loss: 0.39356385668118793\n",
      "Epoch 40/40, Validation Loss: 0.4085921198129654, Validation Accuracy: 0.8127463863337714\n",
      "Loaded Model to device\n",
      "Initialized Loss and Optimizer\n",
      "Epoch 1/40, Training Loss: 0.6713437040646871\n",
      "Epoch 1/40, Validation Loss: 0.6294609308242798, Validation Accuracy: 0.6925098554533509\n",
      "Epoch 2/40, Training Loss: 0.6252221465110779\n",
      "Epoch 2/40, Validation Loss: 0.582024335861206, Validation Accuracy: 0.7273324572930355\n",
      "Epoch 3/40, Training Loss: 0.59651447335879\n",
      "Epoch 3/40, Validation Loss: 0.5499178469181061, Validation Accuracy: 0.7148488830486203\n",
      "Epoch 4/40, Training Loss: 0.5606854657332102\n",
      "Epoch 4/40, Validation Loss: 0.5151842534542084, Validation Accuracy: 0.7621550591327201\n",
      "Epoch 5/40, Training Loss: 0.5346500972906748\n",
      "Epoch 5/40, Validation Loss: 0.4984082132577896, Validation Accuracy: 0.7608409986859396\n",
      "Epoch 6/40, Training Loss: 0.5122584700584412\n",
      "Epoch 6/40, Validation Loss: 0.48714683949947357, Validation Accuracy: 0.7621550591327201\n",
      "Epoch 7/40, Training Loss: 0.4968411823113759\n",
      "Epoch 7/40, Validation Loss: 0.46900199353694916, Validation Accuracy: 0.7864651773981604\n",
      "Epoch 8/40, Training Loss: 0.48763080437978107\n",
      "Epoch 8/40, Validation Loss: 0.46265386044979095, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 9/40, Training Loss: 0.4802562743425369\n",
      "Epoch 9/40, Validation Loss: 0.45801055431365967, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 10/40, Training Loss: 0.4726628214120865\n",
      "Epoch 10/40, Validation Loss: 0.4551941305398941, Validation Accuracy: 0.7877792378449409\n",
      "Epoch 11/40, Training Loss: 0.4639429102341334\n",
      "Epoch 11/40, Validation Loss: 0.451594814658165, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 12/40, Training Loss: 0.45976191759109497\n",
      "Epoch 12/40, Validation Loss: 0.44966137409210205, Validation Accuracy: 0.7910643889618922\n",
      "Epoch 13/40, Training Loss: 0.4526212066411972\n",
      "Epoch 13/40, Validation Loss: 0.450080469250679, Validation Accuracy: 0.7884362680683311\n",
      "Epoch 14/40, Training Loss: 0.45071480174859363\n",
      "Epoch 14/40, Validation Loss: 0.4477752298116684, Validation Accuracy: 0.7917214191852825\n",
      "Epoch 15/40, Training Loss: 0.44567341605822247\n",
      "Epoch 15/40, Validation Loss: 0.44975030422210693, Validation Accuracy: 0.7864651773981604\n",
      "Epoch 16/40, Training Loss: 0.44656001031398773\n",
      "Epoch 16/40, Validation Loss: 0.45172712206840515, Validation Accuracy: 0.78580814717477\n",
      "Epoch 17/40, Training Loss: 0.4425940066576004\n",
      "Epoch 17/40, Validation Loss: 0.46872447431087494, Validation Accuracy: 0.7739816031537451\n",
      "Epoch 18/40, Training Loss: 0.4495235085487366\n",
      "Epoch 18/40, Validation Loss: 0.4414292871952057, Validation Accuracy: 0.7950065703022339\n",
      "Epoch 19/40, Training Loss: 0.4390576481819153\n",
      "Epoch 19/40, Validation Loss: 0.4490572363138199, Validation Accuracy: 0.804862023653088\n",
      "Epoch 20/40, Training Loss: 0.43491601943969727\n",
      "Epoch 20/40, Validation Loss: 0.43906092643737793, Validation Accuracy: 0.7982917214191853\n",
      "Epoch 21/40, Training Loss: 0.43713269631067914\n",
      "Epoch 21/40, Validation Loss: 0.4479665458202362, Validation Accuracy: 0.7844940867279895\n",
      "Epoch 22/40, Training Loss: 0.4324515213569005\n",
      "Epoch 22/40, Validation Loss: 0.4472742825746536, Validation Accuracy: 0.7871222076215506\n",
      "Epoch 23/40, Training Loss: 0.4243698517481486\n",
      "Epoch 23/40, Validation Loss: 0.4401577115058899, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 24/40, Training Loss: 0.4243399053812027\n",
      "Epoch 24/40, Validation Loss: 0.4445531964302063, Validation Accuracy: 0.8055190538764783\n",
      "Epoch 25/40, Training Loss: 0.4251449505488078\n",
      "Epoch 25/40, Validation Loss: 0.4439409077167511, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 26/40, Training Loss: 0.42031721274058026\n",
      "Epoch 26/40, Validation Loss: 0.4370002746582031, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 27/40, Training Loss: 0.41317865749200183\n",
      "Epoch 27/40, Validation Loss: 0.44219836592674255, Validation Accuracy: 0.7936925098554534\n",
      "Epoch 28/40, Training Loss: 0.4180602232615153\n",
      "Epoch 28/40, Validation Loss: 0.4365047365427017, Validation Accuracy: 0.8028909329829172\n",
      "Epoch 29/40, Training Loss: 0.4132744024197261\n",
      "Epoch 29/40, Validation Loss: 0.43926696479320526, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 30/40, Training Loss: 0.4123132973909378\n",
      "Epoch 30/40, Validation Loss: 0.45017552375793457, Validation Accuracy: 0.797634691195795\n",
      "Epoch 31/40, Training Loss: 0.41387949883937836\n",
      "Epoch 31/40, Validation Loss: 0.44766148924827576, Validation Accuracy: 0.7930354796320631\n",
      "Epoch 32/40, Training Loss: 0.4146370639403661\n",
      "Epoch 32/40, Validation Loss: 0.43823114037513733, Validation Accuracy: 0.804862023653088\n",
      "Epoch 33/40, Training Loss: 0.40776053071022034\n",
      "Epoch 33/40, Validation Loss: 0.4378605931997299, Validation Accuracy: 0.8022339027595269\n",
      "Epoch 34/40, Training Loss: 0.4039107908805211\n",
      "Epoch 34/40, Validation Loss: 0.4353559762239456, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 35/40, Training Loss: 0.40247894326845807\n",
      "Epoch 35/40, Validation Loss: 0.43790268898010254, Validation Accuracy: 0.8009198423127464\n",
      "Epoch 36/40, Training Loss: 0.397655725479126\n",
      "Epoch 36/40, Validation Loss: 0.43724480271339417, Validation Accuracy: 0.8002628120893561\n",
      "Epoch 37/40, Training Loss: 0.3982594509919484\n",
      "Epoch 37/40, Validation Loss: 0.4404769539833069, Validation Accuracy: 0.8035479632063075\n",
      "Epoch 38/40, Training Loss: 0.39691150685151416\n",
      "Epoch 38/40, Validation Loss: 0.4399973005056381, Validation Accuracy: 0.7943495400788436\n",
      "Epoch 39/40, Training Loss: 0.3969097783168157\n",
      "Epoch 39/40, Validation Loss: 0.44346609711647034, Validation Accuracy: 0.7996057818659659\n",
      "Epoch 40/40, Training Loss: 0.39356949428717297\n",
      "Epoch 40/40, Validation Loss: 0.44094496965408325, Validation Accuracy: 0.8028909329829172\n",
      "Average Validation Accuracy: 0.8032325196742374\n"
     ]
    }
   ],
   "source": [
    "val_accuracies = []\n",
    "for train_idx, val_idx in skf.split(combined_features, labels):\n",
    "    # Create TensorDatasets for the current fold\n",
    "    train_dataset = TensorDataset(torch.tensor(combined_features[train_idx]), torch.tensor(labels_numpy[train_idx].reshape(-1,1), dtype=torch.float32))\n",
    "    val_dataset = TensorDataset(torch.tensor(combined_features[val_idx]), torch.tensor(labels_numpy[val_idx].reshape(-1,1), dtype=torch.float32))\n",
    "\n",
    "    # Create DataLoaders for the current fold\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "    # Train and validate your model for the current fold\n",
    "    # Train and validate your model for the current fold and store the validation accuracy\n",
    "    val_accuracy = train_and_validate(train_dataloader, val_dataloader, len(val_dataset), num_epochs=40)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Calculate the average validation accuracy across all folds\n",
    "average_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "print(f'Average Validation Accuracy: {average_val_accuracy}')\n",
    "average_val_accuracy_dict[4] = average_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the keys and values as separate lists\n",
    "keys = list(average_val_accuracy_dict.keys())\n",
    "values = list(average_val_accuracy_dict.values())\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(keys, values)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('number of hidden layers')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.title('Scatter plot of  validation accuracy vs number of hidden layers')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more Hidden layers did not seem to significantly affect the validation accuracy, as seen from the scatter plot the accuracy growth is at around `0.0015`. We will use the original CombinedModel for our training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Training of CombinedModel with Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Training Loss: 0.5317186078823665\n",
      "Epoch 2/40, Training Loss: 0.4762610930855535\n",
      "Epoch 3/40, Training Loss: 0.4608021482762669\n",
      "Epoch 4/40, Training Loss: 0.45401756140646066\n",
      "Epoch 5/40, Training Loss: 0.4466279201099978\n",
      "Epoch 6/40, Training Loss: 0.4435521515806307\n",
      "Epoch 7/40, Training Loss: 0.4389368411419647\n",
      "Epoch 8/40, Training Loss: 0.43844563233032197\n",
      "Epoch 9/40, Training Loss: 0.43577248254055234\n",
      "Epoch 10/40, Training Loss: 0.4317254404999128\n",
      "Epoch 11/40, Training Loss: 0.4298154602234228\n",
      "Epoch 12/40, Training Loss: 0.4300938271369566\n",
      "Epoch 13/40, Training Loss: 0.42776172357697445\n",
      "Epoch 14/40, Training Loss: 0.42666732605562363\n",
      "Epoch 15/40, Training Loss: 0.424092243781642\n",
      "Epoch 16/40, Training Loss: 0.4219192631519204\n",
      "Epoch 17/40, Training Loss: 0.4209210357370497\n",
      "Epoch 18/40, Training Loss: 0.42109948521119955\n",
      "Epoch 19/40, Training Loss: 0.41835703973525334\n",
      "Epoch 20/40, Training Loss: 0.4179773399715914\n",
      "Epoch 21/40, Training Loss: 0.4196624837800109\n",
      "Epoch 22/40, Training Loss: 0.41664060523749147\n",
      "Epoch 23/40, Training Loss: 0.41528318906907274\n",
      "Epoch 24/40, Training Loss: 0.4153918292639511\n",
      "Epoch 25/40, Training Loss: 0.41451401354259804\n",
      "Epoch 26/40, Training Loss: 0.41274852256345396\n",
      "Epoch 27/40, Training Loss: 0.4115133928291562\n",
      "Epoch 28/40, Training Loss: 0.412101592688563\n",
      "Epoch 29/40, Training Loss: 0.41009487424577984\n",
      "Epoch 30/40, Training Loss: 0.4092369625157043\n",
      "Epoch 31/40, Training Loss: 0.40897001161733093\n",
      "Epoch 32/40, Training Loss: 0.4092425495198294\n",
      "Epoch 33/40, Training Loss: 0.4086569387841375\n",
      "Epoch 34/40, Training Loss: 0.4071634507644139\n",
      "Epoch 35/40, Training Loss: 0.4078718996019799\n",
      "Epoch 36/40, Training Loss: 0.40769402455037634\n",
      "Epoch 37/40, Training Loss: 0.4057762766288233\n",
      "Epoch 38/40, Training Loss: 0.4048659756795323\n",
      "Epoch 39/40, Training Loss: 0.40726201114941296\n",
      "Epoch 40/40, Training Loss: 0.40325820346621155\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "# Create a TensorDataset for the entire dataset\n",
    "full_dataset = TensorDataset(torch.tensor(combined_features), torch.tensor(labels_numpy.reshape(-1,1), dtype=torch.float32))\n",
    "\n",
    "# Create a DataLoader for the entire dataset\n",
    "full_dataloader = DataLoader(full_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Train your model on the entire dataset (You can remove the validation loop from your train_and_validate function)\n",
    "def train_full(train_dataloader, num_epochs=num_epochs, device='cuda' if torch.cuda.is_available() else 'cpu', lr=1e-3):\n",
    "    # Replace with your custom model\n",
    "    model = CombinedModel(bert_output_size=768, num_numerical_features=len(numerical_features_columns), num_classes=1)\n",
    "    model.to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch_features, batch_labels in train_dataloader:\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(batch_features)\n",
    "            loss = loss_fn(logits, batch_labels)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Print the average training loss for the epoch\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {total_loss / len(train_dataloader)}')\n",
    "    return model\n",
    "\n",
    "# Train the model on the entire dataset\n",
    "optimized_model = train_full(full_dataloader)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming your test data is a numpy array\n",
    "test_combined_features = combined_features_test\n",
    "test_combined_features_tensor = torch.tensor(combined_features_test, dtype=torch.float32)\n",
    "optimized_model.eval()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Move the model and test features to the appropriate device\n",
    "optimized_model.to(device)\n",
    "test_combined_features_tensor = test_combined_features_tensor.to(device)\n",
    "\n",
    "# Perform a forward pass through the model to obtain predictions\n",
    "with torch.no_grad():\n",
    "    logits = optimized_model(test_combined_features_tensor)\n",
    "\n",
    "# Process the predictions to get the final predicted targets\n",
    "# If it's a binary classification problem, you can apply a threshold and convert the output to binary labels (0 or 1)\n",
    "threshold = 0\n",
    "predicted_targets = (logits > threshold).float().cpu().numpy()\n",
    "\n",
    "# If it's a multi-class problem, you can apply a softmax function and get the class with the highest probability\n",
    "# predicted_targets = torch.argmax(torch.softmax(logits, dim=1), dim=1).cpu().numpy()\n",
    "\n",
    "print(predicted_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_targets = predicted_targets.astype(int)\n",
    "df = pd.DataFrame(predicted_targets, columns=['target'])\n",
    "df = pd.concat([ test['id'],df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       0\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('BERT_predictions/BERT_CombinedNN.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This approach of taking numerical inputs through a linear layer in the Neural Network resulted in an accuracy of `0.808` based on my kaggle submission. This performed `4-6%` better than the Traditional models. This is quite interesting since `BERT_CC.ipynb` performed significantly worse using a similar approach. This could mean that keeping the numerical inputs as separate features and then passing into the Neural Network is a better approach than concatenating into a single string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
